{"student_id":"78","student_name":"Kai","student_slug":"kai","advisor_name":"Kathleen Stevens Wilson","title":"World Loader","thesis_statement":"World Loader is a machine learning powered Unity plugin which aims to accelerate 3D content production workflow. It takes a single 2D image as an input and generates the environment reflected in it through object detection techniques. The result is a scene composed of independent models 3D artists can use to edit the scene after generated.","abstract":"World Loader is a machine learning powered Unity plugin which aims to accelerate the workflow of 3D content production, and it’s also a prototype of a futuristic content creation tool. World Loader takes a 2D image as input and outputs a 3D scene which reflects the environment in the 2D picture. The objects in the generated scene are stand-alone models from the asset and can be edited and swapped, so it’s not just a single mesh with pixels as textures on it. It conserves the context of the environment. Therefore, animation artists can be very flexible as they work with 3D software to develop real-world environments. I expect this could be very helpful in the process of matte painting and composition. Moreover, as we pursue more immersive experiences, being able to copy or map the real world into virtual space is also appealing. \r\nThe plugin combines a set of different pre-trained machine learning models. Each of them is in charge of a different functionality that enables the construction of the whole scene. The Detectron from Facebook Research is in charge of object detection which is able to provide the (x,y) coordinate and object name. The depth estimation model is in charge of the (z) coordinate in the space. The 3D Bounding Box Estimation model outputs the rotation of objects. ","context_research":"Image processing through machine learning is an essential part of this project. To be able to reconstruct a 3D scene based on a 2D image, we need the computer to read more information than just pixels. The research keywords related to this topic are those in the field of 3D machine learning, which includes \"multiple objects detection”, \"scene synthesis/reconstruction”, \"scene understanding”, “3D pose estimation”, “3D bounding box estimation”.  The following projects are especially meaningful references for my project.<br><br>\r\nSoccer On Your Tabletop:<br>\r\nThis project presents a system that transforms a monocular video of a soccer game into a moving 3D reconstruction, in which the players and field can be rendered interactively with a 3D viewer or through an Augmented Reality device. The team uses the MaskCNN algorithm to train on 3D player data extracted from soccer video games. How they compare with state of the art body pose and depth estimation techniques is a really useful technique for my project.\r\n<br><br>\r\nHolistic 3D Scene Parsing and Reconstruction from a Single RGB Image(ECCV2018):<br>\r\nThis team presents an analysis-by-synthesis framework to recover the 3D structure of an indoor scene from a single RGB image using a stochastic grammar model integrated with latent human context, geometry, and physics. Specifically, they introduce a Holistic Scene Grammar (HSG) to represent the 3D scene structure, which characterizes a joint distribution over the functional and geometric space of indoor scenes. This solves the joint parsing and reconstruction problem. Actually, they did most of the things I want to do with a more robust method. However, the scene is still limited to an indoor environment and they are a pure technical research project so they don’t propose applications in real use. (discovered this near the end of the thesis.)","technical_details":"This project includes a Unity editor plugin written in C# as UI and the client to send images to python server which is running machine learning frameworks. On the server side, the python server receives the image and feeds it into the Detectron, Monodepth, and 3D-Deepbox framework to analyze the information hidden in the image, including names of objects, contours of objects, coordinates of objects(x,y index), depths of objects(z index), and the rotations of objects. After resolving the task, the Python server calls the Unity client to instantiate objects from a set of models. ","further_reading":"","tags":[{"name":"3D","slug":"3d"},{"name":"Design","slug":"design"},{"name":"Machine Learning","slug":"machine-learning"},{"name":"Tool","slug":"tool"}],"video_presentation_url":"https://vimeo.com/336836579","video_documentation_url":"https://youtu.be/RPMpUWFpSy0","project_url":"https://github.com/kaichehung/WorldLoader","headshot":{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/2H6A0017-768x512-1.jpg","title":"2H6A0017-768x512","alt":"kai headshot","caption":""},"thumbnail_image":{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/2-768x435-1.png","title":"2-768x435","alt":"image","caption":""},"slide_show":[{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/img03-1.jpg","title":"img03","alt":"image 3","caption":""},{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/0-768x480-1.png","title":"0-768x480","alt":"image4","caption":""},{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/1-768x480-1.png","title":"1-768x480","alt":"image 5","caption":""}]}