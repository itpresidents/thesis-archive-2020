{"student_id":"24","student_name":"Brandon Newberg","student_slug":"brandon-newberg","advisor_name":"Gabriel Barcia-Colombo","title":"Let’s Dance: Movement Technologies","thesis_statement":"A quadrophonic audio installation designed to stimulate interaction and movement between people on a dance floor.","abstract":"How do we relate to music and space, with other people? How can people be encouraged to dance expressively, without worry?<br><br>\r\n\r\n“Let’s Dance” explores how to create an interactive installation that encourages participants to dance, connecting with music and each other. By entering a dance floor with a vive tracker on their wrist, each user can control qualities of one part of a song. The track becomes fully realized as participants “perform” the music with their movements, collectively creating their environment. ","context_research":"The work began as a piece for one person. A participant would enter a room alone and a neural network analyzed their movements, deciding whether or not they were dancing. Based on its analysis, music and lighting would vary in intensity.<br><br>\r\n\r\nI confirmed my intuition that nightlife and dancing are important human activities through research on the history of ecstatic rituals, as well as modern nightlife. There is a primal sensation to connect to when losing oneself on a dark dance floor.<br><br>\r\n\r\nI sought to expand the first version into something social. What makes a whole dance floor move? Why, in many clubs, do people insist on facing a DJ, when the sound and lights surrounds them? I want to foster interactions that break these norms, using technology to connect people and help free them to move.<br><br>\r\n\r\nI built the technical infrastructure to analyze movement, finding ways of analyzing ‘dancey-ness’ and designing potential layouts for an ‘interactive dance floor.’ I spoke with technologists and designers on how to approach the design and development of the system. I conducted several user tests and discovered that providing a clear point of control with a wearable tracker and spatial audio helped people feel free to move while making the interaction clear. As users realize they can collectively manipulate the tension in a piece of music, they work together to realize a magical moment on the dance floor.","technical_details":"The installation supports up to three people, using the Vive tracking system, TouchDesigner, Ableton Live with ambisonic audio plugin Envelop for Live, four or more speakers, and a lighting controller.","further_reading":"","tags":[{"name":"Art","slug":"art"},{"name":"Installation","slug":"installation"},{"name":"Music","slug":"music"}],"video_presentation_url":"https://vimeo.com/337308595","video_documentation_url":"https://vimeo.com/331338469","project_url":"https://physical-digital.com","headshot":{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/IMG_0765-768x576-1.jpg","title":"IMG_0765-768x576","alt":"brandon headshot","caption":""},"thumbnail_image":{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/archivemain-1024x683.jpg","title":"","alt":"3 people in an art installation","caption":""},"slide_show":[{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/archivemain-1024x683.jpg","title":"","alt":"3 people in an art installation","caption":""},{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/trackers.001-1024x768.jpeg","title":"","alt":"trackers001","caption":""},{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/hand-1024x576.jpg","title":"","alt":"hand","caption":""},{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/IMG_0125_s-1024x683.jpg","title":"IMG_0125_s","alt":"people","caption":""},{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/antstand-1024x576.jpg","title":"antstand","alt":"dancing","caption":""}]}