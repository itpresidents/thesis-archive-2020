[{"student_id":142,"student_name":"\"Effy\" Yue Fan","student_slug":"\"effy\"-yue-fan","advisor_name":"Kathleen M Sullivan","title":"Forcetopia","thesis_statement":"Forcetopia is a kinetic data sculpture that re-envisions a dystopian world map with a force-directed structure. This installation visualizes how data can shape a futuristic network of human society by physicalizing the relationship between each nation. ","abstract":"In the long history of human’s discovery of the world, there have been many different versions of geographic world maps. As the fast development of technologies, the world map is getting more and more “accurate”. However, the most common flat world map we see today is still full of distorted due to different projection methods. The United States is always in the center. Russia looks way bigger than it actually is. The current and historical maps were made with human’s vision towards the world at the time. Maps can be great tools for us to learn knowledge,  but it can also be misleading with the things it chose to show. <br><br>\r\nOver the last few years, the volume of data has exploded. There are 2.5 quintillion bytes of data created each day at our current pace, but that pace is only accelerating. International Data Corporation predicts that the collective sum of the world’s data will grow from 33 zettabytes this year to 175 zettabytes by 2025. <br><br>\r\nIn the era of big data, is it possible to make a more “accurate” world map that minimizes the bias in showing information? Or due to unequal access to technology,  it is less possible. We cannot ignore the missing data, the vulnerable data, and data abuse. Therefore, for my thesis, I am investigating how data visualization can or cannot inform more “accurate” information.<br><br>\r\nThe world map tells us geographic information. If I feed this map some data, for example, the percentage of population using the internet from 1990 to 2017. It shows who contributes to the data explosion and how much. But besides staking color patches on top of our world, is there a better way we can show how data has impacted and distorted the world, beyond just showing number. \r\nWhat if, we look at our world only through data.  Will it be a Utopia or a Dystopia? Or in my case, a Forcetopia. ","context_research":"I. Inspirations and Similar Projects: \r\n<br><br>\r\nData physicalization: <br>\r\nhttp://dataphys.org/list/<br>\r\nhttp://yvonnejansen.me/dataphys<br>\r\n“Opportunities and Challenges of Data Physicalization” https://youtu.be/_Rst_2i2crg<br><br>\r\nData Viz:<br>\r\nMike Bostock<br><br>\r\nData Performance: <br>\r\nhttp://blog.blprnt.com/blog/blprnt/on-data-and-performance<br>\r\n“The Headwaters of a River of Words” - https://www.nytimes.com/2007/10/25/arts/design/25vide.html<br>\r\n“Take a Bullet for the City” - http://www.digiart21.org/art/take-a-bullet-for-the-city<br><br>\r\n\r\nII. Data I collected and found: <br><br>\r\n\r\nJob rejection letters/acceptance letters;<br>\r\n“Loneliness index” of ITP rooms from my IoT devices data;<br>\r\nUnemployment rates all over the world (World Bank);<br>\r\nJobs that have disappeared/Existing jobs in the world/Jobs that will disappear.<br><br>\r\n\r\nIII. Experts and Advisors that I spoked to. <br>\r\n<br>\r\nJer Thorp, <br>\r\nGene Kogan,<br>\r\nTom Igoe,<br>\r\nDanny Rozin,<br>\r\nJustin Peake. <br>","thumbnail_image":{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/thumbnail.001-1-1024x576.jpeg","title":"Forcetopia thumbnail","alt":"Forcetopia thumbnail","caption":"Forcetopia thumbnail"},"headshot_image":{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/IMG_4602-768x512-1.jpg","title":"IMG_4602-768x512","alt":"effy headshot","caption":""},"slide_show":[{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/slideshow6-1024x683.jpg","title":"Forcetopia Exhibition","alt":"Forcetopia Exhibition","caption":"Forcetopia Exhibition"},{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/slideshow2-1-1024x683.jpg","title":"Forcetopia Structure","alt":"Forcetopia Structure","caption":"Controlling Structure"},{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/slideshow3-1024x683.jpg","title":"Forcetopia Installing","alt":"Effy Fan installing Forcetopia","caption":"Forcetopia Installing"},{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/slideshow4-1024x683.jpg","title":"slideshow4","alt":"Forcetopia Glass Sphere","caption":"Forcetopia Glass Sphere"},{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/slideshow5-1-1024x575.jpg","title":"Forcetopia Exhibition","alt":"Forcetopia Exhibition","caption":"Forcetopia Exhibition"}],"tags":[{"name":"Art","slug":"art"},{"name":"Data","slug":"data"},{"name":"Design","slug":"design"},{"name":"Experiment","slug":"experiment"},{"name":"Installation","slug":"installation"},{"name":"Machine Learning","slug":"machine-learning"},{"name":"Networks","slug":"networks"},{"name":"Projection Mapping","slug":"projection-mapping"},{"name":"Python","slug":"python"},{"name":"Sculpture","slug":"sculpture"},{"name":"Speculation","slug":"speculation"}],"video_presentation_url":"https://vimeo.com/336827189","video_documentation_url":"https://www.effyyuefan.com/forcetopia"},{"student_id":9,"student_name":"Adekemi Hanna Sijuwade-Ukadike","student_slug":"adekemi-hanna-sijuwade-ukadike","advisor_name":"Stefani Bardin","title":"Africa Maker","thesis_statement":"Africa Maker is a website for and about African inventors and creative technologists in Africa and in the Diaspora.","abstract":"Africans throughout the continent are making incredible technology, and creating solutions to cope with the ‘nuances’ of living in Africa. At the same time, Africans in the Diaspora feel that the narrative of the technology they are creating is not well represented in the media, in data sets and in artificial intelligence algorithms.\r\n\r\nAfrica Maker is a narrative-driven platform that seeks to showcase emerging African and African Diaspora technologists.\r\n\r\nLarge and small scale solutions to power outages, food preservation, waste disposal, fake pharmaceutical detection -- have been created. Who are these people? Where are their projects? How can I promote, propagate and provide them with resources?\r\n\r\nAs an African Maker I (Kemi) am creating an adaptive thumb piano that can be played in the browser with a mouse pad, touchscreen or by facial gestures.\r\n\r\nMy experience from being completely bed-bound for years, due to Guillain–Barré syndrome, to now walking with a cane, prompted me to create this musical instrument / interface. I am making it for people with weak upper body muscles who want to play a musical instrument.\r\n\r\nThis is an example of one of the ways that I am looking to convey the thought processes / cycles of the many devices and applications that Africans are making.\r\n\r\nI am into helping people. I was a physically strong woman, who became disabled and is now in recovery. I have had to be in the most vulnerable of positions…., down to someone having to dress and bathe and clean me everyday.\r\n\r\nSo, imagine an inventor struggling to make this thing to help their life, like a rudimentary prosthetic, but no one else can benefit from it because of privilege or exposure. This is the core spirit of Africa Maker. To help and promote people because they have chosen to make something to enlighten themselves and others.","context_research":"I stumbled upon this idea of creating an online space for current African innovators while browsing social media feeds. I watched, read and listened to stories of new projects created as a means to dealing with some distinctive African circumstance. I became passionate about the idea of devoting myself to empowering these burgeoning technologists.<br><br>\r\nAfrica Maker will begin as a website with feature articles about some African creative technologists in the New York area. In addition, the website will have resources that can be shared by other content publishers.<br><br>\r\n\r\nFrom my research, there is an increasing effort to develop innovation by Africans by countries such as the United Kingdom, China and Italy, as well as companies such as Johnson &amp; Johnson, the Tony Elumelu Foundation, AfriLabs, to name a few. \r\n<br><br>\r\nWhile these forces provide resources by way of funding, there is not much in the way of uncovering the narrative of the maker, and extending this narrative by providing resources beyond funding and some mentor ship.","thumbnail_image":{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/africa-maker-logo-1.png","title":"Africa Maker Logo","alt":"Africa Maker Logo","caption":"Africa Maker Logo"},"headshot_image":{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/2H6A9894-768x512-1.jpg","title":"2H6A9894-768x512","alt":"kemi headshot","caption":""},"slide_show":[{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/Untitled-2.png","title":"Untitled-2","alt":"project image 1","caption":""},{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/Untitled-1-1.png","title":"Untitled-1","alt":"project image 2","caption":""}],"tags":[{"name":"Culture","slug":"culture"},{"name":"Identity","slug":"identity"},{"name":"Narrative/Storytelling","slug":"narrative-storytelling"},{"name":"Social Good/Activism","slug":"social-good-activism"},{"name":"social practice","slug":"social-practice"}],"video_presentation_url":"https://vimeo.com/336813088","video_documentation_url":""},{"student_id":15,"student_name":"Aidan Nelson","student_slug":"aidan-nelson","advisor_name":"Gregory Shakar","title":"Refracting Rays","thesis_statement":"This installation uses custom lenses and digital rendering software to allow audience members to engage with optics and the phenomenon of refraction.","abstract":"How light interacts with surfaces, lenses and our eyes is fundamental to how visual arts are created and perceived.  Despite this importance, education around basic optical principles tends to employ a science-first approach which may not resonate within an artistic community.  This installation attempts to bridge that gap by encouraging audience members to holistically engage with optics and the phenomenon of refraction.\r\n<br><br>\r\nThis installation consists of a series of engagements with playful and impractical lenses.  A custom software tool distorts images such that they can only be seen through these lenses (a process known as anamorphosis). In the first such engagement, audience members are invited to draw on a digital canvas while looking through one such lens.  They are then able to view the results of their work with and without the lens.  In the second engagement, audience members encounter a large, amorphous video projection.  They later realize that the imagery can be decoded through a viewer mounted within the space.   These experiments aim to inspire audience members’ curiosity about the behavior of light.\r\n <br><br>\r\nAs an artist’s understanding of foundational optical principles grows, their palette is expanded to allow aesthetic exploration and play using these elements.  This installation aims to reduce technical barriers to entry and inspire artists to incorporate creative custom optics into their practice. \r\n","context_research":"This project drew inspiration from a number of different sources in art, museum exhibit design and computer graphics fields.  Deliberate perspective distortion (anamorphosis) was pioneered during the Renaissance and described in detail by Jean François Niceron in 1638.  My software was based in the computational approach described by Francesco De Comité in his paper, ‘A General Procedure for the Construction of Mirror Anamorphoses’ (2010).  Design of the physical installation was inspired in large part by existing museum exhibit designs, most notably at The Exploratorium (The Museum of Science, Art &amp; Human Perception) in San Francisco as well as The Museum of the Moving Image in New York.  Finally, this goals of this project were clarified through my conversations with a number of artists working with custom optics, including Robb Godshaw and Florian Born.\r\n","thumbnail_image":{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/thumb-1024x576.jpg","title":"Lenses","alt":"Lenses","caption":""},"headshot_image":{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/profile-2-169x300-1.jpg","title":"profile-2-169x300","alt":"aidan headshot","caption":""},"slide_show":[{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/alan-1024x576.jpg","title":"User Testing","alt":"User Testing","caption":""},{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/2019-04-19-15-59-36.2019-04-19-16_02_13-1024x576.gif","title":"3d","alt":"3d","caption":""},{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/lens-2-1024x576.jpg","title":"Lenses","alt":"Lenses","caption":""},{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/lens-1-1024x576.jpg","title":"Caustics","alt":"Caustics","caption":""},{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/1E2A0001.2019-04-19-16_10_22-1024x576.gif","title":"gif","alt":"gif","caption":""}],"tags":[{"name":"Art","slug":"art"},{"name":"Design","slug":"design"},{"name":"Education","slug":"education"},{"name":"Installation","slug":"installation"},{"name":"Science","slug":"science"},{"name":"Visual","slug":"visual"}],"video_presentation_url":"https://vimeo.com/336825454","video_documentation_url":"https://vimeo.com/331497697"},{"student_id":138,"student_name":"Alan Peng","student_slug":"alan-peng","advisor_name":"Nancy Hechinger","title":"The Tangram Blanket","thesis_statement":"The Tangram Blanket turns a seemingly basic and everyday object into a toy that helps children to develop skills in sensory and cognitive domains. It not only provides warmth and comfort but also lets children play while learning the world through an imaginative and creative way.","abstract":"For my thesis, I hope to turn an everyday object in children's life into a toy that fires the imagination through the simple interaction. Children play with whatever they can find around them, and they are often emotionally attached to the blankets they sleep with every night. What if we had a chance to reimagine the blankets, make them even more versatile, and embed them into the play activities? Inspired by the ancient Chinese Tangram puzzle, the colorful and comfortable Tangram Blanket will greatly enrich children's play experience.\r\n<br><br>\r\nThe Tangram Blanket aims to foster children’s imagination and creativity through play. It starts as a product design idea that leverages my parents’ business, which is a fleece manufacturer. The Tangram Blanket is mostly made of fleece, a soft and comfortable material. The blanket consists of 7 pieces of fabrics in different geometry shapes, colors and textures. By taking a cue from Tangram, one of the most popular and timeless dissection puzzles, each piece of fabrics can be easily attached and detached with each other using magnets to form various shapes. Through the activity, children will be able to develop their language skills, mathematical thinking, and spatial sense. The Tangram Blanket is not only a blanket that keeps children warm and cuddly but also encourages them to play, build and bring their imaginations to life.","context_research":"Toys serve many different purposes, and there are countless toys for accompanying children to understand the world around them. Some would stimulate creativity, while others would aid in the development of problem-solving skills. In addition to the personal development, toys are also essential to building emotional and social skills. Today, there are many new digital technologies that have not existed before to help to build toys; however, the results of the present study suggest that an abundance of digital worlds don't encourage children to use their imagination, especially for young children ages 2 to 5 years.\r\n<br><br>\r\nIn the process of child development, cognitive skills are vital to a child's ability to comprehend ideas and concepts, to think and learn. Children start to develop and refine cognitive skills through play from birth. Same for the sensory skills, children are born exploring the world through their senses. They touch things around them, put things in their mouths, make funny noises and experiment how the world sounds with fingers stuck in their ears. While absorbing those experiences and make sense of the world, imaginative play is needed for children to reach full potential. It gives children practice in independent and gradually develop decision-making skills.","thumbnail_image":{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/Thumbnail-Image-1-1024x576.jpg","title":"The Tangram Blanket","alt":"The Tangram Blanket","caption":""},"headshot_image":{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/default.png","title":"default","alt":"default","caption":""},"slide_show":[{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/Main-1-1024x683.jpg","title":"The Tangram Blanket","alt":"The Tangram Blanket","caption":""},{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/Main-2-1024x683.jpg","title":"Interact with the Tangram Blanket","alt":"Interact with the Tangram Blanket","caption":""},{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/Main-3-1024x683.jpg","title":"A boy picking up a piece of the Tangram Blanket","alt":"A boy picking up a piece of the Tangram Blanket","caption":""},{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/Main-4-1024x576.png","title":"Main-4","alt":"tangram image","caption":""},{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/Main-5-1024x683.jpg","title":"A girl sleeping on the Tangram Blanket","alt":"A girl sleeping on the Tangram Blanket","caption":""}],"tags":[{"name":"Design","slug":"design"},{"name":"Education","slug":"education"},{"name":"Play/Games","slug":"play-games"},{"name":"Product Design","slug":"product-design"}],"video_presentation_url":"https://vimeo.com/337314460","video_documentation_url":""},{"student_id":19,"student_name":"Alden Rivendale Jones","student_slug":"alden-rivendale-jones","advisor_name":"Gabriel Barcia-Colombo","title":"Future&#8217;s Market","thesis_statement":"Future’s Market is a store of tomorrow: a predicted intervention into predictive systems, a performance of ubiquitous surveillance infrastructure, or a look at a world where walls and wires and bank accounts heave and palpitate with a million unhidden eyes.","abstract":"Future’s Market is the performance of a real store. Practically it operates as a kiosk facilitated by Jim Future, it's main proprietor, played by Alden. They sell a variety of different speculative services meant to be interventions into the predictive economy of tomorrow, which, thanks to ubiquitous IoT sensing technologies, has become a near perfect loop between surveillance, prediction, and behavior modification. Customers are able to buy new personalities, edit their biometric profiles, bottle up emotions to save for later, have their trash examined and scored, or get their identity scrambled. Each of these services is played not so much as a subversion of this new economy but as an unexpected extension of it, a disruption that plays by the same rules, a way of gaming the system by taking it at face value. If someone's Google search history can be used to infer their personality, why couldn't their personality be changed by targeted searching? \r\n<br><br>\r\nJim is played as the type of man who's never been told \"no\" by life yet whose greatest ambition as a small business owner is to one day pack up shop and go on a never-ending Carnival Cruise. A little bit outlandish and stylish but only so far as to drum up new business, inside he's just an everyman trying to make by without his own mediocrity getting in the way. He isn't really cut out for this world but then, who is?\r\n","context_research":"Some influences include Zach Blas’s performative lectures on the future of the internet, Michael Smith's Mike's World, Birgit Bachelor and Walter Langelaar’s Commodify.us, Extrapolation Factory’s workshop series, Hito Steyerl’s Duty Free Art, She Lea Chang’s Garlic=Rich Air, American Artists’s Black Gooey Universe, Irena Haiduk’s Whitney Frauenbank, Melanie Hoff and Dan Taeyoung's Small Data Squad, Helen Nissenbaum’s work on obfuscation tactics, and Lynn Hershman Leeson’s Venus of the Anthropocene.","thumbnail_image":{"src":null,"title":"future","alt":"WCAG violation: this image will not be displayed due to lack of alternative text.","caption":""},"headshot_image":{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/me-1-768x512-1.jpg","title":"me-1-768x512","alt":"alden headshot","caption":""},"slide_show":[{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/P3580114_bright-1024x576.jpg","title":"Future's Market at Hester Street Fair","alt":"A picture of Alden sitting at their Future's Market booth","caption":""},{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/IMG_8778-1024x683.jpg","title":"Selling a New Personality","alt":"Alden selling a new personality to a customer","caption":"Alden selling a new personality to a customer"},{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/IMG_0854-1024x768.jpg","title":"Refuse Reading","alt":"A customer getting their garbage scanned by the Refuse Reader","caption":"A customer getting their garbage scanned by the Refuse Reader"},{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/IMG_20190504_134118-1024x768.jpg","title":"Bionetic Scrying","alt":"A woman standing in front of the booth looking into a webcam.","caption":"A customer being bionetically scried"},{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/P3580095_bright-1024x576.jpg","title":"Affect Juice Jar","alt":"A customer holding down a red button in order to fill up a jar labeled \"disgust\" with a greenish liquid","caption":"A customer filling their affect juice jar with \"disgust\""}],"tags":[{"name":"Art","slug":"art"},{"name":"Machine Learning","slug":"machine-learning"},{"name":"Performance","slug":"performance"},{"name":"social practice","slug":"social-practice"},{"name":"Speculation","slug":"speculation"}],"video_presentation_url":"https://vimeo.com/337308373","video_documentation_url":"https://vimeo.com/331733303"},{"student_id":12,"student_name":"Alexandra Lopez","student_slug":"alexandra-lopez","advisor_name":"Nancy Hechinger","title":"&#8220;Widow&#8221;","thesis_statement":"Widowhood is an invisible state in today’s society. \"Widow\" is an interactive textile sculpture that exposes the wounds, pain, and emotions that embody my experience as a widow. With this installation, I aim to inspire others in the hopes that they become aware of all the devastating losses that come after the tremendous passing of a spouse. ","abstract":"Historically, we widowed women have been portrayed wearing long black dresses, a distinctive image that summons the iconographic fashion from the Victorian era in which mourning rites were strict and remarkably complex, following the example of Queen Victoria after the death of her husband, Prince Albert. Victorian widows endured this burden for four years. This fashion comprised heavy black clothes with thick veils of crepe, and hats equally black and dense that lacked any kind of decoration.  This mourning clothing, known as \"widow's weeds \", distinguished the grieving widows from the rest of society. It was a visible indication of the pain for the death of their spouses, with black signifying the absence of light, represented the spiritual seclusion of the mourning woman.\r\nThis textile sculpture references the “widow’s weeds” and the social implications they represent. In a close examination of this costume, the structure underneath those dresses or “cage skirts” is the tangible metaphor I used to recreate and inhabit my own twisted cage skirt. It is a meditative space where I invite the public to take part in and to reflect on the journey and the humiliation I experienced as a young widow. This installation represents my fight against the stigma that is deeply rooted in widow’s fashion and the other social roles that women were expected to follow when they lost their husbands.\r\n","context_research":"In the search for materials that would help me to express, tangibly and viscerally, the rhetoric of my work, I began with mediums already familiar to me. Before ITP I had decades of professional experience as a textile designer with an architectural background. This motivated my approach to my project, which includes the use of fabric, thread, wool, cables, embroidery, weaving, and a wooden structure. Recognizing the need to incorporate an invitation for the spectators to explore the work in an interactive way, I also conducted research on wearable technology. As a textile artist, I frequently use the sense of touch in the exploration of my surroundings. I like to magnify the property that textile fibers have to communicate the sublime through colors and textures. I envisioned a textile sculpture that would respond to the user's tactile stimuli through the use of capacitive sensors that activate lights and sounds, and the result of these interactions direct the narrative experience of the installation. All of these materials help me to capture and invite others to see, hear, and feel the raw emotions of widowhood. ","thumbnail_image":{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/05/Thumbnail-Widow-Alexandra-Lopez-1024x576.jpg","title":"Thumbnail - Widow - Alexandra Lopez","alt":"front view of the sculpture","caption":""},"headshot_image":{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/Alexandra-Lopez-768x432-1.jpg","title":"Alexandra-Lopez-768x432","alt":"alexandra headshot","caption":""},"slide_show":[{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/Slide2-Widow-Alexandra-Lopez-1-1024x576.jpg","title":"Slide2-Widow -Alexandra Lopez","alt":"detail of the white light and the yellow light inside the sculpture","caption":""},{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/Slide5-Widow-Alexandra-Lopez-1024x576.jpg","title":"Slide5-Widow -Alexandra Lopez","alt":"detail of the cage skirt from the bottom","caption":""},{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/Slide3-Widow-Alexandra-Lopez-1024x576.jpg","title":"Slide3-Widow -Alexandra Lopez","alt":"detail of the embroidery process, and the computerize embroidery machine","caption":""},{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/Slide4-Widow-Alexandra-Lopez-1-1024x576.jpg","title":"Slide4-Widow -Alexandra Lopez","alt":"images of sewing the touch pads","caption":""},{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/Slide6-Widow-Alexandra-Lopez-1-1024x576.jpg","title":"Slide6-Widow -Alexandra Lopez","alt":"images of the construction process assembling the dress into the loom","caption":""}],"tags":[{"name":"Art","slug":"art"},{"name":"Identity","slug":"identity"},{"name":"Installation","slug":"installation"},{"name":"Narrative/Storytelling","slug":"narrative-storytelling"},{"name":"Sculpture","slug":"sculpture"},{"name":"Wearables","slug":"wearables"}],"video_presentation_url":"https://vimeo.com/337313875","video_documentation_url":"https://vimeo.com/331475837"},{"student_id":55,"student_name":"Alice Sun","student_slug":"alice-sun","advisor_name":"Kathleen Stevens Wilson","title":"Consistent Doodles","thesis_statement":"An icon is an ideogram that conveys its meaning through its pictorial resemblance. The term “icon aggregator” refers to an icon library that is created through uploads from multiple creators. My thesis has involved redesigning an icon aggregator search engine with the help of machine learning so that it can effectively organize icons by their visual similarities. Its goal is to help users of an icon aggregator service, by reducing the time and effort spent searching for icons, and thereby let them more fully utilize systems of an icon aggregator like Noun Project.","abstract":"Icons vary in their level of detail, scale, weight, and style depending on their themes and purposes. In order to create coherent, digital environments for end users of devices like mobile phones, interface designers strive to ensure visual consistency in the use of icons. Without such consistency, a set of icons falls apart as a visual language and becomes more like a random jumble of doodles. The key to effectively transforming a set of icons into a universal language is consistency. <br><br>\r\n\r\nCurrent icon aggregator systems have some pros and cons. The pros are the high number of collections and the diversity in style. The Noun Project, which is the largest example of an icon aggregator, has over 2 million curated icons created by a global community. The downside to using Noun Project is its lack of consistency throughout different collections and the fact that its tagging-based search system doesn't help solve the problem. Due to this structure, users have to rely on infinite scrolling and bit of luck, in order to find what they're looking for. Icon aggregators like Noun Project not only cost users a lot of time and effort, but also fail to effectively allow users to utilize its amazing number of collections.<br><br>\r\n\r\nMy thesis, which involves the redesign of an icon aggregator search engine, approaches the problem with the use of machine learning. Image feature extraction has been widely used for other types of search engines and has the potential to be applied to icon sorting as well. Organizing icons by their visual similarities, rather than only by tags, makes the icon searching experience easier and quicker, and encourages collaboration within the community of users by effective cross-collection search that is not limited to an individual collection. ","context_research":"My thesis is heavily influenced by machine learning projects as Font Map or existing search platforms powered by machine learning, such as Pinterest and Google Image Search—which both improves the way of searching by analyzing visual patterns of images. Applying deep learning techniques to icons also has been done before (brandmark.io/intro/), but only for the purpose of \"logo maker\". It's great that I have many similar projects, so my research started from studying them.<br><br>\r\n\r\nAfter studying the existing examples, I've learned that it is possible to sort icons. To start, I needed a large source of icons and I decided to use the Noun Project API—attracted by its high number of collections. Hence, my icon searching engine is based on the Noun Project. Involving the Noun Project API into deep learning process is not only for making high-fidelity prototype, but also to avoid arbitrarily picking icons for my user testing.<br><br>\r\n\r\nThe entire process accompanied with two user testings. The very initial user testing was about clarifying the goal and user needs, and the later one was about checking the usability of redesigned wireframe. All icons that were involved in both user testings were pre-analyzed with machine learning.","thumbnail_image":{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/1280x720_thumb-768x432-1.jpg","title":"1280x720_thumb-768x432","alt":"logo thumbnail","caption":""},"headshot_image":{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/1280x720-768x432-1.jpg","title":"1280x720-768x432","alt":"alice headshot","caption":""},"slide_show":[{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/slide-1-768x432-1.jpg","title":"slide-1-768x432","alt":"image 1","caption":""},{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/slide-2-768x432-1.jpg","title":"slide-2-768x432","alt":"image 2","caption":""},{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/slide-3-768x432-1.jpg","title":"slide-3-768x432","alt":"image 3","caption":""},{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/slide-4-768x432-1.jpg","title":"slide-4-768x432","alt":"image 4","caption":""},{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/slide-5-768x432-1.jpg","title":"slide-5-768x432","alt":"image 5","caption":""}],"tags":[{"name":"Data","slug":"data"},{"name":"Design","slug":"design"},{"name":"IOT","slug":"iot"},{"name":"Machine Learning","slug":"machine-learning"},{"name":"Tool","slug":"tool"},{"name":"UX","slug":"ux"}],"video_presentation_url":"https://vimeo.com/336836504","video_documentation_url":""},{"student_id":3,"student_name":"Amena Hayat","student_slug":"amena-hayat","advisor_name":"Stefani Bardin","title":"The Language of Silence VR","thesis_statement":"A volumetric documentary with holograms from real Pakistani women, across different socio-economic classes and levels of education, who share their stories of gender disparity in the country. I want to highlight that with a lack of education, the cultural norms get more violent and I hope to promote education for the female child. ","abstract":"In Pakistan, the world’s first Islamic nation to appoint a female head of state, only 13 percent of girls are still in school by ninth grade. The effects of poverty are everywhere, but the country’s dual system of civil and sharia law, enables a cloak of invisibility over those effects which belong a gendered nature, while law enforcement authorities routinely dismiss crimes against women as private disputes. The country’s women's status differs significantly by community - in each sect access to property, education, employment and sometimes basic human rights remains considerably lower compared to men's. As a result of this power imbalance that begins with education or lack thereof, rampant domestic abuse and a high rate of child marriages and forced marriages still remain, young girls are forcibly married off in order to resolve the feuds between different clans, there are 1000 honour killings, 400 acid attacks a year while punishments meted out to the murderers are very lenient. It is important to note that a vast majority of crimes are never reported. Voicing all this is not safe, however, and silence is the norm.<br><br>\r\nI collected stories, anonymously, from women across multiple sects in Pakistani society, who wanted to share them, as themselves or through an actor. These stories highlight the fact that the literacy rate for urban women is more than five times the rate for rural women, and while that helps them gain more rights, the theme of Pakistan's hyper-patriarchal culture remains the same: \r\nگھر کی بات گھر میں\r\n“Ghar ki baat ghar mein”\r\nOr, let the matters of a family stay within the walls.","context_research":"Influenced by the following volumetric films/documentaries/experiences:<br>\r\nBlackout<br>\r\nTerminal 3<br>\r\nZero Days VR<br>\r\nClouds<br>\r\nTzina: symphony of longing<br>\r\nOther influences:<br>\r\nArtwork by Shehzil Malik<br>\r\nTehmina Durrani's My Feudal Lord<br>\r\nKhalida Brohi's I Should Have Honor: A Memoir of Hope and Pride in Pakistan<br>\r\nMaya Angelou's work<br>\r\nChimamanda Adichie's ted talks<br>\r\nSaadat H. Manto's short stories<br>\r\n<br>\r\nBasically researched this topic my whole life. When I saw Terminal 3 however, it gave me a perfect medium to share these stories and create an impact.","thumbnail_image":{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/sughra-look-2.jpg","title":"sughra look 2","alt":"sughra look 2","caption":""},"headshot_image":{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/Amena-Hayat-photoID-copy-1024x1003.jpg","title":"Amena Hayat photoID copy","alt":"Amena Hayat photoID copy","caption":""},"slide_show":[{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/sughra-look-1.jpg","title":"sughra look 1","alt":"sughra look 1","caption":""}],"tags":[{"name":"Hologram","slug":"hologram"},{"name":"Narrative/Storytelling","slug":"narrative-storytelling"},{"name":"VR/AR/Immersive","slug":"vr-ar-immersive"}],"video_presentation_url":"https://vimeo.com/336812271","video_documentation_url":""},{"student_id":20,"student_name":"Amitabh Shrivastava","student_slug":"amitabh-shrivastava","advisor_name":"Nancy Hechinger","title":"Programmable-Air","thesis_statement":"Programmable-Air is an easy-to-use open-source hardware kit that enables makers to control air flow for their DIY soft robotics projects. My thesis is to crowdfund this project and get it ready for small-scale manufacturing.","abstract":"Soft Robotics is an emerging field that deals with making mechanisms out of highly flexible materials. It is gaining traction in academics with multi-million dollar investments because of emerging use cases in human-robot interaction and industrial automation. The field is still in its infancy. I believe that given the right tools, makers will have a lot to contribute to soft robotics. The aim of Programmable-Air is to provide makers with a tool to control air flow and in doing so, advance inflatable soft robotics. \r\n<br><br>\r\nI have already hand-made and sold over two dozen Programmable-Air beta kits to makers at institutes like UCLA and Microsoft. Academics and artists have used the kit to power projects such as- an inflatable bra, a sculpture about female sexuality, a Halloween prank, an inflatable seat-belt, lego-like soft grippers, and more! There is an increasing demand that can only be met by small-scale(i.e. thousands of units, not millions) manufacturing, which requires an exorbitant upfront investment. So, I am launching a crowdfunding campaign to make this tool available for the maker community.","context_research":"Programmable-Air started out as the final project for the Soft Robotics class taught by Kari Love. I wanted to make a walking soft robot. I soon realized that while it’s very easy to 3D print molds, and cast silicone to make a state-of-the-art soft robot, it’s very difficult to control it programmatically. <br><br>\r\n\r\nTools like Soft Robotics Toolkit from Harvard and Pneuduino from MIT are trying to make inflatable soft robots more accessible. But they leave a lot to be desired in portability, ease of use, and -most importantly- cost. So I created Programmable-Air, an economical, portable, plug’n’play solution. ","thumbnail_image":{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/thumbnail-1-1024x614.png","title":"thumbnail","alt":"thumbnail","caption":""},"headshot_image":{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/IMG_4688-Edit-Copy-2-768x432-1.jpg","title":"IMG_4688-Edit-Copy-2-768x432","alt":"amitabh headshot","caption":""},"slide_show":[{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/mainImg-1-1024x683.jpg","title":"Programmable-Air kit","alt":"Programmable-Air kit","caption":"Programmable-Air kit."},{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/mainImg-2.gif","title":"Programmable-Air action","alt":"Programmable-Air action","caption":"Programmable-Air in action."},{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/mainImg-3-1024x683.jpg","title":"Hand assembled kits.","alt":"Hand assembled kits.","caption":"(painstakingly) Hand assembled kits."},{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/mainImg-5-1024x683.jpg","title":"User testing!","alt":"User testing!","caption":"User testing!"},{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/mainImg-4-1024x683.jpg","title":"World Maker Faire, NYC","alt":"World Maker Faire, NYC","caption":"World Maker Faire, NYC"}],"tags":[{"name":"Electrical Engineering","slug":"electrical-engineering"},{"name":"Experiment","slug":"experiment"},{"name":"Robotics","slug":"robotics"},{"name":"Science","slug":"science"},{"name":"Software","slug":"software"},{"name":"Tool","slug":"tool"}],"video_presentation_url":"https://vimeo.com/336814645","video_documentation_url":"https://vimeo.com/318337374"},{"student_id":11,"student_name":"Anita K Mbabazi","student_slug":"anita-k-mbabazi","advisor_name":"Stefani Bardin","title":"Rokas","thesis_statement":"I am creating an application that shows how buildings in African countries, with a case study of Uganda, can be built with the least possible contribution of CO2 emissions to the environment. The application also educates the user about climate change. ","abstract":"Rokas is a 3D application that allows users to explore how an African city, in this case Kampala, can build buildings that contribute the least possible amount of greenhouse gas emissions. It also allows users to establish how the city can create carbon sinks (forests, wetlands, grasslands) for those greenhouse gas emissions cannot be avoided. <br><br>\r\n\r\nAfrica covers a surface area that can contain the United States, China and India- the top three greenhouse gas emitters in the world today. Africa’s population growth is currently the highest in the world at 2.5 percent with 1.3 billion additional Africans expected by 2050. It also has the fastest urbanization rate of 3.5 percent per year with half of Africa’s 2.5 billion people expected to be living in urban cities in 2050. This predicts Africa having a big part to play in climate change in the near future.<br><br>\r\n\r\nMy target audience are students and my proposal is shaping the future of Africa through education. <br><br>\r\n\r\nThe reason for this is because 60 percent of the African population are below the age of 25 years. Uganda has the second youngest population in the world with 78 percent below 30 years of age. Therefore, the type of Climate Change Education that the youth in an African country such as Uganda receive will determine where the continent is positioned regarding its positive or negative contribution towards climate change in the coming years.\r\n","context_research":"An important part of my research was regarding the extent to which cities in Africa in this case, Kampala were emulating the modern city design of developed countries like the United States during building construction. I traveled to Kampala during my spring break in March 2019 and the simulations of glass box architecture were very much apparent. I contacted various individuals including a senior architect in Kampala, Architect Kabuye Emmanuel, who has been in the building sector in Uganda for over 30 years. <br><br>\r\nHe indicated that due to pressure from clients who insisted on having the ‘modern buildings’ that they had seen in cities in developed countries, many Architects were designing glass buildings that create a greenhouse effect and needed artificial cooling hence requiring a lot of energy. This meant that more fossil fuels would be needed to be burnt in the future to meet the energy needs that come along with this new trend. <br><br>\r\nIt also became clear that while there is a Government body mandated to protect the environment and protect carbon sinks such as wetlands (National Environmental Management Authority- Uganda), there is no visible evidence of that mandate being carried out. Therefore the rising greenhouse gas emissions from future construction projects which should be absorbed by the carbon sinks such as forests or wetlands, would then be sent to the atmosphere hence contributing to global warming.  <br><br>\r\n\r\nI further spoke to individuals in the education field who supported the creation and use of an interactive application from which students would learn how to make sustainable choices. \r\nI was pleased to discover through talking to one of the worker's of Uganda's biggest telecomm company and Internet service providers, that the company offers discounted internet plans to schools and businesses. This would support the running of the application since the it would require reliable internet access to function efficiently. \r\n","thumbnail_image":{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/k2-1024x585.jpg","title":"Kawuku village","alt":"kawuku village in Kampala","caption":""},"headshot_image":{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/IMG_9310-929x1024.jpg","title":"IMG_9310","alt":"Anita","caption":""},"slide_show":[{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/Screen-Shot-2019-05-10-at-6.52.41-PM-1024x500.png","title":"Screen Shot 2019-05-10 at 6.52.41 PM","alt":"wireframe","caption":""},{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/Screen-Shot-2019-05-10-at-7.03.52-PM-1024x515.png","title":"Screen Shot 2019-05-10 at 7.03.52 PM","alt":"wireframe","caption":""},{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/kawukuvillage3-1024x319.jpg","title":"kawukuvillage3","alt":"rokas","caption":""},{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/11.jpg","title":"11","alt":"rokas","caption":""}],"tags":[{"name":"3D","slug":"3d"},{"name":"Culture","slug":"culture"},{"name":"Data","slug":"data"},{"name":"Design","slug":"design"},{"name":"Education","slug":"education"},{"name":"Social Good/Activism","slug":"social-good-activism"}],"video_presentation_url":"https://vimeo.com/336814404","video_documentation_url":"https://www.anitambabazi.com/rokas/videos"},{"student_id":4,"student_name":"Anthony Bui","student_slug":"anthony-bui","advisor_name":"Nancy Hechinger","title":"Overcoming Play Inertia","thesis_statement":"My goal is to make the listless heart wiggle with joy again. In this effort, I explore imbuing my environment with critical interventions, reimagining objects so that they encourage me to play -- freely, intentionally, and with a renewed sense of urgency.","abstract":"I believe that in our ever-increasing desire to become more efficient adults, we sacrifice our imagination, stop playing, overestimate the time we have, and lose sight of who’s important. Under the guise of self-intervention, I reimagine objects so that they encourage me to play again – freely, intentionally, and with a renewed sense of urgency.\r\n<br><br>\r\nFirst, I explore ways to encourage play in our everyday life. In a suite of “intervention toys”, I imbue everyday adult objects with toyish characteristics. The intent is to create cognitive dissonance between the stoic adult and playful youth within each of us. These “intervention toys” give us doses of small play, opening us up to flow into larger play more easily.\r\n<br><br>\r\nNext, I reimagine our broken social networks, making the case that in giving up our agency to social networks, we lose sight of the people who matter in our lives. I set out to build a tool that helps me connect to the people I want to connect with in my life; a tool that is more a rolodex and less a social network, highlighting intentionality.\r\n<br><br>\r\nLastly, understanding that intentionality requires work — I aim to increase our sense of urgency so that we’re inspired to do that work. Channeling the spirit of memento mori, I challenge us to see time in its entirety, encouraging us to live our lives with more playful tenderness and urgency.\r\n<br><br>\r\nI want to acknowledge that we have to balance our lives: the carpets still need to be vacuumed and the dishes still need to get washed. I’m not suggesting we stop working or neglect our responsibilities. Rather, I want to highlight play as the catalyst to a joyful life. We don’t need it all the time, but we do need it. After all, as Stuart Brown solemnly reminds us, “The opposite of play is not work — it is depression”.\r\n","context_research":"In Play: How it Shapes the Brain, Opens the Imagination, and Invigorates the Soul, Stuart Brown tells us that play is a part of our DNA. Highlighting the evolutionary advantages of play, he claims that “those who missed out on play coudn’t tell friend from foe, misread gestures, got rejected by potential mates, and floundered.”\r\n<br><br>\r\nFurther, Dr. Brown hints at play’s health benefits, describing it as “invigorating, opening” and a deep part of how we create “social connection”. Play’s effects are lasting, giving us a lightness and ease, renewing our natural sense of optimism, and opening us up to new possibilities.\r\n<br><br>\r\nDespite these benefits, adults forget to play. While I’ve lived this first hand, my experience isn’t uncommon. In Play It Away: A Workaholic’s Cure for Anxiety, Charlie Hoehn describes his epiphany at a bar, “participating in the weekly ritual of poisoning myself with alcohol, just so I could have superficial interactions with people I’d probably never see again”, finally admitting that he made the mistake of constantly choosing work over guilt-free play with friends.\r\n<br><br>\r\nWe see this ailment even in fiction. In The Little Prince, Antoine de Saint-Exupéry hints at the decline of playful imagination in adulthood: “Grown-ups love figures… When you tell them you’ve made a new friend they never ask you any questions about essential matters. They never say to you “What does his voice sound like? What games does he love best? Does he collect butterflies?” Instead they demand “How old is he?\"\r\n<br><br>\r\nThere are existing artists in this space. Of note, Carsten Höller, who’s exploratory sculptures include massive slides, describes the perception of fun as “something unintellectual or dirty”, but makes the case that “our attitude to it needs to be revisited.”\r\n<br><br>\r\nOf recent interest, a plethora of articles point out growing millennial ailments: burnout is inevitable because we’re optimizing ourselves to death, we’re more anxious than ever before, and we’re struggling with social isolation and loneliness.\r\n<br><br>\r\nI also research intentionality and urgency in our play lives. Tim Urban, in his visual essay \"The Tail End\", cautions us to choose our connections intentionally, and “not by unconscious inertia.” And Brian Brewington, in his essay \"At Some Point\", beckons us to cherish our moments “for just ten more minutes before going back in.”","thumbnail_image":{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/connective-presence-1024x576.jpg","title":"Connective Luminescence","alt":"Photo of Connective Luminescence project, a grid of LEDs powered by the ethereum blockchain.","caption":""},"headshot_image":{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/me-portrait-768x432-1.jpg","title":"me-portrait-768x432","alt":"me-portrait-768x432","caption":""},"slide_show":[{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/coffeetheque-1024x768.jpeg","title":"Coffeetheque","alt":"Coffeetheque","caption":""},{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/mossy-digital-photo-1024x768.jpeg","title":"Moldy Digital Photo","alt":"Photo of moldy digital photo project","caption":""},{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/05/connective-luminescence-1024x768.jpeg","title":"connective-luminescence","alt":"Photo of Connective Luminescence project, a grid of LEDs powered by the ethereum blockchain.","caption":""},{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/collective-obsolescence-1024x768.jpeg","title":"Collective Obsolescence","alt":"Photo of Collective Obsolescence, a blockchain-powered community check-in.","caption":""}],"tags":[{"name":"Art","slug":"art"},{"name":"Design","slug":"design"},{"name":"Experiment","slug":"experiment"},{"name":"Meditation","slug":"meditation"},{"name":"Memory","slug":"memory"},{"name":"Play/Games","slug":"play-games"},{"name":"Self-care","slug":"self-care"}],"video_presentation_url":"https://vimeo.com/337313562","video_documentation_url":"https://vimeo.com/331512086"},{"student_id":14,"student_name":"Arnav Wagh","student_slug":"arnav-wagh","advisor_name":"Kathleen Stevens Wilson","title":"FLXO","thesis_statement":"Flxo is a thinking tool for soft-robotics exploration. It's a kit consisting of modular interlocking pneumatic muscles which easily integrate with other robotics kits on the market.","abstract":"Contrary to conventional robotics which employ rigid materials and motors, pneumatically or hydraulically actuated soft-robots are squishy and highly adaptive to their surroundings. This makes them safe and ideal for collaborative work with humans and other organic life.\r\n<br><br>\r\nSoft-robotics is an exciting and emerging field with a radically different approach to robotics, combining biomimetics and unconventional materials. This field is still in its infancy and there is still a lot to be discovered and invented. There isn't enough accessible literature and documentation on the subject and a large part of the exploration takes place in well-funded research labs. At present anyone who wants to tinker with soft robotics needs to go through the tedious process of design, fabrication and material sourcing.\r\n<br><br>\r\nFlxo is an effort to fill this gap by democratizing key concepts in soft robotics. Flxo consists of prefabricated modular components, entirely 3D printed on a conventional 3D printer, which interlock to create different mechanisms. Additionally, Flxo is also designed to be integrated with other robotics kits on the market for encouraging open exploration of soft robotics as part of STEM curriculum.","context_research":"I was inspired by modular kits like LEGO, K’nex or LittleBits which encourage thinking and creativity through a hands-on, build it yourself approach. I wanted to model a similar platform for encouraging soft robotics exploration. \r\n<br><br>\r\nA modular approach to soft robotics is not new and has been demonstrated effectively by the reconfigurable robotics lab (RRL) and a few other well-funded research labs. FESTO, a German pneumatic automation company manufactures modular soft grippers at industrial and commercial scale. A lot of the research level initiatives demonstrate a proof of concept of new ways of soft robotics fabrication or novel actuation methods using unconventional materials. Most of these demonstrations are very impressive but are primarily designed for either medical applications, or scientific research and search &amp; rescue operations, hence far from finding meaningful, affordable, readily accessible consumer friendly applications.\r\n<br><br>\r\nMy research is an exploration into making the concepts and principles of soft robotics more democratic, more available at the consumer level, by opening it up to play and creative exploration through an affordable, modular platform called Flxo. Central to Flxo are soft actuators or muscles which work as an engine for a given mechanism. Through rigorous trial and error, initially working with silicone and foam and a messy fabrication process, I eventually arrived at an optimized design which can be entirely 3D printed on even a basic desktop 3D printer available to the general public. The kit is also designed to integrate with the VEX robotics platform to make use of their existing array of structural and motion components.","thumbnail_image":{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/thumbnail-14.jpg","title":"Actuators","alt":"The image shows a top view of the complete set of soft actuators","caption":""},"headshot_image":{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/default.png","title":"default","alt":"default","caption":""},"slide_show":[{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/Snap-1-1024x576.jpg","title":"Snap-1","alt":"This image shows hows easily existing pieces from Vex robotics snap into the soft actuator","caption":""},{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/Snap-4-1024x576.jpg","title":"Snap-4","alt":"This image shows a robotic hand being assembled with the 4 soft actuators for four fingers and some pieces from the vex kit","caption":""},{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/Hand-1024x576.jpg","title":"Hand","alt":"This image shows the robotic hand in action with one of the finger/actuator shown bent","caption":""},{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/Walker-1024x576.jpg","title":"Walker","alt":"This is an image of a walking robot assembled from the same kit","caption":""},{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/00030-1024x576.jpg","title":"00030","alt":"This image shows a gripper assembled from the same kit. The gripper is shown lifting a small toy","caption":""}],"tags":[{"name":"Design","slug":"design"},{"name":"Education","slug":"education"},{"name":"Experiment","slug":"experiment"},{"name":"Play/Games","slug":"play-games"},{"name":"Product Design","slug":"product-design"},{"name":"Robotics","slug":"robotics"},{"name":"Tool","slug":"tool"}],"video_presentation_url":"https://vimeo.com/336836071","video_documentation_url":""},{"student_id":21,"student_name":"Asha Veeraswamy","student_slug":"asha-veeraswamy","advisor_name":"Gabriel Barcia-Colombo","title":"Kineme","thesis_statement":"Kineme is a set of motion capture data sculptures about connection, made by analyzing the kinetic flow of improvised partner dances. This installation emotes the trust, vulnerability and somatic experience conveyed through their movements.","abstract":"Kineme –  refers to units of \"body language,\" or the ways in which people communicate with each other through their stance, gestures, and facial expressions. This installation is inspired by abstract expressionism to explore process as medium. It explores how humans can tap into their emotions using digital motion capture of analog shared movements. This temporal data visualization transforms dynamic non-verbal communicative motions into static sculptures of emotional expression.\r\nUsing the partner dance form of Brazilian Zouk Lambada as a framework, Kineme asks the following questions: Why does dance, as a memetic expression language, create a sense of belonging, meaning, &amp; connection between people? How can generated randomness within a set of rules create shared flow states? What is the relationship between digital loss &amp; analog gain when it comes to representing autotelic experiences?","context_research":"","thumbnail_image":{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/AllFive_DSC00894-e1557454543217.jpg","title":"AllFive_DSC00894","alt":"Five Abstract Sculptures in Row on Plinths","caption":""},"headshot_image":{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/Asha-Veeraswamy-Headshot-Smaller-e1557454273110-768x432-1.jpg","title":"Asha-Veeraswamy-Headshot-Smaller-e1557454273110-768x432","alt":"asha headshot","caption":""},"slide_show":[{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/Spine_DSC00805-1024x577.jpg","title":"Spine_DSC00805","alt":"Abstract Sculpture of Spine","caption":""},{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/DSC00779-1024x577.jpg","title":"DSC00779","alt":"Abstract Sculpture of Elbows","caption":""},{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/Hand_DSC00760-1024x577.jpg","title":"Hand_DSC00760","alt":"Abstract Sculpture of Hands","caption":""},{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/Neck_DSC00790-1024x577.jpg","title":"Neck_DSC00790","alt":"Abstract Sculpture of Neck","caption":""},{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/Head_DSC00772-1024x577.jpg","title":"Head_DSC00772","alt":"Abstract Sculpture of Head","caption":""}],"tags":[{"name":"3D","slug":"3d"},{"name":"Art","slug":"art"},{"name":"Data","slug":"data"},{"name":"Installation","slug":"installation"},{"name":"Sculpture","slug":"sculpture"}],"video_presentation_url":"https://vimeo.com/337308465","video_documentation_url":""},{"student_id":5,"student_name":"Assel Dmitriyeva","student_slug":"assel-dmitriyeva","advisor_name":"Stefani Bardin","title":"ML for Social Good: Pedestrian Movement","thesis_statement":"The purpose of this study is to model pedestrian movement on microlevel. In Social Sciences, where particles treated as individual agents, numerous attempts have been done to build Agent Based Models. I am interested in investigating underlying behavioral rules that pedestrians follow. Ultimate goal is to conduct empirical research of pedestrian movement on and near intersections in Downtown Brooklyn area. ","abstract":"Empirical study on human crowd movement have started over 50 years ago. But the field of pedestrian movement on intersections have not been studied extensively. With the rise of technologies such as Connected and Autonomous vehicles, IoT and Smart cities it is essential to build models of pedestrian movement and increase safety in urban areas. ","context_research":"Simulation modeling of pedestrian movement can solve real-world problems safely and efficiently. Inspecting processes and interacting with simulation model in action builds both understanding and trust. Empirical study on human crowd movement have started over 50 years ago. But the field of pedestrian movement on intersections have not been studied extensively. <br><br>\r\nWith the rise of technologies such as Connected and Autonomous vehicles, IoT and Smart cities it is essential to build models of pedestrian movement and increase safety in urban areas. However, building an accurate model by obtaining patterns from the crowd movement requires big amounts of primary data. <br><br>\r\nTo overcome these difficulties, Machine Learning techniques can be utilized. Using unsupervised learning techniques, simulated agents can learn and adjust their behaviour without knowing the scenario’s layout, based in learnt patterns around environment features. ","thumbnail_image":{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/thumbnail-3-1024x576.jpg","title":"thumbnail","alt":"thumbnail picture","caption":""},"headshot_image":{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/20190327_154923_280-01-768x432-1.jpeg","title":"20190327_154923_280-01-768x432","alt":"assel","caption":""},"slide_show":[{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/thumbnail-3-1024x576.jpg","title":"thumbnail","alt":"thumbnail picture","caption":""},{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/poster32.jpg","title":"poster 32","alt":"poster 32","caption":""}],"tags":[{"name":"Data","slug":"data"},{"name":"Experiment","slug":"experiment"},{"name":"Machine Learning","slug":"machine-learning"},{"name":"Science","slug":"science"},{"name":"Tool","slug":"tool"}],"video_presentation_url":"https://vimeo.com/336812906","video_documentation_url":""},{"student_id":18,"student_name":"Ayal Rosenberg","student_slug":"ayal-rosenberg","advisor_name":"Gregory Shakar","title":"ElectroEd","thesis_statement":"Tangible, electronic-music instruments - designed for children - can create more joyful and meaningful music experiences at early ages. Allowing children to easily create, play and educate themselves through experience and immersion.\r\n","abstract":"Creative outlet and joyful learning are the true jet-engines for a young child’s well being. The faster children will be allowed to create and “jam”, the deeper the experience goes (just like their quest for language). At young ages, traditional music education and instruments are maintaining a great distance between competence and actual creation. This leads to anxiety and boredom with most kids, and creates this unjustified natural-selection based on talent and pushy parents. Electronic music  instruments (such as sequencers, drum machines, loop machines), are perfect tools for achieving the goal of a joyful, fulfilling and effective music-learning experience, and are typically not marketed to young children nor offered as valid beginning instruments.<br><br>\r\nI have made two prototypes of Music-tech instruments that incorporate the ideas of helping kids (ages 6-9) encounter music in a fun, immersive and empowering way.<br><br>\r\nThe elements on which I based my designs are - simplicity, tangibility, sense-of-success, and the lack of the screen(avoiding overstimulation). For years, the field of electronic-music instruments has been growing and developing along a billion dollar industry of music production and R&amp;D labs. Why shouldn't kids be a part of the audience (and practitioners)? Do electronic beats and sounds suit only the palette of a “sophisticated” adult mind? What could happen if kids will get access to the realm of electronic instruments? <br><br>\r\nOur fear that this is too-easy and too-quick an access to music, and that kids need to learn hardship in order to become a creative person and an artist, is passé, condescending and egotistical. My research shows, that the demand for traditional instruments will rise after children will gain more positive and empowering music-experiences at young ages.With ElectroED, I create a tool that allows children to access music creation in a way that is creative and fulfilling.\r\n","context_research":"In Hans Henrik Knoop’s, “Play, Learning and Creativity”, he interrogates the philosophy that happy children are better learners. He writes, “Children are dependent on learning effectively and experiencing joy in life right from birth...if they are bored, they’ll soon grow restless and seek-out greater stimulation”. One critical factor is the “creative-tension”, which will dictate whether a child will engage or withdraw. If the tension is too big, there will be no flow and no harmony in the act. ElectroED was created with this tension in mind.<br><br>\r\n\r\nMy target users are 6-9 year-olds. I have learned that during those years, the child’s mind is making the transition from the absorbent-mind into the creative and goal-driven mind. It’s usually around the age of 10 that children are “choosing” an instrument with their parents. So I believe that before that, a child should be immersed in positive creating and really experience music. After seeing children engage my beat instrument, I have learned that the element of success is very powerful in a child’s state of creating.<br><br>\r\nIn the matter of what else is out there - Most of the Music-tech-for-kids world has an engineering (DIY) approach. It’s almost always about expressing engineering creativity and not artistic creativity. The other mediums are plastic, complicated, over-stimulating toys, and screen-based applications. There are hardly, if any, true tangible products that can be referred to as musical instruments.\r\n","thumbnail_image":{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/imgForArchive-1-1024x576.jpg","title":"imgForArchive","alt":"1","caption":""},"headshot_image":{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/headshot-768x512-1.jpg","title":"headshot-768x512","alt":"ayal headshot","caption":""},"slide_show":[{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/goodPic2-1024x683.jpg","title":"goodPic2","alt":"1","caption":""},{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/8V6B0206-1024x683.jpg","title":"8V6B0206","alt":"1","caption":""},{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/govIls2-1024x680.jpg","title":"govIls2","alt":"1","caption":""},{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/looperPic-archive-1024x576.png","title":"looperPic archive","alt":"1","caption":""}],"tags":[{"name":"Design","slug":"design"},{"name":"Education","slug":"education"},{"name":"Music","slug":"music"},{"name":"Play/Games","slug":"play-games"}],"video_presentation_url":"https://vimeo.com/336825536","video_documentation_url":"https://vimeo.com/261948474 , https://vimeo.com/335235072"},{"student_id":8,"student_name":"Azalea Vaseghi","student_slug":"azalea-vaseghi","advisor_name":"Kathleen M Sullivan","title":"Digital Embrace","thesis_statement":"Digital Embrace is a data driven exercise that explores how the internet is potentially affecting us in ways we are unaware of. ","abstract":"Although social media claims to catalyze social connections, much of the time it only serves to simplify our experiences and lives into manageable, easy to digest snippets. This according to, psychologist and the professor of the social studies of science and technology at MIT, Sherry Turkle “turns [people] into something close to objects” and, consequently, makes oneself “vulnerable to seeing itself as one.” This method of interaction, according to Turkle, breeds narcissism, which in psychoanalysis, is “not to indicate people who love themselves, but a personality…who cannot tolerate the complicated demands of other people but tries to relate to them by distorting who they are” and so “gets on with others only by dealing with their made-to-measure representations”. This level of control in online interaction, couple with our body’s release of the “cuddle drug” oxytocin during the act of social media engagement, create an allure that few are able to resist. But how is this potentially affecting the way we interact in the long run? Digital embrace seeks to unveil these shifts are they are occurring. ","context_research":"Our desire to control the way we are perceived is something that sociologist Erving Goffman explores in The Presentation of Self in Everyday Life. According to Goffman, “everyone is always and everywhere, more or less consciously, playing a role”. When we interact with one another, one participant plays the role of the performer while the other serves as the audience. In these instances, it is the goal of the “actor” to cast themselves in the best light possible. However, there are many non-verbal cues the actor might unwittingly give the audience that might put the them in a position of vulnerability during these interaction that is not ideal. This aversion to vulnerability is something that social media often capitalizes on as Sherry Turkle explores in her book Alone Together. In this book, Turkle interviews a number of individuals on their use of digital mediums as tools for communication. Although many of them credit these tools with the ability to relieve some of the stress that comes with dealing with other human beings, it becomes clear that this is often at the cost of foregoing vital experiences that help us in our development as human beings, such as the ability to have verbal conversations and the ability to function independently of one another. Often these interactions trick our brains into thinking that we are getting the same level of satisfaction from these interactions as we would from in person interaction by flooding our bodies with feel good chemicals that keep us engaged. In the end, however, all this leads us, according to Turkle, to expect more from technology and less from each other.  ","thumbnail_image":{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/IMG_0656-768x1024.jpg","title":"IMG_0656","alt":"Wearable hug sensor on mannequin","caption":""},"headshot_image":{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/default.png","title":"default","alt":"default","caption":""},"slide_show":[{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/back-1024x576.png","title":"back","alt":"back","caption":""},{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/IMG_0664-1024x768.jpg","title":"IMG_0664","alt":"Wearable hug sensor detail","caption":""}],"tags":[{"name":"Data","slug":"data"},{"name":"Design","slug":"design"},{"name":"Experiment","slug":"experiment"},{"name":"Speculation","slug":"speculation"},{"name":"Wearables","slug":"wearables"}],"video_presentation_url":"https://vimeo.com/336825383","video_documentation_url":""},{"student_id":23,"student_name":"Barak Chamo","student_slug":"barak-chamo","advisor_name":"Gabriel Barcia-Colombo","title":"An Instrument of Value","thesis_statement":"A computer-controlled carving machine - reprogrammed, refitted and repurposed.<br>\r\nDefying its intention of production to continuously draw patterns in sand.<br><br>\r\n\r\nAn Instrument of Value is a robotic sculpture that portrays the juxtaposition between technological and a human experience rooted in the present.","abstract":"We make technology in our image, an extension of our bodies and senses. In return, technology, through automation and mechanisation, shapes human society. But as some aspects of human function, such as production and association, are accelerated, other parts of the human experience are diminished. This societal “tunnel vision”, driven by globalized values of production and consumption, stands at great odds with spiritual and cultural practices that place meditation, presence and impermanence at the core, rather than the periphery.\r\n<br><br>\r\nI remembered visits to Zen temples in Japan, where I saw monks endlessly rake rock gardens and picking moss, or the dedication of Tibetan monks as they draw sand mandalas only to sweep them away upon completion. I was inspired by this contrast and conflict of values to use technology in service of meditation, true experience and presence. Using machines of production automation and reprogram them into agents of continuous practice, defying their purpose of production, focusing on the performance of a task rather than its material outcome or accomplishment.\r\n<br><br>\r\nEach geometric patten is plotted slowly, neatly, in white sand and as it completes the machine dwells for a short while, allowing viewers to appreciate and contemplate its performance but not own or collect it.  Then, in decisive brush strokes, it sweeps away the sand to clear the plate for a new design, again and again.\r\n<br><br>\r\nWith this work I hope to open up the question of how technology shapes our society, and what are the cultural values that dictate the direction in which technology evolves. Can we imagine a world in which meditation and presence are not at odds with technological progress? How could a meditating robot inspire us to imagine such a future?","context_research":"Research for my thesis project was divided into three parts: conceptual, technical and formal.\r\n<br><br>\r\nI began by studying Asian philosophy and spiritual practice to understand the meaning behind meditational practices that were inspiring to me, such as the drawing and destruction of sand mandalas, raking of rock garden, and various forms of dance. I also studied Western philosophy, media theory and sociology, including writings by Kant, McLuhan, Dewey and Marcuse in an attempt to identify and explain (to myself first) the disparity and opposition I noticed between technological progress and a diminishing sense of meaningful connection, presence and experience.\r\n<br><br>\r\nTechnical research focused on learning how to generate mandalas in code, based on a set of rules that are randomly activated. These generated drawing then had to be converted into machine code, and plotted using software I wrote to control CNC carving machines. I also had to experiment with various methods for plotting sand at constant rates and built a custom sand extruder that could be retrofitted onto my machine of choice.\r\n<br><br>\r\nI also conducted formal research on the meaning and structure on mandalas, and found helpful books that broke down the intricate sand paintings intro their constituent parts. It was very important to me that the drawings created by the machine are respectful to the original formal meaning of  the mandala and that they pay homage to this truly inspiring spiritual practice, rather than appropriate and desecrate it.","thumbnail_image":{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/0C2A9362-2-2.jpg","title":"An Instrument of Value","alt":"An Instrument of Value - the moment the machine begins to brush the sand painting away","caption":"The machine begins brushing away the sand painting"},"headshot_image":{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/5W3A1653-768x512-1.jpg","title":"5W3A1653-768x512","alt":"barak headshot","caption":""},"slide_show":[{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/0C2A9362-1024x576.jpg","title":"An Instrument of Value","alt":"An Instrument of Value - the moment the machine begins to brush the sand painting away","caption":"The machine begins brushing away the sand painting"},{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/Untitled1-1024x576.jpg","title":"An Instrument of Value","alt":"An Instrument of Value - top view of the machine","caption":"A pattern is plotted, each one is unique"},{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/5W3A6537-1024x576.jpg","title":"An Instrument of Value","alt":"An Instrument of Value - a completed four leaf lotus pattern","caption":"Upon completion the machine dwells for a minute, allowing viewers to appreciate its performance. The pattern, however, cannot be removed whole from the fixed black bed."},{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/7A7A6830-1024x576.jpg","title":"An Instrument of Value","alt":"An Instrument of Value - parts of sand extruder","caption":"Parts of the sand extruder, this replaced the typical drill spindle, transforming the purpose of the machine"},{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/0C2A9358-1024x576.jpg","title":"An Instrument of Value","alt":"An Instrument of Value - completed hexagon pattern","caption":"The sand is extruded slowly and precisely, the formation of accurate patterns is mesmerizing to watch."}],"tags":[{"name":"Art","slug":"art"},{"name":"Culture","slug":"culture"},{"name":"Meditation","slug":"meditation"},{"name":"Robotics","slug":"robotics"},{"name":"Sculpture","slug":"sculpture"},{"name":"Speculation","slug":"speculation"}],"video_presentation_url":"https://vimeo.com/337308528","video_documentation_url":"https://vimeo.com/331471476/b09680eede"},{"student_id":22,"student_name":"Beverly Chou","student_slug":"beverly-chou","advisor_name":"Kathleen Stevens Wilson","title":"Slow Net","thesis_statement":"Slow Net is a series of experiments that explore how slow networks can be used to protect against data-collecting entities that threaten our autonomy and influence our identities.","abstract":"Privacy concerns have made many news headlines recently, and it’s become clear that our behavioral data is collected when we’re browsing online and using smart devices. Some of the data is used for improving user experience, but much of it is used to predict and influence our behaviors in real-time. By predicting what we’ll do next, data collectors can use the data to intervene and divert our actions in a direction that supports them economically. In this process, humans are reduced to interchangeable pieces of data in a homogenous population of data laborers. As a result, power and wealth is concentrated among those who are able to collect, utilize, and gatekeep vast amounts of information. Our identities get privatized and our autonomy is threatened.<br><br>\r\n\r\nBecause real-time collection of data is enabled by fast Internet speeds, one form of resistance could involve co-opting a tactic from labor unions called the slowdown strike, in which workers deliberately reduce their productivity. My thesis project, Slow Net, aims to utilize this strategy of purposeful inefficiency in three pieces. <br><br>\r\n\r\n1. A zine called A Quick Guide to the Slow Net provides conceptual context to the problems underpinning data collection. <br>\r\n\r\n2. An online messaging application, Slow Chat, forces users to write longer messages and wait longer between messages as conversations progress. <br>\r\n\r\n3. A Slow Router provides free wifi at a much slower speed than expected. <br><br>\r\n\r\nEach of these pieces functions with the goal of slowing the capture of personal data, encouraging more intentional action, and creating opportunities for idle time that allow for introspection and self-development. Collectively these actions attempt to preserve our autonomy and identity. My hope is that as users we can reconsider our relationship with many of the internet platforms we use that exploit us, and as technologists we can re-examine our role in working with and developing these technologies.","context_research":"I originally started my inquiry by asking how we can build trust in our everyday technologies by exposing their underlying systems. I am fascinated with infrastructure and Hans Haacke’s work, especially \"Condensation Cube\", which exposes an invisible system in action. Haacke’s \"Shapolsky Et Al. Manhattan Real Estate Holdings, A Real-Time Social System, As Of May 1, 1971\" was my main inspiration in trying to map where our behavioral data goes after it gets collected. After reading Shoshana Zuboff’s \"The Age of Surveillance Capitalism\" and Jack Self’s article \"Beyond the Self\", I eventually diverged to focus on the impact of data collection because I was alarmed by the imbalance of power between users and data holders. Our current ITP resident Se¿o’s \"Postcards Computer\" and Kevin Roose’s New York Times article “Is Tech Too Easy to Use?” helped me to develop a rationale around how complexity and inefficiency can be used advantageously. \r\n<br><br>\r\nFor A Quick Guide to the Slow Net, I was inspired by Mimi Onuoha and Diana Nucera’s \"A People’s Guide to AI\" and and Amy Wibowo’s \"Bubblesort Zines\". I really like how they discuss complicated technical ideas to broader audience. Slow Chat was largely inspired by my inability to text people back within socially appropriate timeframes. For the Slow Router, I looked to other artists using network infrastructure to resist against invasions of privacy like Trevor Paglen’s \"Autonomy Cube\" and Dhruv Mehrotra’s \"Othernet\". ","thumbnail_image":{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/thesis-archive-icon.jpg","title":"thesis-archive-icon","alt":"hand draw image of a snail","caption":""},"headshot_image":{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/bev-headshot-1.jpg","title":"bev-headshot (1)","alt":"bev headshot","caption":""},"slide_show":[{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/thesis-archive-main-1024x565.jpg","title":"thesis-archive-main","alt":"photo showing the slow net zine on the left, an iphone displaying slow chat app in the middle, and a rapsberry pi with an ethernet cable plugged in on the right","caption":""},{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/thesis-archive-zine-1024x632.jpg","title":"thesis-archive-zine","alt":"Young woman stands by window reading a zine that reads \"A Quick Guide to the Slow Net\" on the cover","caption":""},{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/thesis-archive-chat-1-1024x602.jpg","title":"thesis-archive-chat-1","alt":"screenshot from a laptop showing slow chat app conversation between two people","caption":""},{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/thesis-archive-slownet-portal-1-425x1024.jpg","title":"thesis-archive-slownet-portal-1","alt":"screenshot from a smartphone of slow net captive portal","caption":""}],"tags":[{"name":"Networks","slug":"networks"},{"name":"Privacy/Security","slug":"privacy-security"},{"name":"Social Good/Activism","slug":"social-good-activism"},{"name":"Speculation","slug":"speculation"}],"video_presentation_url":"https://vimeo.com/336836245","video_documentation_url":""},{"student_id":24,"student_name":"Brandon Newberg","student_slug":"brandon-newberg","advisor_name":"Gabriel Barcia-Colombo","title":"Let’s Dance: Movement Technologies","thesis_statement":"A quadrophonic audio installation designed to stimulate interaction and movement between people on a dance floor.","abstract":"How do we relate to music and space, with other people? How can people be encouraged to dance expressively, without worry?<br><br>\r\n\r\n“Let’s Dance” explores how to create an interactive installation that encourages participants to dance, connecting with music and each other. By entering a dance floor with a vive tracker on their wrist, each user can control qualities of one part of a song. The track becomes fully realized as participants “perform” the music with their movements, collectively creating their environment. ","context_research":"The work began as a piece for one person. A participant would enter a room alone and a neural network analyzed their movements, deciding whether or not they were dancing. Based on its analysis, music and lighting would vary in intensity.<br><br>\r\n\r\nI confirmed my intuition that nightlife and dancing are important human activities through research on the history of ecstatic rituals, as well as modern nightlife. There is a primal sensation to connect to when losing oneself on a dark dance floor.<br><br>\r\n\r\nI sought to expand the first version into something social. What makes a whole dance floor move? Why, in many clubs, do people insist on facing a DJ, when the sound and lights surrounds them? I want to foster interactions that break these norms, using technology to connect people and help free them to move.<br><br>\r\n\r\nI built the technical infrastructure to analyze movement, finding ways of analyzing ‘dancey-ness’ and designing potential layouts for an ‘interactive dance floor.’ I spoke with technologists and designers on how to approach the design and development of the system. I conducted several user tests and discovered that providing a clear point of control with a wearable tracker and spatial audio helped people feel free to move while making the interaction clear. As users realize they can collectively manipulate the tension in a piece of music, they work together to realize a magical moment on the dance floor.","thumbnail_image":{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/archivemain-1024x683.jpg","title":"","alt":"3 people in an art installation","caption":""},"headshot_image":{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/IMG_0765-768x576-1.jpg","title":"IMG_0765-768x576","alt":"brandon headshot","caption":""},"slide_show":[{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/archivemain-1024x683.jpg","title":"","alt":"3 people in an art installation","caption":""},{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/trackers.001-1024x768.jpeg","title":"","alt":"trackers001","caption":""},{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/hand-1024x576.jpg","title":"","alt":"hand","caption":""},{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/IMG_0125_s-1024x683.jpg","title":"IMG_0125_s","alt":"people","caption":""},{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/antstand-1024x576.jpg","title":"antstand","alt":"dancing","caption":""}],"tags":[{"name":"Art","slug":"art"},{"name":"Installation","slug":"installation"},{"name":"Music","slug":"music"}],"video_presentation_url":"https://vimeo.com/337308595","video_documentation_url":"https://vimeo.com/331338469"},{"student_id":27,"student_name":"Caleb Ferguson","student_slug":"caleb-ferguson","advisor_name":"Gregory Shakar","title":"North Central Positronics","thesis_statement":"A sprawling online text adventure game set in a post-apocalyptic future where any player can add-to or change the game universe at any time. ","abstract":"While we gladly recount \"It's not about the destination, it's about the journey\", the results-based culture we live in often encourages the opposite. <br><br>\r\n\r\nDespite our professed disdain for rigid procedures and bureaucracy, we find ourselves entrenched in economic and social systems that enforce behavioral compliance to protocol.\r\n<br><br>\r\nThis game is set an post-apocalyptic world dominated by an authoritarian collective called North Central Positronics. While the overbearing collective demands the player follow certain instructions, the game allows players to break away from protocol and make their own path.<br><br>\r\n\r\nPlayers that stake out their own path have complete control over the content of their adventure, and whatever they add is permanently saved in the game universe. Players can link their adventures and narratives to others material in the game - creating an opportunity for collaborative creativity as well.\r\n<br><br>\r\nThe game allows players to do all of this under the veil of total anonymity, giving them an opportunity to adventure without fear of surveillance or judgement.\r\n<br><br>\r\nThe resulting game universe is therefore ever-changing and rhizomatic. Players that contribute to it break away from artificial ‘choices’ a traditional game or story has to offer, and instead truly create their own.","context_research":"North Central Positronics is commentary on technology’s role in the concentration of power and authority. <br><br>\r\n\r\nModern technologies like cloud computing, media streaming, blockchain, and even the internet itself promised decentralization and democratization; but have also created mega-tech giants, overnight millionaires, and crises about surveillance and personal data.<br><br>\r\n\r\nAlexander Galloway details this era of containment and control in his book 'Protocol: How control exists after decentralization'. It is an era of fidelity, pattern and algorithm where information is a life-force and randomness is the enemy. \r\n<br><br>\r\nCompanies in this era grapple for complete control of our wallets and eyeballs by creating behavioral funnels that provide the ‘illusion of choice’ in the content we see and the actions we take.<br><br>\r\n\r\nNetflix’s interactive 'Bandersnatch' is a paragon of this illusion. While viewers feel they’re making personalized choices, they are really operating within a gated, highly monitored world designed to retain their attention.<br><br>\r\n\r\nNorth Central Positronics goes a step beyond the gated worlds of choose-your-own-adventure games and rigid text adventure games like Zork. It is influenced by The Stanley Parable, which pokes fun at the illusion of choice in games and in life; and Dungeons &amp; Dragons, which encourages creativity and spontaneity in lieu of optimal path-finding.<br><br>\r\n\r\nThe game’s content is inspired by works of sci-fi including The Matrix and Animatrix series, The Dark Tower series by Stephen King, and CW’s The 100 - works which call these themes into question by transporting the viewer to a world just far enough from our own.","thumbnail_image":{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/db-main-pic.png","title":"db-main-pic","alt":"db-main-pic","caption":""},"headshot_image":{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/caleb-headshot-e1557460120298-768x432-1.jpg","title":"caleb-headshot-e1557460120298-768x432","alt":"caleb headshot","caption":""},"slide_show":[{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/7-db-1024x608.png","title":"7-db","alt":"7-db","caption":""},{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/vista-no-bar-1024x529.png","title":"vista-no-bar","alt":"vista-no-bar","caption":""},{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/ScienceVictoryCiv5_ScreenArt.png","title":"ScienceVictoryCiv5_ScreenArt","alt":"ScienceVictoryCiv5_ScreenArt","caption":""},{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/shareholder-value-1.jpg","title":"shareholder-value","alt":"shareholder-value","caption":""}],"tags":[{"name":"Culture","slug":"culture"},{"name":"Narrative/Storytelling","slug":"narrative-storytelling"},{"name":"Networks","slug":"networks"},{"name":"Play/Games","slug":"play-games"},{"name":"Speculation","slug":"speculation"}],"video_presentation_url":"https://vimeo.com/336825590","video_documentation_url":""},{"student_id":29,"student_name":"Camilla Padgitt-Coles","student_slug":"camilla-padgitt-coles","advisor_name":"Gregory Shakar","title":"The Tuning House","thesis_statement":"\"The Tuning House\" is a voice-activated light and sound installation where you use your voice to choose a color and sound palette. The frequency of the participant’s voice is translated into a synthesized pitch and color, creating a personalized expression of chromo-synesthesia. Isolating color and sound pairings in this way highlights a simplified and subjective relationship between frequencies which are present all around us.","abstract":"The idea behind this project is to customize sounds and related colors using something personal to the participant as an input. For this installation, the personalized input is the voice. It encourages humming, toning and actively using the voice to customize pitches and related colors. As the participant's voice is synthesized into minimalist color, light, and sonic tones, a feedback loop is created that can continue or be frozen to create a chord or meditative drone. This interaction can create joy out of thin air and/or quiet the mind and thoughts depending on the way the participant chooses to interact with it. ","context_research":"My main influences were Brian Eno’s relaxation rooms that he created for a hospital in the UK and LaMonte Young and Marian Zazeela’s \"Dream House\" installation in NYC. \r\n<Br><Br>\r\nBrian Eno’s relaxation rooms for the Montefiore Hospital in England seemed like exactly like a place that I wish existed in public spaces everywhere; somewhere quiet and pleasant to escape to and recharge in before returning to your daily tasks, whatever they may be. The Dream House by LaMonte Young and Marian Zazeela is a place I have visited many times. While it is not technically interactive, it is a highly sensory environment. LaMonte Young designed a drone for the space that changes based on where you are holding your head, all with physical sound engineering and using no sensors whatsoever. I found that when I left the Dream House, I felt changed.\r\n<Br><Br>\r\nFor this project, I researched topics regarding the relationships between light and sound from both scientific and psychological perspectives, as well as color therapy, specifically color light therapy, or chromotherapy. Last summer, I landed on the Dinshah chromotherapy system, which was developed by Dinshah Ghadiali in 1920. According to this system, each color has a specific therapeutic purpose. I also created a series of experiments using Dinshah’s color to note translation system, which finds correlations between colors and sounds by doing math on their respective frequencies to try to find the closest relationships between them over the electromagnetic spectrum. This was done by dividing the frequency of the color by two 40 times to find the closest frequency of sound. For example, the color red translated to the frequency of around 397 is closest to the musical note G at the frequency of 392. The idea was that using these supporting sounds would support a chromotherapy session with a specific color. \r\n<Br><Br>\r\nI used the Dinshah chromotherapy system as a basis for color and sound pairings which I have since built on, and I prototyped installations leading up to my thesis in the classes Ideation &amp; Prototyping (Tandon), Video Sculpture, The Temporary Expert, The Code Of Music, and NIME, as well as in an unofficial 100 Days Of Making research project.","thumbnail_image":{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/tuninghouse-1-1024x576.jpg","title":"tuninghouse","alt":"Image of the Tuning House with a light green light and a person inside, taken from a distance and with the door closed","caption":""},"headshot_image":{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/portrait-1-768x432-1.jpg","title":"portrait-1-768x432","alt":"camilla portrait","caption":""},"slide_show":[{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/tuninghouse-1-1024x576.jpg","title":"tuninghouse","alt":"Image of the Tuning House with a light green light and a person inside, taken from a distance and with the door closed","caption":""}],"tags":[{"name":"Art","slug":"art"},{"name":"Installation","slug":"installation"},{"name":"Meditation","slug":"meditation"},{"name":"Music","slug":"music"},{"name":"Play/Games","slug":"play-games"}],"video_presentation_url":"https://vimeo.com/336825708","video_documentation_url":"https://vimeo.com/camillapc/the-tuning-house"},{"student_id":28,"student_name":"Camille M Weins","student_slug":"camille-m-weins","advisor_name":"Gregory Shakar","title":"The Comorbiditree","thesis_statement":"The Comorbiditree is a tool that takes a case study approach to illustrating how mismanaging type 2 diabetes, which is heavily affected by blood sugar levels and exercise duration, can lead to the development of a comorbidity or multi-morbidity.","abstract":"Type 2 Diabetes is considered the 7th leading cause of death in the United States. However, Heart Disease is ranked at number one, and can be considered a comorbidity of Diabetes. Thus, a diabetic needs to undergo a monumental lifestyle change to manage their fasting blood glucose level, effectively creating a constrained environment that can oftentimes make them feel powerless. The Comorbiditree seeks to provide new perspective on a user’s sense of control. This app was designed with my mother’s statistics in mind, however, it can easily be scaled for others. This app utilizes two quantifiable variables, blood sugar, a reflection of your diet, and exercise duration, which can have immediate results on your blood sugar value, to build a model that connects my mother’s data and relates it to its comorbidities. ","context_research":"I spent a lot of time talking to Dr. Boris Boguslavskiy about the specifics of the disease and where he finds some of his resources for patient pamphlets. I also was in correspondence with Sam Slover regarding a lot of the technicalities of my thesis. My thesis is a reflection of applied science with a secondary focus on the visualization.\r\n<br><br>\r\nMy mother doesn’t own a computer. She’s around them constantly for her job so she doesn’t want to see any symbols of work when she’s home. It made perfect sense to build a web app because it’s easy to scale for a tablet or smartphone. A case study approach gives me the ability to make a speculative model such as this without worrying about the liability of developing for a wide audience, given the subject matter. However, that doesn’t mean that someone can’t use my approach as a reference for their own personal needs.\r\n","thumbnail_image":{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/graph-2.jpg","title":"graph","alt":"graph of comorbidities","caption":""},"headshot_image":{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/camille-weins-768x432-1.jpg","title":"camille-weins-768x432","alt":"camille headshot","caption":""},"slide_show":[{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/low-risk-1024x567.jpg","title":"low-risk","alt":"low comorbidity odds","caption":""},{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/moderate-risk-1024x597.jpg","title":"moderate-risk","alt":"moderate risk","caption":""},{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/high-risk-1024x597.jpg","title":"high-risk","alt":"high comorbidity odds","caption":""}],"tags":[{"name":"Data","slug":"data"},{"name":"Science","slug":"science"},{"name":"Speculation","slug":"speculation"},{"name":"Tool","slug":"tool"}],"video_presentation_url":"https://vimeo.com/336825663","video_documentation_url":""},{"student_id":130,"student_name":"Carrie Sijia Wang","student_slug":"carrie-sijia-wang","advisor_name":"Gabriel Barcia-Colombo","title":"ALEX, Your Best Friend At Work","thesis_statement":"If we ever reach a world where artificial intelligence knows us better than we know ourselves, are we willing to give in to the all-powerful technology, trade our privacy for a sense of security, our free will for happiness? A semi-critical, moderately humorous look at the relationship between humans and machines, individuals and society.","abstract":"“ALEX, Your Best Friend At Work” is a performance and participatory experience that takes the audience into a futuristic office constantly observed, measured and evaluated by an artificial intelligence system called “ALEX.”\r\n<br><br>\r\nFor ALEX, every word, action or thought can be turned into data, measurable against an enormous database of rules and standards. Whenever the system detects anything out of the normal, acceptable range, the employee in question is required to attend a “repair session”—a 10-20-minute one-on-one session with ALEX, watched by the other colleagues. Through conversation, data collection, various tests including facial expression analysis and speech analysis, ALEX helps the employee determine the root cause behind their unusual behavior, and make the necessary changes to fix their problems.\r\n<br><br>\r\nThe project consists of two parts—a performance and a participatory experience. The performance follows a linear narrative, in which an employee of the company gets caught on camera crying in the stairwell—a behavior deemed “out of range”—and gets called in by ALEX for a one-on-one session. The participatory experience invites people, three at a time, to take part in a trial of a beta version of ALEX 2.0, in which the participants are asked to give up their free will and follow ALEX's suggestions for 10 minutes.\r\n<br><br>\r\nIn a culture driven by progress and pure efficiency, what does it mean to be human? Are emotions just obstacles to be taken care of? How has the development of technology changed human behavior? By exploring what it is like to be in a futuristic workplace controlled by an all-knowing, all-connected machine, my project aims to prompt reflections on the state of human alienation in a rule-based, technology-dominated society.","context_research":"I focused my thesis research in three areas:\r\n<br><br>\r\n1. The relationship between humans and machines, society and technology<br>\r\n2. History of dystopias<br>\r\n3. History of testing the human mind\r\n<br><br>\r\nBelow are a few articles/books included in my research:\r\n<br>\r\nThe Most Human Human, Brian Christian\r\nPropaganda, The Formation of Men's Attitudes, Jacques Ellul\r\nDystopia, A Natural History, Gregory Claeys<br>\r\nThe Technological Society, Jacques Ellul<br>\r\nSocial Darwinism, Scientific Racism, and the Metaphysics of Race, Rutledge M. Dennis<br>\r\nHomo Deus: A Brief History of Tomorrow, Yuval Noah Harari<br><br>\r\n\r\nThe class “Rest of You” with Dan O’Sullivan, which I took at the first half of my thesis semester, has been very helpful for my research in collecting data from everyday life and human bodies.<br><br>\r\n\r\nA few of my past projects contributed to the formation of my thesis. I see them as part of my ongoing research on audience interaction and multimedia integration in performance and installation. \"The System\" and \"Color Censorship\" are both multimedia performances set in dystopian worlds. \"Type to erase. Repeat to forget\" is an installation piece inspired by \"The System\" and invites participants to erase content on the screen using a keyboard or a microphone. \"Games of Futility\" is a series of voice-controlled browser games that are both playful and frustrating on purpose.","thumbnail_image":{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/archive_photos_main2-1024x576.jpg","title":"archive_photos_main2","alt":"\"ALEX, Your Best Friend at Work\", System Interface Design","caption":""},"headshot_image":{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/carrie_profile-768x432-1.jpg","title":"carrie_profile-768x432","alt":"carrie headshot","caption":""},"slide_show":[{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/alex_doc_photos-1024x576.jpg","title":"alex_doc_photos","alt":"\"ALEX, Your Best Friend at Work\", Performance at the Riese Lounge, Photo: Tong Wu","caption":"\"ALEX, Your Best Friend at Work\", Performance at the Riese Lounge, Photo: Tong Wu"},{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/alex_doc_photos2-1024x576.jpg","title":"alex_doc_photos2","alt":"\"ALEX, Your Best Friend at Work\", System Interface Design","caption":"\"ALEX, Your Best Friend at Work\", System Interface Design"},{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/alex_doc_photos3-1024x576.jpg","title":"alex_doc_photos3","alt":"\"ALEX, Your Best Friend at Work\", System Interface Design","caption":"\"ALEX, Your Best Friend at Work\", System Interface Design"},{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/alex_doc_photos4-1024x576.jpg","title":"alex_doc_photos4","alt":"\"ALEX, Your Best Friend at Work\", Participatory Experience, Photo: Tong Wu","caption":"\"ALEX, Your Best Friend at Work\", Participatory Experience, Photo: Tong Wu"},{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/alex_doc_photos5-1-1024x576.jpg","title":"alex_doc_photos5","alt":"\"ALEX, Your Best Friend at Work\", Participatory Experience, Photo: Tong Wu","caption":"\"ALEX, Your Best Friend at Work\", Participatory Experience, Photo: Tong Wu"}],"tags":[{"name":"Art","slug":"art"},{"name":"Culture","slug":"culture"},{"name":"Data","slug":"data"},{"name":"Narrative/Storytelling","slug":"narrative-storytelling"},{"name":"Performance","slug":"performance"},{"name":"Speculation","slug":"speculation"}],"video_presentation_url":"https://vimeo.com/337309232","video_documentation_url":"https://vimeo.com/330938399"},{"student_id":26,"student_name":"Chelsea Chen Chen","student_slug":"chelsea-chen-chen","advisor_name":"Gabriel Barcia-Colombo","title":"Now You Are In the Conversation","thesis_statement":"A playful critique that visually depicts the relationship between artist, artwork, and audiences in an age that mediated by smartphones and social networks. To discuss how do people look at artworks now and does our obsession with capturing takes away from the enjoyment of the experience itself.","abstract":"Now you are in the conversation is a square-shaped keyboard displayed in a 30-inch frame just like a traditional oil painting. Instead of having 26 letters, it has hundreds of blank keys. Hundreds of mini solenoids drive those keys to type themselves nonstop until it detects audiences are taking photos for it.\r\n\r\n","context_research":"It takes two to tango, and also to have a conversation. The self-typing keyboard illustrates the artist’s endless monologue, and audiences can join the artist by viewing it. At this moment, the monologue turns to a conversation. The blank keys represent that art is not asking you to accept a conclusion, just that you entertain these possibilities -- what makes art special is that it resists closure. When the audiences raise their smartphones they ended the conversation, everything stops. \r\n <br><br>\r\n\r\n Any discussion of how we look at art today must take into account how the world of art has changed with the advent of smartphones and social networks.<br><br>\r\n<br><br>\r\nIf you google an image of the Mona Lisa today, you will be confronted with as many images of visitors raising their smartphones to document the painting as you will of the piece itself. Moreover, in terms of those most popular Instagram-Ready exhibitions - such as Dream Machine and 29 rooms - the experience of the artwork itself is secondary to its pictures. You won’t really remember the physical experience of being in the exhibitions; only how it looks. The enduring part of the experience is how it lives as a photo, and so only its photographic qualities matter. \r\n<br><br>\r\n\r\nIn my opinion, observation should be primary to participation. In classic Kantian aesthetic philosophy, the “judgment” of art was specifically about removing a given object of contemplation from “personal interest.” The aesthetic was the domain where audiences separated themselves from attachments to artist or subject matter and judged the work independently. \r\n <br><br>\r\nI hope to spark curiosity that my audience might get interested in other things besides their own image. So I created an interactive installation that gets annoyed by being surrounded by people who take too many photos. \r\n","thumbnail_image":{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/thumbnail-7-576x1024.jpg","title":"thumbnail","alt":"a close shot of white computer keys","caption":""},"headshot_image":{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/profiloPic-768x432-1.jpg","title":"profiloPic-768x432","alt":"chelsea headshot","caption":""},"slide_show":[{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/WechatIMG2347-1024x562.png","title":"WechatIMG2347","alt":"a keyboard wall","caption":""},{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/keyImage4-1024x576.jpg","title":"keyImage4","alt":"a closed shot of keys","caption":""},{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/keyImage2-1024x576.jpg","title":"keyImage2","alt":"a closed shot of keys","caption":""},{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/Screen-Shot-2019-05-10-at-12.06.02-AM-copy-1024x576.jpg","title":"Screen Shot 2019-05-10 at 12.06.02 AM copy","alt":"a woman tries to take a photo for the keyboard wall","caption":""},{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/Screen-Shot-2019-05-10-at-12.08.51-AM-copy-1024x576.jpg","title":"Screen Shot 2019-05-10 at 12.08.51 AM copy","alt":"a key cap attached with a solenoid","caption":""}],"tags":[{"name":"Art","slug":"art"},{"name":"Culture","slug":"culture"},{"name":"Installation","slug":"installation"},{"name":"Machine Learning","slug":"machine-learning"}],"video_presentation_url":"https://vimeo.com/337308653","video_documentation_url":"https://vimeo.com/331218720"},{"student_id":32,"student_name":"Chengchao Zhu","student_slug":"chengchao-zhu","advisor_name":"Gabriel Barcia-Colombo","title":"Winding Time","thesis_statement":"Is time absolute? Why do people perceive time differently? Is your time the same as mine? Inspired by Einstein’s theory of relativity, Winding Time is an experimental installation that investigates personal time and relative speed. How do speed and movement affect our individual timeline? What're the differences between others' timeline and yours?","abstract":"We think of time as a measurement because of its absoluteness. Consequently, we let time decide our life choices; we encounter endless deadlines; we are busy fighting with time. While Einstein’s theory of relativity has given us a new perspective to consider time as a changing element around us, our perception of time is not only dynamic but personal. People have their personal timelines because of their relative speed to others and different interactions within space.\r\n\r\nWinding Time is an experimental interactive installation trying to visualize how people with different speed have different timelines and how their timelines demonstrate their movements spread in a particular space. What the installation showed could consider as a short recent personal timeline trace which was affected by their movement and speed. \r\n\r\nWinding Time invites people to wind up a clockwork motor to reveal a stretched personal timeline that will be generated on video gradually. People will be able to observe their past timeline and also could compare theirs to others.","context_research":"During my research, I was introduced to Einstein's theory of relativity and learned a new concept - spacetime. In Einstein’s theory, spacetime is a four-dimensional concept where people’s trace would look like a spiral spaghetti. I found this point of view inspiring and started thinking about how to connect people’s movement with time and space in our three- dimensional world in an artistic way. To effectively engage audiences in the installation and help them to concepts of relativity and fluidness of time, I chose the wind-up motor as an input.","thumbnail_image":{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/Thumbnail1-1024x576.jpg","title":"Thumbnail1","alt":"Thumbnail1","caption":""},"headshot_image":{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/head_shot-768x432-1.jpg","title":"head_shot-768x432","alt":"chengchao headshot","caption":""},"slide_show":[{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/mainsize44-1024x576.jpg","title":"mainsize44","alt":"44","caption":""},{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/mainsize11-1024x576.jpg","title":"mainsize11","alt":"mainsize11","caption":""},{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/mainsize55-1024x576.jpg","title":"mainsize55","alt":"mainsize55","caption":""},{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/mainsize22-1024x576.jpg","title":"mainsize22","alt":"mainsize22","caption":""},{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/mainsize33-1024x576.jpg","title":"mainsize33","alt":"mainsize33","caption":""}],"tags":[{"name":"Art","slug":"art"},{"name":"Experiment","slug":"experiment"},{"name":"Installation","slug":"installation"},{"name":"Machine Learning","slug":"machine-learning"},{"name":"Science","slug":"science"}],"video_presentation_url":"https://vimeo.com/337308723","video_documentation_url":"https://vimeo.com/335302729"},{"student_id":31,"student_name":"Chengtao Yi","student_slug":"chengtao-yi","advisor_name":"Gregory Shakar","title":"Chengtao designed by Chengtao","thesis_statement":"My Thesis is a life-size replica of my upper body that has multiple functional parts , imagine a human version of Swiss army knife, with my face on it.","abstract":"I am literally making myself. By replicating myself and combining various functionalities with my body parts I tried to investigate the boundary and connections between utilitarian objects, critical sculptures and human bodies. Trying to answer the question: \"What is the ultimate product?” and \"What is the ultimate role for designers?\" <br><br>\r\nThe goal for product design in the modern consumer age has been always about being as friendly and humanistic as possible. Hardware, software are trying to become as intelligent and empathetic as us human. New breakthroughs in artificial intelligence has pushed this idea even more. We might have an ultimate product that can handle all the things at requests, and understands all our orders, even feel what we feel. That make me wonder what if, essentially, all we want to have is just another human that serves us and obeys us unconditionally. Products are becoming humans, and at the same time, we are morphing into products. My thesis is an art installation/sculpture that attempsa to illustrate this state and answer the questions. ","context_research":"Part 1: Major influence, Similar projectsMovie - Swiss Army Man https://www.imdb.com/title/tt4034354/<br>\r\nArtists: Urs Fischer, Tom Sachs, Damian Ortega, Pierre Huyghe, kelly knox, Omkaar Kotediaork<br>\r\n\r\nhttp://kotedia.com/Melting statue replica <br>\r\nhttps://www.vogue.it/en/news/vogue-arts/2017/09/06/interview-urs-fischer-vogue-italia-september-2017/?refresh_ce=\r\n<br>\r\nCosmic Thing<br>\r\nhttps://petrolicious.com/articles/damien-ortega","thumbnail_image":{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/TN-1024x576.jpg","title":"TN","alt":"1","caption":""},"headshot_image":{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/chian.jpg","title":"chian","alt":"chengtao","caption":""},"slide_show":[{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/91low-1024x576.jpg","title":"91low","alt":"1","caption":""},{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/61low-1024x576.jpg","title":"61low","alt":"chengtao","caption":""},{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/ARCHIVE2-1024x576.jpg","title":"ARCHIVE2","alt":"chengtao arm","caption":""},{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/ARCHIVE4-1024x576.jpg","title":"ARCHIVE4","alt":"chengtao4","caption":""},{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/ARCHIVE5-1024x576.jpg","title":"ARCHIVE5","alt":"ARCHIVE5","caption":""}],"tags":[{"name":"Art","slug":"art"},{"name":"Design","slug":"design"},{"name":"Installation","slug":"installation"},{"name":"Product Design","slug":"product-design"},{"name":"Speculation","slug":"speculation"}],"video_presentation_url":"https://vimeo.com/336825795","video_documentation_url":"https://www.chengtaoyi.com/#/chengtao-designed-by-chengtao/"},{"student_id":25,"student_name":"Chian Huang","student_slug":"chian-huang","advisor_name":"Adaora Udoji","title":"Memory Playback, &#8220;Grandma, do you remember?”","thesis_statement":"Memory Playback, “Ama, do you remember?” is an interactive experience with spatial audio design that brings the past memory between my grandma and me to the dining table. This project is designed for my grandma who suffers from Alzheimer's disease. It questions about can the emerging technology help to recall my grandma’s loss memory and enhance her life quality.","abstract":"Memory Playback, “Grandma, do you remember?” is an interactive memory playback experience designed for my grandma. The experience is about a series of past memories between my grandma and her family that are projected on a set of plates. \r\n<br><br>\r\nIn this experience, each plate is designed as a plane for projecting different life moments between my grandma and me. The plate is like a container that holds the memory; therefore, by putting different plates together, it will trigger different video and spatial audios. The audio contains the recordings of the conversations we had in the past which associated to individual memory, including narration to guide through the experience.  \r\n<br><br>\r\nMy grandma suffers from Alzheimer’s disease who experiences memory loss, cognitive and mobility disability. As her family members, it’s difficult to see our loved one changes dramatically to a different person. Although she loses her memory about her family, she still enjoys being around with them. Therefore, this project is designed for myself, my grandma, and the family as an opportunity to look back the memories and celebrate these precious moments together. Moreover, I want to investigate how effective it can be by using different forms of visuals and audios to recall the memory for Alzheimer’s patient. \r\n","context_research":"I practiced different methodologies of research, such us observation, qualitative research, and literature reviews. \r\n<br><br>\r\nFor over five years, I have observed my grandma who has slowly progressed from the early stage of Alzheimer’s to the later stage today. Other than understanding my grandma, I also talked to different family members whose loved ones also suffer from the same disease. In particular, I want to know about what do they feel, what have they done to fight for the disease, and what are their best wishes to them. Moreover, I was able to talk to the Clinical Supervisor from Alzheimer’s Association, NYC Chapter, who is in charge of organization’s care and support team. After the conversation, I understand what do the professionals have learned and what do they think from an organization’s perspective. \r\n<br><br>\r\nLastly, I have reviewed many different studies such as how the brain works, how the memory is recalled, how can Alzheimer’s patients deal with their life changes, and how can the emerging technologies help the family members’ life to become better. \r\n","thumbnail_image":{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/archive_main.jpg","title":"archive_main","alt":"memory playback_main","caption":""},"headshot_image":{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/ChianHuang-768x432-1.jpg","title":"ChianHuang-768x432","alt":"Chian headshot","caption":""},"slide_show":[{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/archive_slide4-1024x576.jpg","title":"archive_slide4","alt":"all the projection","caption":""},{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/archive_slide5-1024x576.jpg","title":"archive_slide5","alt":"one of the projection","caption":""},{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/archive_slide1-1-1024x576.jpg","title":"archive_slide1","alt":"my grandma and the younger me","caption":""},{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/archive_slide3-1-1024x576.jpg","title":"archive_slide3","alt":"my grandma and the current me","caption":""},{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/archive_slide4-1-1024x576.jpg","title":"archive_slide4","alt":"words to say it to my grandma","caption":""}],"tags":[{"name":"Art","slug":"art"},{"name":"Design","slug":"design"},{"name":"Installation","slug":"installation"},{"name":"Memory","slug":"memory"},{"name":"Narrative/Storytelling","slug":"narrative-storytelling"}],"video_presentation_url":"https://vimeo.com/336814678","video_documentation_url":"https://vimeo.com/user72937333/memoryplayback"},{"student_id":37,"student_name":"Dan Oved","student_slug":"dan-oved","advisor_name":"Gabriel Barcia-Colombo","title":"The Self-Driving Human","thesis_statement":"The self-driving human is a device and performance where an intelligent portable agent makes decisions for a person in the real world.","abstract":"As technology increasingly becomes integrated with our daily lives, we rely on it more and more to make decisions for us, from things such as how we should get from one place to the next (Waze), to what we should have for dinner (yelp, tripadvisor), to what content we should see on the internet (social media), to who we should date (dating apps).    What would a future feel like when all of our decisions are made by these machines?  \r\n<br><br>\r\nThe self-driving human simulates this scenario by making choices for the human in areas that are currently not decided by technology.  It’s a portable device that detects objects around the person using a camera and machine learning, and gives commands to the user on how to interact with the environment based on an arbitrary algorithm that changes day by day.  It allows the person to outsource thinking and decision making to an algorithm that they do not entirely understand.\r\n<br><br>\r\nThe agent’s decision space is limited to what the machine has been trained to see.   The user does not know what the logic of the algorithms are, and while the machine does know the objective, it does not know if it is good or bad.   What happens when the objectives of this machine differ from the objectives of the person its meant to serve?   How do the choices made by the algorithm collide with the humans desires when they’re disconnected from the biases and emotions of that the person has learned throughout his or her life?\r\n<br><br>\r\nThe device is portable and works totally offline using machine learning on the edge, allowing for real-time response even where there is no internet connection, and maintaining privacy as all data stays on the device.\r\n<br><br>\r\nFor the performance it is carried by me in the real world, where I listen to its commands and attempt to do as we’re instructed, no matter how uncomfortable it makes me.\r\n","context_research":"This thesis is heavily influenced by previous performance art pieces where someone was given instructions by a piece of technology or a human to perform.  These include: Nicole He’s The Best Art, where a machine generated art projects for her to make, Anastasis’ The Sybil Society, where identities and conversations were created and performed by people, Lauren McCarthy’s Social Turkers, where she would go on daily online dates and be instructed by human Mechanical Turk workers on what to do and say, and Max Hawkin's Randomized Living, where he lets randomized computer programs decide where he lives over two years.  It’s also influenced by projects that explore the subjectiveness and black-box nature of machine learning algorithms, such as the Normalizing Machine by Mushon Zer-Aviv , Dan Stavy and Eran Weissenstern, in which participants attempt to identify who looks normal from previous participants and a machine analyzes these decisions and adds them to its aggregated algorithmic image of normalcy, and So Kanno and Yang02 ‘s Asemic Languages, in which a robot invents and draws new characters that look as if they are important, but in reality are purely aesthetic, showing that a robot only knows what it has been taught.  \r\n<br><br>\r\nThere have been lots of writing around these subjects that I’ve read.  About decision making and choice, Thinking, Fast and Slow by Daniel Kahneman explores the two systems of the mind and their affects on our decision making and choices - this book revealed to me the massive amounts of decisions we make and are not aware of, and how they are influenced in different scenarios.  Algorithms to Live By by Tom Griffiths and Brian Christian explore how algorithms used by computers, can be applied to human decision making.  Essays in 25 Way of Looking at AI were hugely influential, including the Purpose Put into the Machine by Stuart Russel, which discusses purposes that humans put into machines and the failure when the machine’s objectives differ from our own.  Homo Deus by Yuval Harrari was the largest influence for me to dive into this thesis, in particular this quote:  \r\n<br><br>\r\n“Every day millions of people decide to grant their smartphone a bit more control over their lives…  In pursuit of health, happiness and power, humans will gradually change first one of their features and then another, and another, until they will \r\nno longer be human.”\r\n","thumbnail_image":{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/MainImageForSubmission-1024x682.png","title":"Stranger Walk Prompts","alt":"Stranger Walk Prompts","caption":""},"headshot_image":{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/thesis-12-169x300-1.jpg","title":"thesis-12-169x300","alt":"dan headshot","caption":""},"slide_show":[{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/thesis-8-1024x683.jpg","title":"thesis-8","alt":"portable prototype, with the coral and raspberry pi and camera. held in a hand.","caption":""},{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/PetThatDog-1024x576.jpg","title":"Pet That Dog","alt":"Pet that Dog","caption":""},{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/SelfDrivingHuman-1024x576.jpg","title":"say hello to that person","alt":"say hello to that person","caption":""},{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/thesis-7-1024x683.jpg","title":"thesis-7","alt":"camera on the back","caption":""},{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/fanny-1-1024x768.jpg","title":"fanny-1","alt":"the device inserted into a fanny pack, with a spy camera sticking out.","caption":""}],"tags":[{"name":"Critical Theory Art","slug":"critical-theory-art"},{"name":"Experiment","slug":"experiment"},{"name":"Machine Learning","slug":"machine-learning"},{"name":"Performance","slug":"performance"},{"name":"Speculation","slug":"speculation"}],"video_presentation_url":"https://vimeo.com/337308779","video_documentation_url":"https://vimeo.com/331468540/"},{"student_id":42,"student_name":"Daniel S Castano","student_slug":"daniel-s-castano","advisor_name":"Kathleen M Sullivan","title":"OSCAR: Create beautiful and responsive graphical user interfaces to control interactive installations","thesis_statement":"Imagine you are a maker who needs the client to trigger something with a touch screen. One button that controls a video, sound, light or a whole experience. If you are not a coder, the solution is to hire a developer who will make an entire app just to display a custom button with the logo or image that you want. OSCAR is a GUI creator to control interactive installations without coding, making this process faster, cheaper and scalable.","abstract":"With the rise of the capacitive screens market since 2007 due to the arrival of smartphones, many products, and their uses have changed. We are now used to press virtual buttons and slide virtual faders on touchscreens that control features on our computers, thermostats, media players, and more.<br><br>\r\nVirtual interfaces have increased in number in the last 10 years, evolving, and generating specialized concepts and roles we didn’t consider before, as UI/UX design, responsiveness, and front-development. Also, multiple tools have been designed to facilitate their design and implementation, spreading their use across industries.<br><br>\r\nMuseums, galleries, AV companies, and marketing agencies are implementing more multimedia installations to communicate concepts in engaging ways to their audiences. Many of these interactive installations have decided to rely on touchscreens to display and trigger their content, asking for the user to include their input to control the outcome and personalize the experience.\r\n<br><br>\r\nHowever, the process to create one of these interfaces of control is still complicated even if it is a simple button with an image, and not many people are able to implement it. Let’s take for example:\r\n<br>\r\nImagine you are part of an exhibit design company. You and your team are in charge of designing a piece to explain the states of matter to children. You have three animations explaining the concepts and just one screen to display the content. You want the kids to control what they watch and allow them to participate actively in the installation. Your team is able to manage the video clips but the problem comes when you have to design a friendly graphical interface for the children to trigger the videos they want to play. In the current industry, this interface would have to be outsourced no matter how simple it is, because it will require producers, designers, and developers.<br><br>\r\nOSCAR is intended to simplify the process of implementation of these interfaces for end users, in this case, children and visitors.","context_research":"Some examples of these touch interfaces and installations are:<br><br>\r\nZaha Hadar sales gallery by HUSH:<br>\r\nThe possible buyers are called to use an app to navigate the sales gallery and its products. The buyer or host triggers different videos and light on an architectural model to display what apartment they are visualizing.<br><br>\r\nColombia Pavilion at EXPO MILANO 2015 by Sonic Design:<br>\r\nThe pavilion used touch screens to trigger videos and control video games around the theme \"Thermal floors\"<br><br>\r\nPNC Beacon by AV&amp;C:<br>\r\nThe tower and its installation implemented an iPad with a beautiful interface to control and trigger the illumination cues on the interactive cylinder. This app was used just for the client who was in backstage taking care of the light environment.<br><br>\r\n\r\nNote that there are several systems involved in the experiences. There are sound, lighting, video systems and software elements that are talking and synchronizing between each other depending on the user interaction. The high-end industry uses specialized software and hardware to run their installations, meanwhile, the low-end and little exhibition producers rely on open source and rapid-prototyping tools.\r\n<br><br>\r\nSpecialized tools:<br>\r\nPandoras box / Desguise for Video management<br>\r\nAbleton Live for Audio control<br>\r\nDMX consoles for Light programming\r\n<br><br>\r\nOpen source tools:<br>\r\nProcessing/openFrameworks for visual programming<br>\r\nReaper for Audio Control<br>\r\nPure Data for visual programming<br><br>\r\n\r\nFortunately, most of these tools were designed to work with more applications at the same time and they are open to being controlled by well-documented protocols such as MIDI, OSC, KEYBOARD, Serial, TCP/UDP, and more.\r\n<br><br>\r\nThere are some companies and products designed to control this type of installations. TouchOSC, Lemur, OSC Open Stage Control are some of the tools you can find to implement interfaces of control over OSC to drive this exhibits. However, all these tools come with a built-in style that limits customization. On the other hand, most of them are not multiplatform and are not able to communicate with multiple devices at the same time. These features weren’t included because these tools were designed for another target: people interested in controlling an exhibit from the backstage.\r\n<br><br>\r\nHowever, if the exhibition needs to deliver control to the final users at the front stage, it has to implement beautiful and intuitive interfaces for them to control. This is the identified problem and opportunity of design.\r\n","thumbnail_image":{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/thumbnailImage-1-1024x576.png","title":"OSCAR thumbnail Image","alt":"OSCAR logo. Friendly jellyfish","caption":""},"headshot_image":{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/2H6A9781-768x512-1.jpg","title":"2H6A9781-768x512","alt":"daniel headshot","caption":""},"slide_show":[{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/OSCAR-fruit-1024x576.jpg","title":"OSCAR fruit","alt":"Interface designed with OSCAR","caption":""},{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/sending-OSC-to-TouchDesigner-1024x576.jpg","title":"Send OSC to TD","alt":"Sending OSC to TouchDesigner","caption":""},{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/EditMode-1024x500.jpg","title":"EditMode","alt":"OSCAR in edit mode","caption":""},{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/bananaTouch-1024x573.jpg","title":"live Setup","alt":"GUI designed by OSCAR in live setup","caption":"OSCAR is controlling MADMAPPER to trigger different videos with a simple press"},{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/workshop-1024x683.jpg","title":"OSCAR Workshop","alt":"Workshops about OSCAR and OSC communication","caption":""}],"tags":[{"name":"Business","slug":"business"},{"name":"Data","slug":"data"},{"name":"Design","slug":"design"},{"name":"Installation","slug":"installation"},{"name":"Networks","slug":"networks"},{"name":"Product Design","slug":"product-design"},{"name":"Software","slug":"software"},{"name":"Tool","slug":"tool"},{"name":"Visual","slug":"visual"}],"video_presentation_url":"https://vimeo.com/336825916","video_documentation_url":"https://trafalmejo.github.io/OSCar/"},{"student_id":38,"student_name":"Dominick Paul Chang","student_slug":"dominick-paul-chang","advisor_name":"Kathleen M Sullivan","title":"Linear Harmony","thesis_statement":"Linear Harmony is an interactive audiovisual installation that prompts exploration and discovery by connecting light, sound, and space through the mechanics of music theory. ","abstract":"Linear Harmony is an interactive audiovisual installation that aims to instill a sense of discovery, using simple forms of sound, light, and space. The piece is initially at rest, and requires input from the viewer in order for it to begin and continue progressing. No instruction is given, other than it is intended for a single user at a time. \r\n<br><br>\r\nInspired by choose-your-own-adventure stories and the concept of multverses, Linear Harmony assigns the twelve notes used in modern Western music to a “timeline”. Each timeline has slightly different rules for how it operates, based on different ideas in musical harmony. These rules dictate what pathways are available. \r\n<br><br>\r\nTwelve points of light will be projected onto the floor at equidistant points along a circle. Each of these points of light represent one of the twelve notes and will be the points of interaction for viewers. Haze will be used so the beams of light are visible in the air. Breaking the beam of light acts as a selection. \r\n<br><br>\r\nThe first selection made from the piece's resting states establishes that specific note as a tonal center and applies that timeline's rules. A four-note chord based on that note is played. Four speakers setup around the projected area allow for the sound to be spatialized as if it is coming from the selected point's direction. Pathways are then drawn to other points along the circle, highlighting other chords that make sense in a functional harmonic progression. This creates strong associations between the spatialization of the sound, the geometry of the light, and the physicality of the space. ","context_research":"I wanted to connect my work in music, lighting, visuals, and interactive installation into a strong conceptual piece that explores building complexity from simple structures and creating intuitive, discoverable interactions. \r\n<br><br>\r\nWhen I began working with lighting, I experimented with using projectors and haze to create aerial and beam effects, as opposed to projecting onto a screen or other surface. I found lighting artists such as Guillaume Marmin, Anthony McCall, and Joanie Lemercier, whose similar use of volumetric projections to create these immersive spaces inspired the aesthetics of this piece.  In terms of conceptual design and sound design, I was inspired by Ryoji Ikeda and Tristan Perich, who use simple components to build complex and beautiful systems.\r\n<br><br>\r\nI wanted to couple this idea of light sculpture with a sonic element, in such a way that the viewer could manipulate and influence the piece. By using concepts in music theory as rules for the piece, I could create a series of interactions based on these guidelines. The visual layout for the notes is the circle of fifths, which is a common concept in music theory. This allowed me to easily create associations between the visual, sonic, and interactive elements of the piece.","thumbnail_image":{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/Thesis-Cover-1024x576.jpg","title":"Thesis-Cover","alt":"Thesis Cover","caption":""},"headshot_image":{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/05/admin-ajax.php_.jpeg","title":"admin-ajax.php","alt":"Dom and Ellena","caption":""},"slide_show":[{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/Resting-State.jpg","title":"Resting State","alt":"Resting State","caption":""},{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/Kat-Beam-1024x683.jpg","title":"Kat-Beam","alt":"Kat in the beams","caption":""},{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/Andy-Beam-683x1024.jpg","title":"Andy-Beam","alt":"Andy Beam","caption":""},{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/Shiny-Sequins-1024x683.jpg","title":"Shiny-Sequins","alt":"For the children","caption":""},{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/Hand-Beam-1024x576.jpg","title":"Hand Beam","alt":"Hand Beam","caption":""}],"tags":[{"name":"Art","slug":"art"},{"name":"Experiment","slug":"experiment"},{"name":"Installation","slug":"installation"},{"name":"Music","slug":"music"},{"name":"Play/Games","slug":"play-games"},{"name":"Sculpture","slug":"sculpture"},{"name":"Sound","slug":"sound"},{"name":"Spatial Audio","slug":"spatial-audio"},{"name":"Visual","slug":"visual"}],"video_presentation_url":"https://vimeo.com/336825868","video_documentation_url":"https://youtu.be/NorhZVCQvh0"},{"student_id":40,"student_name":"Dongphil Yoo","student_slug":"dongphil-yoo","advisor_name":"Kathleen Stevens Wilson","title":"Redrum: Collaborative Human-AI Toy Design","thesis_statement":"Redrum explores the possibilities of a Human–AI collaborative effort to create an action figure toy. Machine learning techniques have been used to generate a backstory and inspire the visual design of a series of small, 4-inch, collectible toys.","abstract":"How do we incentivize creativity with cutting-edge technology? What creates an environment that optimizes creative output? What if AI could be used to fuel creativity? Since we have entered the golden age of AI, it seems worthwhile to focus on determining how to work together with AI, instead of just focusing on whether AI will overtake us. In my project, Redrum, I have explored the potential for working collaboratively on creative projects, human and computer together, building on the strengths of each.<br><br>\r\n\r\nAs an indie toymaker, I usually start the concept development process with lengthy background research in order to write a short backstory about each action figure and start to envision the look. However, this process often leads me to feel my creative aptitude is impaired because the cognitive load quickly becomes overwhelmed. As a result, I am less likely to seek out novelty and imagination in the creative process. In order to surmount this, I decided to build a creativity support system incorporating machine learning technology into the early stage of design.<br><br>\r\n\r\nThe computer, with its amazing capability to handle repetitive and deterministic activities, can generate endless story passages based on the input of enormous amounts of text data. Since my goal was to create horror action figures, the text I used for input was primarily criminal records, fictional narratives, movie scripts, etc. Together, the computer and I summarized and revised the outputs repeatedly in a tight feedback loop to obtain backstories, many nonsensical, some quite whimsical. Ultimately, I, as the human collaborator, polished the final backstory and used it for the next step – to design and build my action figures.<br><br>\r\n\r\nI hope future collaboration with AI will mentally liberate me to engage in creative pursuits and will amplify my creative potential in ever more productive ways.","context_research":"I first looked at previous creative projects that have used artificial intelligence in the process of art and design, art toy design in particular. I found the New York-based artist Adam Ellis who has created exceptional cartoon characters with machine learning techniques. His working process is similar to mine in terms of making a character from an AI-generated story. I then got down to using several neural network models for text generation.<br><br>\r\n\r\nMore specifically, I started reading the latest machine learning papers to try to better understand the concept behind each model I tried to use and the practical implementations. The main consideration in terms of the AI part was making the text generator as simple and fast as possible with decent text generation models. I focused on acquiring functionality such as summarization, prediction, and determining the sentimental similarity.<br><br>\r\n\r\nLast but not least, for the toy design, I read a couple of books about indie toy design. These books describe the process of toy design and production in detail and gave me a general sense of toy making. Furthermore, I interviewed toy experts through social media, and I got some know-how and insightful feedback - use a putty mold for the small part, a story to tell is the key in toy bootlegging subculture. I chose resin as a default material because it is used conventionally and is easy to deal with as well. I also settled on a 4-inch sized toy since that size is highly collectible in the community.","thumbnail_image":{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/thumbnail-13-1024x576.jpg","title":"thumbnail","alt":"thumbnail image","caption":""},"headshot_image":{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/me-768x432-1.jpg","title":"me-768x432","alt":"dongphil headshot","caption":""},"slide_show":[{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/slide1-1024x576.jpg","title":"slide1","alt":"slide show image","caption":""},{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/slide2-2-1024x576.jpg","title":"slide2","alt":"slide show image","caption":""},{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/slide3-3-1024x576.jpg","title":"slide3","alt":"slide show image","caption":""},{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/slide4-3-1024x576.jpg","title":"slide4","alt":"slide show image","caption":""},{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/slide5-2-1024x576.jpg","title":"slide5","alt":"slide show image","caption":""}],"tags":[{"name":"Art","slug":"art"},{"name":"Culture","slug":"culture"},{"name":"Machine Learning","slug":"machine-learning"},{"name":"Narrative/Storytelling","slug":"narrative-storytelling"},{"name":"Product Design","slug":"product-design"},{"name":"Sculpture","slug":"sculpture"},{"name":"Toy","slug":"toy"}],"video_presentation_url":"https://vimeo.com/336836340","video_documentation_url":"https://vimeo.com/331474024"},{"student_id":44,"student_name":"Elizabeth Ferguson","student_slug":"elizabeth-ferguson","advisor_name":"Kathleen Stevens Wilson","title":"SpeakOut","thesis_statement":"SpeakOut is a protest tool that uses the devices we already have in our pockets. One person speaks into their smartphone, and others can receive and amplify that live audio over a wider space. SpeakOut is a web app that runs in the browser, with no need to download a native app.","abstract":"Origin Story<br><br>\r\nSpeakOut is an answer to a question I asked a year ago. I was at a protest where a group of us could not hear the speeches being given to the crowd.  I wondered: how might protesters amplify speeches themselves with the devices we already have, and in the process hear better and be more empowered? <br><br>\r\n\r\nImmediate Use Case<br><br>\r\nI built SpeakOut to be tested in a tight use case with Transportation Alternatives, a New York City advocacy group for safer streets for cyclists, pedestrians and public transit.  \r\n<br><br>\r\nOn a rainy Sunday in March, TransAlt members and I tested SpeakOut at a rally to #FinishQueensBlvd in Queens. In a crowd of 50, people gave speeches into a smartphone on a mic stand that streamed live audio using the SpeakOut web app in the browser. Slowly, a light echo of amplification accumulated in the air as five to ten people chose to amplify that live audio with their smartphones, surrounding the crowd in the message of the speakers. \r\n<br><br>\r\nNext Steps<br><br>\r\nI am now in a place where I wonder what role SpeakOut can play in the organization of social movements, and what my perspective is on ethical or moral technology. \r\n<br><br>\r\nCan a web app similar to SpeakOut give people options to take action after a protest, therefore facilitating the growth and persistence of long-term group structures?<br><br>\r\n\r\nWhat does it mean to build ethical requirements into design, so that there is a coherence between the project’s goals, chosen materials, affordances, and consequences in the world? <br><br>\r\n\r\nIs design even a strong enough tool on its own, or what other frameworks, such as corporate structures, legislation and policy, need to be in place to limit harm and protect rights?","context_research":"As I conducted design research and read relevant books and articles, I learned two major things that influenced SpeakOut’s design and my thoughts on its potential impact.<br><br>\r\n\r\nDesign Research<br><br>\r\nFirst, SpeakOut’s interaction design needed to match the temporary group structure of the rally, and not necessarily the more flat structure of the group running it. For example, rallies are strategized events with pre-decided roles, physical placement and coordination with press and police. Understandably, my partners at TransAlt did not want listeners to see the speak button to make it harder for another well-intentioned or rogue broadcast to disrupt plans. They also did not want to share out the listen page’s URL until the event began, so that people attended the rally and did not stay at home to listen remotely. These conversations shaped the design of the web app.<br><br>\r\n\r\nContext Research<br><br>\r\nSecond, my readings reminded me that the U.S. constitution protects citizen activists’ rights to public assembly and free speech. Yet digital actions can still be targeted by surveillance deployed by powerholders or adversaries. The most useful reading was Zeynep Tufekci’s book Twitter and Tear Gas about technology and social movements. As Tufekci writes: “People make technology, but technology also has structuring power.” What structuring power does SpeakOut’s technology have on people who use it, and what unintended consequences might there be?<br><br>\r\n\r\nThis question has driven me to seek out examples of frameworks for ethical technology, potentially build my own, and begin to test the implementation of them.","thumbnail_image":{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/GroupPhoto3-1024x576.jpg","title":"Demo of SpeakOut at Transportation Alternatives Rally","alt":"Demo of SpeakOut at Transportation Alternatives Rally","caption":"Demo of SpeakOut at Transportation Alternatives Rally"},"headshot_image":{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/ProfilePic69ratio-768x432-1.jpg","title":"ProfilePic69ratio-768x432","alt":"elizabeth headshot","caption":""},"slide_show":[{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/speakouthomepage2-2-1024x576.png","title":"SpeakOut web app","alt":"Picture of SpeakOut web app","caption":"SpeakOut"},{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/DemoTransAltRally23ratio-1024x683.jpg","title":"Demo of SpeakOut at TransAlt Rally","alt":"A crowd of people at a rally test SpeakOut","caption":"Demo of SpeakOut at TransAlt Rally"},{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/UserTestingJuanRestrepo23ratio-1024x683.jpg","title":"UserTestingJuanRestrepo23ratio","alt":"User Testing with TransAlt organizer, Juan Restrepo","caption":"User Testing with TransAlt organizer, Juan Restrepo"},{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/UserTestingTransAltMeeting23ratio-1024x682.jpg","title":"UserTestingTransAltMeeting23ratio","alt":"User Testing at TransAlt Queens Committee Meeting","caption":"User Testing at TransAlt Queens Committee Meeting"}],"tags":[{"name":"Mobile","slug":"mobile"},{"name":"Networks","slug":"networks"},{"name":"Privacy/Security","slug":"privacy-security"},{"name":"Product Design","slug":"product-design"},{"name":"Social Good/Activism","slug":"social-good-activism"}],"video_presentation_url":"https://vimeo.com/336836393","video_documentation_url":"https://www.youtube.com/watch?v=IU4wfKYcPqQ&t="},{"student_id":150,"student_name":"Ella Chung","student_slug":"ella-chung","advisor_name":"Gabriel Barcia-Colombo","title":"Breathe We Live","thesis_statement":"Breathe We Live is an interactive meditation experience that awakens the reflection of the human relationship with nature through breathing.","abstract":"Breathe We Live is an interactive installation that presents the invisible connection between human and natural environment through shedding lights on the activity of breathing. The invisible exchange of oxygen is brought into the projection of the natural world and human connection. The breathing sensors track the user in real time of their breathing frequency, and the interaction with the plants will help the user to meditate and slow down their breathing. The goal of this installation is to encourage us to rethink our connection and responsibility towards nature.\r\n<br><br>\r\nThe installation invites people to pay close attention to their body through a session of breathing meditation practice. I created a meditative space, with embedded interactive components, that enables intimate experience between viewers and the natural environment. Only one or two people can enter the space at a time. The installation uses human breath as an input to produce corresponding visuals in real-time. A Kinect camera mounted inside the space will detect the user’s movement to provide a false feedback loop for breathing, when the user is moving and breathing too fast, the visual and music will slow down to give the user feedback to breathe slower. \r\n<br><br>\r\nAccording to my research about mediation, walking through nature is one of the best ways to relieve stress. I wanted to create a meditative space for people to understand their breathing activity and their close relationship to nature. I hope the experience helps the users to reflect their relationship with the current state of nature. \r\n","context_research":"Trees are made of human breath. The tree is recording a history of us. The tree is us. When people work with trees, they will carefully consider every cut and work with each individual tree’s unique shape and growth pattern. Can we tell a tree contains our breath patterns and human history? This makes me think deeper about the relationship between human breath and nature.\r\n<br><br>\r\nOne of the projects that I was inspired by is Vicious Circular Breathing, an art installation by Rafael Lozano-Hemmer. Users breathe the air that was previously breathed by participants who previously visited the same space. The installation consists of a glass room filled with carbon dioxide and oxygen sensors and paper bags hanging from respiration tubes that visualizes the viewers’ breathing patterns. The demonstration of breathing makes the interactive process more dynamic than only showing the results of processed data. \r\n<br><br>\r\nMy installation creates an environment for communal meditation experience between human and nature. The viewers are invited to blow their breath into the sensor while meditating and listening to the sound of nature. The plants within the visual system react according to the participant’s breathing cycle. \r\n<br><br>\r\nDuring user testing sessions I conducted over the design process, participants found the meditation experience to be soothing, but they wanted the space to be darker and more immersive. Some participants wanted physical interaction components along with the visuals. After the user testing, I made the following changes in my design. I projected the visuals closer to the plants and the human to show a clearer connection between the two. I found that the placement of the microphone in my previous design was too far from the users and the users had to breathe harder than they normally do. To fix the problem, I replaced the microphone with wind sensors, which is more sensitive, and placed them right next to the plants. \r\n","thumbnail_image":{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/Thumbnail-Image-2-1024x576.jpg","title":"Thumbnail Image","alt":"Breath We Live Installation Thumbnail Image","caption":""},"headshot_image":{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/My-Photo-768x432-1.jpg","title":"My-Photo-768x432","alt":"ella headshot","caption":""},"slide_show":[{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/Main-Image-1-1-1024x576.jpg","title":"Main Image 1","alt":"Breath We Live Installation Main Image","caption":""},{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/Main-Image-1-copy-1024x576.jpg","title":"Main Image 2","alt":"Breath We Live Installation Main Image","caption":""},{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/Main-Image-1-copy-2-1-1024x576.jpg","title":"Main Image 1 copy 2","alt":"Breath We Live Installation Thumbnail Image","caption":""},{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/Main-Image-1-copy-2-2-1024x576.jpg","title":"Main Image 1 copy 2","alt":"Breath We Live Installation Thumbnail Image","caption":""}],"tags":[{"name":"Design","slug":"design"},{"name":"Experiment","slug":"experiment"},{"name":"Meditation","slug":"meditation"},{"name":"Projection Mapping","slug":"projection-mapping"},{"name":"VR/AR/Immersive","slug":"vr-ar-immersive"}],"video_presentation_url":"https://vimeo.com/337309277","video_documentation_url":"https://vimeo.com/335274809"},{"student_id":45,"student_name":"Ellen Nickles","student_slug":"ellen-nickles","advisor_name":"Gabriel Barcia-Colombo","title":"Gotcha! Sincere Competitive Chitchat","thesis_statement":"Ever wanted to win a conversation? Here's a game to keep score!","abstract":"This is a party game in which players try to sneak secret words into a discussion without getting caught. It’s like an icebreaker but with a competitive twist: you win points by hiding specific words in your responses or by catching your fellow opponents in the act.  \r\n<br><br>\r\nThe game challenges you to productively converse with others--to listen and to contribute--all the while planning how to surreptitiously work in your words. But how can you talk naturally if you’re suspicious of others’ word choices and vice versa? Sneakiness and constant questioning defies the implicit rules of cooperation in a conversation. To win you must manage these opposing goals and conceal your words within the context of constructively moving the dialogue forward. \r\n","context_research":"There are many ways to play! In one version of the game, the round begins with a prompt to direct the conversation: players choose from either a hypothetical, a debate topic, or a personal experience question. Each player then draws one card with a secret word to keep until they use it in a response. Snuck words are placed face down within a certain amount of time after they are spoken to indicate a play. Players call gotcha on each other by naming suspect words out loud. Don’t get caught or correctly guess others’ words to win points.\r\n<br><br>\r\nTo develop the game, I researched traditional icebreakers as well as word games from the mid-1800s to the present that incorporate guessing, bluffing, narrative, and role playing. It’s a little like Taboo in that players guess words and gain points from successful attempts. It also overlaps with Balderdash considering that players’ contributions need to sound convincing especially if they were completely fabricated to slip in words. Unlike both of those games, however, this one finds structure in the familiar back and forth of everyday dialogue. \r\n<br><br>\r\nThe mechanics and content emerged through iterative design and multiple playtests with a range of people including old friends, new pals, acquaintances, complete strangers, other game developers, avid game players, folks not particularly interested in playing, repeat players of the game, members of the same family, high school students, retirees, and everyone in between, and in a variety of settings such as game developer events, classrooms, homes, and bars. Through this process, I discovered that this game appeals to several audiences for different reasons: family and friends play to enjoy their company at home or at a social venue, party guests play this game to get to know each other in unexpected ways, and native and non-native English-language learners play to practice their vocabulary at home or at school.\r\n<br><br>\r\nThis game is for all the many talented storytellers in my life. Originally inspired by Word Sneak on The Tonight Show Starring Jimmy Fallon, I created this version for us to share old stories, invent new ones, and laugh a lot along the way. ","thumbnail_image":{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/3_image_1280_720_thumbnail-1024x576.jpg","title":"3_image_1280_720_thumbnail","alt":"gotcha game!","caption":""},"headshot_image":{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/thesisJournalApr2019-199x300-1.jpg","title":"thesisJournalApr2019-199x300","alt":"ellen headshot","caption":""},"slide_show":[{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/3_image_1080_1920_slideshow-1024x576.jpg","title":"3_image_1080_1920_slideshow","alt":"gotcha! sincere competitive chitcat","caption":""}],"tags":[{"name":"Design","slug":"design"},{"name":"Education","slug":"education"},{"name":"Narrative/Storytelling","slug":"narrative-storytelling"},{"name":"Play/Games","slug":"play-games"}],"video_presentation_url":"https://vimeo.com/337308893","video_documentation_url":""},{"student_id":47,"student_name":"Erin Cooney","student_slug":"erin-cooney","advisor_name":"Stefani Bardin","title":"Podscape","thesis_statement":"“Podscape” is a story/processing network, consisting of a system of pods that represent stories from plants, animals, humans, fungus and things, set in the Capital/Anthropocene. They are a collection from humans that were co-created with nonhumans via a workshop ritual.  The co-creation between human and nonhuman manifests in a machine-learning model trained on extinct bird sounds. All these elements contribute to an audio-sensory and interactive installation.","abstract":"             Podscape co-creators participate in a workshop ritual “Embodied Storytelling/’Nature’ Portal”, that generates pod stories and simultaneously creates the world communally. Participants create stories through somatic exercises that attune participants to non-dominant forms of sensing/information receiving from nonhumans, accompanied with writing exercises. The workshop looks at the binary of fiction &amp; non-fiction, natureculture divide, animism, perspectivism, nonhuman communication and vital materiality. Additionally, the ritual is a reproducible experience that can exist separately from the podscape. \r\n<br><br>\r\n            I’m also training a machine learning model trained on collected extinct bird recordings using WaveGAN. WaveGAN is a machine learning algorithm which learns to generate raw audio waveforms. This is a celebrating their existence along with mourning their extinction. The model explores the queering of dead and living, a liminal chimera of species that normally wouldn’t interact in close physical proximity. It interacts with something “dead” regeneratively. \r\n","context_research":"           My thesis is situated in art and spiritual praxis, and research theorizing our current state in the Anthropo/Capitalocene, a vast and varied experience. This project examines multispecies worldings and explores perceived binaries of: nature &amp; culture, human &amp; nonhuman, organism &amp; machine, fiction &amp; non-fiction speaking to the western experience I grew up in, and the body as non-linear archive.<br><br>\r\nMy research includes authors whose work explores the decentering of human exceptionalism, with an emphasis on multi-species entanglements and re-thinkings of the hyper-segmentation of human and nonhumans inherent in capitalism. Although some of my research includes thinkers that work within the institution of academia and therefore participate in a western legacy, their inquiries engage with decolonization, namely, Donna Haraway, Kim TallBear, Anna Tsing, Karen Barad and Jane Bennett amongst many. <br><br>\r\n         I’m influenced by speculative fiction for its ability to hold space for non-dominant voices. I see the workshop as a potential compositional healing vehicle via tuning into the body using various somatic exercises. The energetic temporality of the body is a nonlinear archive. Aside from the linear aging process, experiences of past and future are compressed into the present that can be accessed in various ways, similar to temporalities of stories. Inspiring work in these veins are: Octavia Butler, Ursula K Le Guin, CAConrad, Alexis Pauline Gumbs, Eliza Swann, Laura Stinger, Edgar Fabian Frias, Iele Paloumpis, Pauline Oliveros, Ruth Zaporah, PsychoMagic and work I’ve done with various healers.\r\n","thumbnail_image":{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/podmap-bare-1024x576.jpg","title":"podmap bare","alt":"pod illustration","caption":""},"headshot_image":{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/admin-ajax.jpeg","title":"admin-ajax","alt":"erin headshot","caption":""},"slide_show":[{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/Untitled-3-1024x576.jpg","title":"Untitled-3","alt":"workshop","caption":""},{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/workshop1-1024x576.jpg","title":"workshop1","alt":"workshop photo","caption":""},{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/workshop2-1024x576.jpg","title":"workshop2","alt":"workshop photo","caption":""},{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/molly-1024x576.jpg","title":"molly","alt":"installation","caption":""},{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/close-up-1024x576.jpg","title":"close up","alt":"materials","caption":""}],"tags":[{"name":"Art","slug":"art"},{"name":"Machine Learning","slug":"machine-learning"},{"name":"Narrative/Storytelling","slug":"narrative-storytelling"},{"name":"social practice","slug":"social-practice"},{"name":"Speculation","slug":"speculation"}],"video_presentation_url":"https://vimeo.com/336814705","video_documentation_url":"https://vimeo.com/335303739"},{"student_id":141,"student_name":"Eva Yipeng Chen","student_slug":"eva-yipeng-chen","advisor_name":"Adaora Udoji","title":"The Code of the Cloisters","thesis_statement":"Imagine you are Dr. Robert Langdon from the Da Vinci Code, and having a new adventure in an epic medieval museum in New York City —— Not in VR, but the real world.\r\n","abstract":"The Code of the Cloisters is a physical immersive experience that allows you to explore the MET Cloisters museum in a brand new way. This project will allow visitors to act as detectives to collect clues and solve puzzles in the museum along with the help of an antique book and an AR app. <br><br>\r\n\r\nThe book is originally from the 18th century, it includes several stories and puzzles. All of them seem relative to the well- known exhibit —— the Unicorn Tapestries. Visitors will have to go to the Met Cloisters Museum where the tapestries are showed and try to figure out the puzzles with the help of a modern tool, an AR app, in this medieval style building. \r\n<br><br>\r\nThrough this process, a real connection between visitors and the exhibits will be built. People won’t feel the exhibits from thousands of years ago are too far to be reached out anymore. Visitors will be able to learn and to enjoy in this AR game.\r\n","context_research":"This idea comes from tons of my sorrowful museum visiting experience. <br><br>\r\n\r\nWhen I was in the Louvre, the Vatican Museum, the Palace Museum or the Metropolitan Museum, the magnificence of human civilization always attracted me. But when I wanted to learn more about their background history, it was not that easy. The audio guide always introduced every interesting exhibit in a boring way, and unfortunately, I got bored pretty easily. <br><br>\r\n\r\nI know all of us had at least once been hit by that sorrowfulness. \r\n<br><br>\r\nAfter that, I read Dan Brown’s novel. Dr. Robert Langdon, the main character in his novels, is a professor of art history and symbolism. He took adventures in many famous museums and tells a lot of background stories of the museum and exhibits in a very exciting way. I think I learned more about Vatican City from the fiction Angels and Demons than from the City itself even though I have personally been there. I realize the magic of storytelling from this experience. People are eager to learn, exhibits are marvelous —— we just need a story and technology to bridge the gap between human and exhibits. \r\n","thumbnail_image":{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/thumbnailImage-1024x576.png","title":"thumbnailImage","alt":"thumbnailImage","caption":""},"headshot_image":{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/IMG_3163-768x512-1.jpg","title":"IMG_3163-768x512","alt":"headshot","caption":""},"slide_show":[{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/UI1-1024x576.jpg","title":"UI1","alt":"ui1","caption":""},{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/visualGuide-1024x576.jpg","title":"visualGuide","alt":"visualGuide","caption":""},{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/prototype2-1024x576.png","title":"prototype2","alt":"ui2","caption":""},{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/userflow-1024x522.jpg","title":"userflow","alt":"userflow","caption":""}],"tags":[{"name":"History","slug":"history"},{"name":"Mobile","slug":"mobile"},{"name":"Play/Games","slug":"play-games"},{"name":"UX","slug":"ux"},{"name":"VR/AR/Immersive","slug":"vr-ar-immersive"}],"video_presentation_url":"https://vimeo.com/336822070","video_documentation_url":"https://youtu.be/JekvUzLytgE"},{"student_id":48,"student_name":"Fanni Katalin Fazakas","student_slug":"fanni-katalin-fazakas","advisor_name":"Adaora Udoji","title":"Jamie &amp; Jamie","thesis_statement":"“Jamie &amp; Jamie” is an exploration of gender dynamics through transforming a traditional shooting game in VR into a mission to complete a domestic task. Two players are armed with an iron against a flying barrage of dirty clothes and must work together to get the house in order. \r\n","abstract":"“Jamie &amp; Jamie” is a whimsical, multiplayer VR game based on stories collected from a wide range of New Yorkers about their personal experiences of gender roles, pay gap and domestic work. The game invites people of all genders to do laundry together in a bizarre virtual setting. Subverting the typical shooting game format, participants are instead armed with an iron as a “gun”, and clothes as their “targets”. The game itself is rigged to allocate more points for one of the players, ultimately encouraging collaboration in order to complete the challenge. <br><br>\r\n\r\nI grew up in Budapest, Hungary where everyone I know in their 20’s, including myself, is married. I am, by Hungarian standards, considered quite lucky for having a “progressive” husband who shares household duties equally with me. In fact, my childhood was also unique in that I grew up in a family where my mother worked and my father took on the bulk of homemaking and childcare duties. Yet, even in the privilege of my own relatively equal marriage and upbringing, the issues around feminism and gender dynamics is a difficult conversation to be had.<br><br>\r\n\r\nI decided to focus on domestic chores, and specifically the task of ironing because to me, it is a concrete representation of gender dynamics within relationships and behind closed doors. Through conducting interviews in Washington Square Park with over 50 people, I realized that the topic of ironing naturally brought into question gender roles around the task. \r\n\r\nI investigated how and which technology would facilitate an experience that might encourage participation across all genders. Since video games are typically a familiar format for male players, I juxtaposed the medium with a historically feminine task in order to bring up a heavy subject in a playful way. <br><br>\r\n\r\nThrough the multiplayer experience, I hope to spark inclusive conversations that affect both Eastern Europeans and New Yorkers alike and encourage participants to reconsider their own association and approach to everyday responsibilities.\r\n","context_research":"As part of my research, I investigated how feminist artists used their art practice to draw attention to the problems women were facing in their times. The idea behind the “Manifesto for Maintenance Art” by Mierle Laderman Ukeles heavily affected the series of experiments I was doing in public spaces. Similarly to Ukeles, I was bringing daily housework to the streets while I was wearing a VR headset. After the performance, I invited people to join me and share their own experiences, which later served as a base of the VR game. Tom Finkelpearl’s book - “What We Made: Conversations on Art and Social Cooperation” - gave me a solid understanding of the history of collaborative art practice, which helped me integrate my collection of interviews into the game.\r\nDesigning the experience in a way that doesn’t make men feel attacked or blamed was very important for me. I started this part of the research by looking at the HeForShe campaign where men are not only treated as part of the conversation on gender equality but as the solution itself. Following this approach, I built up the structure of the game so that while it starts as a competition between the two players, they can win only by collectively coming up with a solution. \r\nAdditionally, I wanted to make the experience accessible to the general public. A majority of VR experiences are only within reach for festival-going audiences. I was inspired by the format of “Tidal Wave” by MarshMallowLaserFeast, which is a VR installation located outdoors. Since my interviews and content were sourced on the streets of New York, I am showcasing the final project at its origin, in Washington Square Park. I’m in contact with each person I interviewed, as they will receive personal invites to the “premiere”. \r\n","thumbnail_image":{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/thesis_thumbnail-1024x576.jpg","title":"Jamie &amp; Jamie the fight of the irons","alt":"Jamie & Jamie the fight of the irons","caption":""},"headshot_image":{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/thesis_profile_fannifazakas-768x432-1.jpg","title":"thesis_profile_fannifazakas-768x432","alt":"fanni headshot","caption":""},"slide_show":[{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/thesis_slide1-1024x576.jpg","title":"Unreal Engine - Virtual Laundry Room","alt":"3D Environment - Laundry Room","caption":""},{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/thesis_slide_new1small-1024x576.jpg","title":"Jamie &amp; Jamie - controller settings and interaction design","alt":"physical and virtual settings. controllers and their mappings in vr","caption":""},{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/thesis_slide5-1024x576.jpg","title":"Jamie &amp; Jamie Custom Made Oculus Controller","alt":"Jamie & Jamie Custom Made Oculus Controller built into an actual iron","caption":""},{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/thesis_slide_new2-1024x576.jpg","title":"Outdoor VR session","alt":"All together 32 people tried out my Thesis on Washington Square Park.","caption":""},{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/thesis_slide_new3-1024x576.jpg","title":"ironing board with two Oculus Rifts set up on it","alt":"ironing board with two Oculus Rifts set up on it","caption":""}],"tags":[{"name":"Justice","slug":"justice"},{"name":"Narrative/Storytelling","slug":"narrative-storytelling"},{"name":"Performance","slug":"performance"},{"name":"social practice","slug":"social-practice"},{"name":"VR/AR/Immersive","slug":"vr-ar-immersive"}],"video_presentation_url":"https://vimeo.com/336814726","video_documentation_url":"https://vimeo.com/331455667"},{"student_id":51,"student_name":"Gabriel Brasil","student_slug":"gabriel-brasil","advisor_name":"Adaora Udoji","title":"HyperCarnaval","thesis_statement":"HyperCarnaval is a virtual reality experience that imagines an alternative future for our digital selves: one inspired by the rhythms, colors, and spirit of Carnaval.","abstract":"HyperCarnaval chronicles how I've found my artistic voice by creating a VR studio while having Carnaval as my inspiration. It started with the question \"where does creativity happen\" and \"what makes for an inspiring environment\" in VR and grew up naturally into a journey of self-discovery. As I created the tools to immerse myself on my own creations, I've found parallels between the embodiment of VR and the roots of Carnaval culture.\r\n<br><br>\r\nAs my collection of references and 3D creations grew, I've felt that browsing through file icons and static images on a 2D interface were not giving me a full picture of my research and weren't reflecting the multi-media VR nature of these objects. I was looking for ways to be with these characters; dance and sing with them; be inspired by my virtual environments. Then it hit me: As the project developed, I figured out that what I looking for was a Carnaval party.<br><br>\r\nThe culture of my home country Brazil was starting to resonate with the original research on \"what makes for a truly creative environment\" until I realized that what I was creating was a Carnaval Party with my own identity.  My design choices were reflecting urges in my understanding of my own culture and my interest in virtual reality; making parallels between Carnaval and Virtuality more apparent as I became immersed in my own research on immersion itself. <br><br>\r\nCarnaval is a social virtual environment that happens on specific moments where everybody can become avatars of their own creation. It is a hand-crafted reality shared by a community under the rhythm of drums and dance. The realization that I had a \"Virtual Reality\" system already embedded deep in my cultural identity was a revelation that is still growing on me; I've become the answer to my own question on the inspiring power of VR.  By sharing this personal experience I look forward to inspiring an alternative vision for VR as a path toward self-discovery and empowered creativity. A shared virtual Carnaval party: a HyperCarnaval","context_research":"My research had two main subjects: The first was user experience in creative interfaces for VR. The second was the Brazilian carnaval culture.\r\n<br><br>\r\nThe interface research concentrated mostly on figuring out the pipeline necessary to turn assets created in VR tools back into interactive VR characters or environments. During the \"100 days of making\" class I started a \"100 days of VR\" project. For months I've worked on becoming proficient on using Oculus Medium and Quill, two of the most popular and flashed out VR art tools available and generated dozens of original 3D content. The process of exporting my VR creations demanded the use of traditional 3D modeling programs (Maya) and game development engines (Unity3D), thus generating insights on the different philosophies behind established 2D user experience and the emerging 3D immersive work environments.\r\n<br><br>\r\nThe cultural research coalesced into Carnaval culture, more specifically artists and aesthetics that interfaced with technology and used its roots to imagine an alternative vision of the future. \r\nOne of the main references was the profoundly influential Chico Science and his band Nação Zumbi. His \"AfroCyberdelic\" vision of the future is both grim and full of colors and inspired a tropical tomorrow unbounded by the often harsh and totalitarian vision of the future traditionally preached in Latin America.<br><br>\r\nBoth research paths coalesced when combined with dance and music. I used motion capture equipment to record my spouse and I dancing different Brazilian styles and added them to the characters and environments from the interface research. \r\n","thumbnail_image":{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/Artboard-2-1-1024x576.jpg","title":"HiperCarnaval Project","alt":"HiperCarnaval Project","caption":"HiperCarnaval Project"},"headshot_image":{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/Gabriel_Portrait_April2019.jpg","title":"Gabriel_Portrait_April2019","alt":"Gabriel_Portrait_April2019","caption":""},"slide_show":[{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/Artboard-4-1024x576.jpg","title":"HiperCarnaval Slide Show 1","alt":"HiperCarnaval Slide Show 1","caption":"HiperCarnaval Slide Show 1"},{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/Artboard-3-1024x576.jpg","title":"HiperCarnaval Slide Show 2","alt":"HiperCarnaval Slide Show 2","caption":"HiperCarnaval Slide Show 2"},{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/screen_2049x994_2019-05-09_17-31-25-1024x497.jpg","title":"HyperCarnaval","alt":"HyperCarnaval Monstera Deliciosa","caption":"HyperCarnaval Character \"Monstera Deliciosa\" dancing with open arms"},{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/Artboard-6-1024x576.jpg","title":"HiperCarnaval Slide Show 4","alt":"HyperCarnaval Character dancing on top of a mountain while the moor shines behind him.","caption":"HiperCarnaval Slide Show 4"},{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/Artboard-7-1024x576.jpg","title":"HiperCarnaval Slide Show 5","alt":"HiperCarnaval Slide Show 5","caption":"HiperCarnaval Slide Show 5"}],"tags":[{"name":"3D","slug":"3d"},{"name":"Art","slug":"art"},{"name":"Culture","slug":"culture"},{"name":"Identity","slug":"identity"},{"name":"VR/AR/Immersive","slug":"vr-ar-immersive"}],"video_presentation_url":"https://vimeo.com/336708075","video_documentation_url":"https://vimeo.com/331464075"},{"student_id":53,"student_name":"Hadar Ben-Tzur","student_slug":"hadar-ben-tzur","advisor_name":"Kathleen Stevens Wilson","title":"1968 WSQP – an augmented reality app","thesis_statement":"1968 WSQP, an augmented reality app, invites Washington Square Park visitors to follow the footsteps of Wallace and June – two young activists meeting in the park on a hot spring day in 1968. Download the app for a cinematic experience, which binds past and present into a single moment in space.","abstract":"The fight for civil rights, protests against the Vietnam war, assassinations, the women's rights movement – 1968 was undoubtedly a pivotal year in history, and a unique point in time in downtown Manhattan, NYC. 1968 WSQP, a geo-located augmented reality app, invites Washington Square Park visitors to follow the footsteps of Wallace and June – two young activists meeting in the park on a hot spring day in 1968. In order to bind story and space, we have divided Washington Square Park into the east side and the west side – each side triggers a different character to follow all the way to the meeting point under the arch. Download the app, and Join as Wallace tries to deal with the fact that he’s been drafted, or free-spirit June as she rushes through the park to meet Wallace.","context_research":"Augmented reality as an immersive storytelling medium is almost tailor-made for historical fiction – music, spoken text, periodical videos and sound, geolocation, visual effects, image targets, illustrations, press clippings, interviews, and much more. 1968 WSQP App tells the story of 1968 and provides the necessary historical context to the same challenges we face as a society today. Through the story of Wallace and June, we introduce our audience to same-aged social activists which once stood and waved protest signs at the same place, and often — on behalf of the same values. 1968 WSQP was developed in collaboration with Ilana Bonder. Thanks to playwright Joanna Evans who wrote the spoken text, drummer Roy Ben-Yosef, and guitar player Roberto Trzini, who wrote an original soundtrack.","thumbnail_image":{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/Archive_19687-1024x576.jpg","title":"Archive_19687","alt":"1968WSQP","caption":""},"headshot_image":{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/Hadar-1-768x432-1.jpg","title":"Hadar-1-768x432","alt":"hadar headshot","caption":""},"slide_show":[{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/Archive_2-1024x576.jpg","title":"Archive_2","alt":"1968WSQP","caption":""},{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/Archive_23-1-1024x576.jpg","title":"Archive_23","alt":"1968WSQP","caption":""},{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/Archive_24-1024x576.jpg","title":"Archive_24","alt":"1968WSQP","caption":""},{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/Archive_22-1024x576.jpg","title":"Archive_22","alt":"1968WSQP","caption":""}],"tags":[{"name":"History","slug":"history"},{"name":"Mobile","slug":"mobile"},{"name":"Narrative/Storytelling","slug":"narrative-storytelling"},{"name":"UX","slug":"ux"},{"name":"VR/AR/Immersive","slug":"vr-ar-immersive"}],"video_presentation_url":"https://vimeo.com/336836447","video_documentation_url":""},{"student_id":100,"student_name":"Hafiyyandi","student_slug":"hafiyyandi","advisor_name":"Nancy Hechinger","title":"MOHAMMAD","thesis_statement":"A series of artistic experiments on ways to express the complexities of personal identity across cultural and geographical boundaries.","abstract":"Identity is not only self-produced but also negotiated with one’s community and governing institutions. Having lived as an immigrant since I was a teenager, my concept of self and the way I express it have to be continuously adjusted depending on where I am; especially when part of that self is subject to social, economic or political persecution. This identitarian inconsistency also persists even when my well-being is not at stake. I have become unable to sufficiently articulate who I am.\r\n\r\nThrough MOHAMMAD, I explored ways to forge an identity that works for me: a form of identity that fluidly expresses the different ways I construct myself. There are three artistic experiments, each culminating in a mini-installation.\r\n\r\nThe first stage is building an inventory of self. I collected my genetic-ancestry data (biological self), chat logs (performed self), and wrote down the different ‘selves’(authored self) I have. Using this inventory, I made an installation of two video self-portraits that ‘talk’ to and slowly merge into each other.\r\n\r\nThe second stage is denying an imposed identity. For the purpose of this project, I chose to sarcastically portray my experience at immigration counters in country borders. I created an installation where a viewer got to classify a photo as ‘MOHAMMAD’ or ‘NOT MOHAMMAD’. After each classification, it printed out different visa pages depending on the choice made.\r\n\r\nFinally, the third stage is creating a new identity by repurposing conventional identity expressions. I created custom patterns that were interpolated from the Islamic geometric pattern and my own hand drawings. Depending on the parameters fed into the generator, the patterns can dynamically change while retaining some of the original features. They can hide as well as reveal embedded icons and meanings.","context_research":"Erik Erikson (1968) characterized identity as having three unique components: the ego, personal identity, and social identity. This framework of seeing identity as both internally conceived and externally negotiated has persisted and been echoed, although differing in detail, by other identity theorists.\r\n\r\nIn a 1993 paper, Radhakrishnan introduced the idea of “postcolonial hybridity”. Due to historical forcing of national-identity and geographical dislocation, postcolonial hybrids find themselves without a stable regime or an authentic root to anchor their in-between identities. Radhakrishnan proposed that to claim authenticity, a hybrid can produce an “original past” in defiance of a grand narrative.\r\n\r\nMany artists have explored this defiance in their works. In Wafaa Bilal’s Domestic Tension (2007), he granted the public permission to harm his body. Here, Bilal challenged the US-imposed narrative of “all Iraqis are terrorists”.\r\n\r\nOther artists turned defiance into creating new identitarian narratives. In Salman Rushdie’s Satanic Verses (1988), the sacred tale of the Prophet Mohammad was reinvented through a story of two Indian men in Britain. A sacrilege, Satanic Verses developed a protagonist that truly embraces his in-between-ness without bowing down to either Islamic or colonialist English narrative of an Indian man. Similarly, through brutalizing his older works and incorporating elements of queerness and pop culture, Jeffrey Gibson’s latest works (2011-present) fabricates a new Native American art history and visual vocabularies.","thumbnail_image":{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/thumbnail-2-1-1024x576.jpg","title":"thumbnail-2","alt":"Two self-portraits with a backdrop of colorful fabric","caption":""},"headshot_image":{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/portrait2-768x432-1.jpg","title":"portrait2-768x432","alt":"Hafiyyandi headshot","caption":""},"slide_show":[{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/images-1-1024x576.jpg","title":"images-1","alt":"An installation of a self-portrait","caption":""},{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/images-2-1024x576.jpg","title":"images-2","alt":"Two people looking at blank screens","caption":""},{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/images-4-1024x576.jpg","title":"images-4","alt":"A person looking at a visa page","caption":""},{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/images-7-1024x576.jpg","title":"images-7","alt":"Colorful praying mat made of abstract patterns","caption":""},{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/images-6-1024x576.jpg","title":"","alt":"Close up of colorful prayer mat","caption":""}],"tags":[{"name":"Art","slug":"art"},{"name":"Identity","slug":"identity"},{"name":"Installation","slug":"installation"}],"video_presentation_url":"","video_documentation_url":""},{"student_id":57,"student_name":"Haiyi Huang","student_slug":"haiyi-huang","advisor_name":"Adaora Udoji","title":"The Drawing Booth","thesis_statement":"How can drawing help us “see” ourselves better and empower us through self-discovery? A interactive drawing booth that allows people to “capture” themselves through their drawing process. ","abstract":"Drawing has always been a way for me to process my thoughts. As technology continues to advance and our daily life becomes increasingly digital, I now realize the value drawing is able to offer to me—the freedom and the time for self-reflection. How can drawing help us “see” ourselves better and empower us through self-discovery? I want to design a drawing experience that allow people to capture their own essence ---their inner thoughts, voices, emotions, personalities, and quirks.<br><br>\r\n   \tThe Drawing Booth resembles a photo booth, but instead of taking photos, visitors capture themselves through drawing,by recording and revealing their drawing process. Upon entering the Drawing Booth, the visitor will be guided to randomly select a prompt, for example, “draw something that makes you smile no matter what”. A webcam is placed above the drawing paper to record the drawing process. Once the visitor is done drawing, a time-lapse video showing the visitor’s characteristic process of drawing is generated as a “portrait” of the visitor. ","context_research":"While designing this thesis project, I have looked into the topic of drawing, psychology, and modern-day technology through literature references such as Drawing-The Purpose by Leo Duff and Jo Davies and Drawing/Thinking: Confronting an Electronic Age by Marc Treib. I also interviewed several people with various academic and professional backgrounds to understand what drawing means to them. The takeaways I got from my initial research is that most people draw to communicate something and that the process of drawing is as important as the drawing itself.  As for the final design of my thesis, I drew inspiration from several existing projects such as Face-o-Mat by Tobias Gutmann, Let’s Rethink High School: a touring video booth that collected more than 1,000 stories and ideas about how to improve high school education by Local Projects. ","thumbnail_image":{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/thebooth-1024x683.jpg","title":"The Drawing Booth","alt":"The Drawing Booth","caption":""},"headshot_image":{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/haiyi-profile-pic-1024x683.jpg","title":"haiyi profile pic","alt":"haiyi profile pic","caption":""},"slide_show":[{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/thebooth-768x512-1.jpg","title":"thebooth-768x512","alt":"drawing booth","caption":""}],"tags":[{"name":"Art","slug":"art"},{"name":"Design","slug":"design"},{"name":"Installation","slug":"installation"}],"video_presentation_url":"https://vimeo.com/336814906","video_documentation_url":"https://vimeo.com/331479189"},{"student_id":60,"student_name":"Hau Yuan","student_slug":"hau-yuan","advisor_name":"Kathleen M Sullivan","title":"Ultimate “Mobile-First” Design","thesis_statement":"What if we save our dying phone like rescuing a patient? What if we commemorate our deprecated phone when we no longer need them? Ultimate “Mobile-First” Design is a whimsical product suite that exaggerates how smartphones have shaped our behavior and mental model.","abstract":"After the paradigm shift of “Mobile-First” design a decade ago, smartphones have gradually become integrated into every facet of our daily life. Our reliance on smartphones has incorporated them as the extensions of our bodies. They empower us to complete the tasks that our bodies are not capable of. Also, they are affecting us physically, perceptually and mentally. We are losing natural wayfinding abilities because of robust GPS navigation. We have more awkwardness in small talk because of our dependency on our phones. Posting Instagram stories is usually prior than having delicious dishes. <br><br>\r\n\r\nIn Ultimate \"Mobile-First\" Design, I created a series of whimsical products playfully to remind people about our entrenched habits and mental models of getting along with those tiny glowing screens. The product suite consists of Smartphone First Aid Kit, Smartphone Heat Stroke Treatment Kit, and i-Coffin. Each of the products talks about one specific behavior regarding the way we use our smartphones.\r\n","context_research":"I've always been interested in speculating our relationships with machines. In Speculative Everything, Anthony Dunne and Fiona Raby propose a kind of design that is a means of speculating about how things could be—to imagine possible futures. In the examples of this book, artists and designers often pose “what if” questions behind the work they created, which are intended to let the audience picture the exaggerated scenario of a specific topic. They inspired me to anchor my thesis as satirical speculation of our firmly established behavior using a phone.<br><br>\r\n\r\nAnother piece that inspired me was Artificial Defence Mechanisms by James Chambers. It is a series of electronic products that could protect themselves from threats in their environment the way animals do in nature. Instead of using practical engineering way to avoid damages, James gave products funny yet well-designed animal-like behavior to make people project stronger emotional ties onto formerly static products. His approach truly opens my mind to think about new ways of talking about the profound issue by reversing the way things typically work. I took this anthropomorphic and humorous approach as my design principle and created three products. ","thumbnail_image":{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/thumbnailImage-1-1024x576.jpg","title":"thumbnailImage","alt":"thumbnailImage","caption":""},"headshot_image":{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/thesisProfilePicture-768x432-1.jpg","title":"thesisProfilePicture-768x432","alt":"hau headshot","caption":""},"slide_show":[{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/thesis-slidesShow-1-1024x576.jpg","title":"thesis-slidesShow-1","alt":"thesis-slidesShow-1","caption":""},{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/thesis-slidesShow-2-1024x576.jpg","title":"thesis-slidesShow-2","alt":"thesis-slidesShow-2","caption":""},{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/thesis-slidesShow-3-1024x576.jpg","title":"thesis-slidesShow-3","alt":"thesis-slidesShow-3","caption":""},{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/thesis-slidesShow-4-1024x576.jpg","title":"thesis-slidesShow-4","alt":"thesis-slidesShow-4","caption":""},{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/thesis-slidesShow-5-1024x576.jpg","title":"thesis-slidesShow-5","alt":"thesis-slidesShow-5","caption":""}],"tags":[{"name":"Design","slug":"design"},{"name":"Speculation","slug":"speculation"}],"video_presentation_url":"https://vimeo.com/336826222","video_documentation_url":"https://vimeo.com/335046717"},{"student_id":59,"student_name":"Heng Tang","student_slug":"heng-tang","advisor_name":"Gregory Shakar","title":"A Farewell to Trolls","thesis_statement":"My thesis is a word game where players type in friendly words or sentences to win and abusive words to lose. It encourages people to have genial attitudes when interacting with people on the Internet. This means less trolling, cyberbullying and a better online community.","abstract":"Let's face it! Internet trolls are ubiquitous nowadays. Just browse through the comment section of YouTube videos, you can find a dictionary of swear words. To fight against the poison of the Internet community the games encourage people to use nice and friendly words to interact with others online.","context_research":"Trolling is an Internet slang which began in early 1990 on forums and Usenet which initially carried no wrong or harmful meaning. At that time, the forum veterans would ask stupid questions to troll the newbies and make fun of their straightforward answers, but it never crossed the line of no insult and abuse.<br><br>\r\n\r\nNowadays, the definition of trolling on the Internet carries more negative meaning than positive. Internet trolls make … remarks to … just for ... There are lots of exciting stories behind the choice of the word “troll”, but for the time’s sake, I am gonna skip the part and jump right to the presentation today.<br><br>\r\n\r\nMany people underestimate internet trolling. No big deal. It is wrong and dangerous. The article The Life and Death Consequences of Cyber Bullying told you the opposite with statistics and interviews. Many teenagers commit suicide because of cyberbullying. Real lives are being destroyed, literally. That is the worst case. In most common occasions, it prevents the rational discussion of things we love.\r\n<br><br>\r\nNow we know it is terrible. Here is another bad news, internet trolls are ubiquitous. We need to fight againstto fight against it.","thumbnail_image":{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/Main-Image.png","title":"Main Image","alt":"Thumbnail","caption":""},"headshot_image":{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/Snipaste_2019-04-19_16-22-18.png","title":"Snipaste_2019-04-19_16-22-18","alt":"Headshot","caption":""},"slide_show":[{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/Assest-1024x576.jpg","title":"Assest","alt":"Scene","caption":""},{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/player.jpg","title":"player","alt":"Keyboard Man","caption":""}],"tags":[{"name":"Design","slug":"design"},{"name":"Play/Games","slug":"play-games"}],"video_presentation_url":"https://vimeo.com/336826064","video_documentation_url":""},{"student_id":54,"student_name":"Huiyi Chen","student_slug":"huiyi-chen","advisor_name":"Kathleen M Sullivan","title":"Today I Will Be a Better Human","thesis_statement":"A performance and a series of wearable installations that transform the artist into a “better” human with algorithmically optimized emotion, empathy, and social interaction. Today I will be a better human is an attempt to understand what it means to be human in the age of automation, with a language of absurdity and vulnerability. ","abstract":"What makes us human? Feelings? Memories? Empathy? Are we still the same human when we outsource our memories, feelings, and empathy to machines?\r\n<br><br>\r\nToday I will be a better human consists of three wearable devices: I Will Never Forget Your Name, a social assistant that helps me impress people by optimizing my memory; Tearing Up, an empathy assistant that optimizes my emotional Intelligence by pumping tears into my eyes when it senses sorrow in other people; Hugger, the sentiment assistant that comforts me and optimizes my negative emotions. Collectively, these devices are my personal reaction to the values and expectations that society puts upon me, and a critical comment on the culture in which we are optimized and evaluated by algorithms. <br><br>\r\nIn a postindustrial society, our value as a human is defined by our economical value and our labor. We aim to be faster, stronger, smarter, prettier, and the list goes on. To produce more value, we create technical devices to extend our abilities and compensate for our weaknesses. We are all cyborgs in some way, and we are incentivized to be more and more so.<br><br>\r\nIn the last few decades, authority has to shift from humans to algorithm and more than ever, our lives are evaluated and optimized by algorithms. For example, what book we read depends on Amazon's algorithm; how we travel to a place depends on Google’s instruction...I ask myself: what are some aspects of us that hasn’t been optimized by algorithms because technology is not there yet, but is likely to be in the future? In Today I will be a Better Human, I envision a future in which we outsource more of ourselves to machines: feelings, emotions, social interactions.<br><br>\r\nBut can these feelings really be improved with the help of algorithms? Or could it nullify the things that makes humans actually human ? In the end, maybe it is exactly our imperfections, our limitation, our weakness that makes us human.","context_research":"The questions I started off with my thesis are: How is technology shaping our modern relationship with others, with ourselves and with it? How does technology change our state of mind, our sense of self, and our social relationships? <br><br>\r\nTo answer these questions, I read a few research papers, Alone Together by Sherry Turkle, Calm Technology by Amber Case. I also interviewed  a couple psychologists. Throughout the course of my research, I have become more convinced that technology has a profound influence on who we are as human beings. However, the influence is not as simple as positive or negative, but rather convoluted. For example, the average IQ in the world has decreased and the autism rate has been increasing in the past few decades, possibly correlating to the popularization of smartphones; Yet on the other hand, the average death rate has also decreased and technological advancement allows improved treatments for the autistics…<br><br>\r\nI have also come to realize that the limits of our algorithms today is the part of our social interaction that we have yet to formalize. To paraphrase what Sherry Turkle wrote, technology tends to take something complicated and promises something simpler. As a result, we stop cultivating the the ability to gather ourselves. <br><br>\r\nA deeper understanding of these problems allows me to have a clearer attitude towards them.  Machines are better at certain tasks and they have  helped us in tremendous ways. We should acknowledge and embrace that. At the same time, we should also acknowledge their limitations, and how they might shape us. This is the message I want to convey through my work. <br><br>\r\n\r\nTechnical Research<br><br>\r\nThe Technical challenge of this project is to build a computer vision and machine learning algorithm on a portable and affordable computer so that I can recognize other people’s faces and emotions as I walk around.  I researched and experimented with various face recognition models including opencv, clmtrackr, and aws rekognition. I ended up implementing the model with raspberry pi + aws because it allowed me to offload all the heavy computation to the cloud instead of running locally on the raspberry pi, which has limited computational power. \r\n ","thumbnail_image":{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/Huiyi-Chen-120-copy.jpg","title":"Huiyi Chen 120 copy","alt":"picture of Huiyi wearing tearing hat and tear up","caption":""},"headshot_image":{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/profile-3-768x432-1.jpg","title":"profile-3-768x432","alt":"huiyi headshot","caption":""},"slide_show":[{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/slide2-4-1024x706.jpg","title":"slide2","alt":"hat with embedded camera to detect faces","caption":""},{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/slide3-7.jpg","title":"slide3","alt":"tearing with the tearing device","caption":""},{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/slid5-1024x682.jpg","title":"slid5","alt":"back view","caption":""},{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/Huiyi-Chen-90-1024x662.jpg","title":"Huiyi Chen 90","alt":"hugging self","caption":""},{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/pineapple-1024x682.jpg","title":"pineapple","alt":"performing as an optimized human at pineapple reality","caption":""}],"tags":[{"name":"Art","slug":"art"},{"name":"Identity","slug":"identity"},{"name":"Machine Learning","slug":"machine-learning"},{"name":"Performance","slug":"performance"},{"name":"Speculation","slug":"speculation"},{"name":"Wearables","slug":"wearables"}],"video_presentation_url":"https://vimeo.com/336825976","video_documentation_url":"https://www.youtube.com/watch?v=ywYDmZnJ-Hc"},{"student_id":61,"student_name":"Ilana Bonder","student_slug":"ilana-bonder","advisor_name":"Gabriel Barcia-Colombo","title":"Stories Through Space","thesis_statement":"How can technology help us engage with historical content? What is the potential of emerging mediums to transform the way we experience and learn history? Stories Through Space is an exploration of Augmented Reality and Geolocation as a tool for interactive digital storytelling. \r\n","abstract":"Augmented Reality and Geolocation can be used as an engaging storytelling medium. With high­ speed connectivity, data collection, and machine learning, we are moving towards a world where the abstraction of reality we used to see in a map can finally be juxtaposed into the real world by the lenses of our gadgets. And, with that, comes the possibility of  immersing the user in the hidden narratives about those locations. \r\n<br><br>\r\nBy blending the virtual and physical worlds and giving the user control of the point of view, new opportunities of narrative interaction emerge. Simultaneously, new challenges related to technical performance and user experience are presented to us. Through the perspective of AR development, UX design and extensive User Testing, the goal of this Thesis is to analyze the process of developing Augmented Reality applications in order to suggest frameworks and best practices for creating storytelling experiences in space.\r\n<br><br>\r\nThis research is a result of my contribution and development of the apps  '1968 Washington Square Park' and 'Al Mahjar: the story of the Poets of Little Syria'. Even though the projects differ in content and location, both use AR to play with the relations between time and space: visitors are immersed in the same spot they are physically standing in, the way it was in the past, and are invited to interact with the historical content around them. \r\n<br><br>\r\nRead the full research article on https://medium.com/@ilanabonder/https-medium-com-stories-through-space-3d5ec0548ebb\r\n","context_research":"1968 Washington Square Park, is a project built in collaboration with the designer and content creator Hadar Ben-Tzur in a fellowship with History Channel and NYC Media Lab. It tells the story of two young activists in the midst of the Vietnam War, Civil Rights Movement and Women's Liberation protests. The app can be experienced in Washington Square Park, Manhattan, NY. \r\nDownload the app at https://itunes.apple.com/us/app/1968WSQP/id1461671466\r\n<br><br>\r\nAl Mahjar: the story of the Poets of Little Syria, is a partnership with Pioneer Works, Edge of Arabia and the Washington Street Historical Society. The project's goal is to turn an existing walking tour into a mobile app, making the story of the first Arab immigrants in New York City more accessible and interactive. The experience is located in the Financial District area, also in Manhattan, NY, region that about a century ago was known as Little Syria.\r\n\r\n","thumbnail_image":{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/THUMB_4-1024x576.jpg","title":"THUMB_4","alt":"stories through space thumb","caption":"stories through space thumb"},"headshot_image":{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/my_photo.png","title":"my_photo","alt":"photo of Ilana Bonder","caption":""},"slide_show":[{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/THESIS_WEB1-1024x576.png","title":"stories_through_space","alt":"Stories Through Space: an exploration of augmented reality and geolocation as a tool for historical, interactive digital storytelling.","caption":"Stories Through Space: an exploration of augmented reality and geolocation as a tool for historical, interactive digital storytelling."},{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/THESIS_WEB2-1024x576.png","title":"washington_sq_park","alt":"This research is a result of my contribution and development of the apps '1968 Washington Square Park' and 'Al Mahjar: the story of the Poets of Little Syria'.","caption":"This research is a result of my contribution and development of the apps  '1968 Washington Square Park' and 'Al Mahjar: the story of the Poets of Little Syria'."},{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/THESIS_WEB3-1024x576.png","title":"little_syria","alt":"This research is a result of my contribution and development of the apps '1968 Washington Square Park' and 'Al Mahjar: the story of the Poets of Little Syria'.","caption":"This research is a result of my contribution and development of the apps  '1968 Washington Square Park' and 'Al Mahjar: the story of the Poets of Little Syria'."},{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/THESIS_WEB5-1024x576.png","title":"user testing","alt":"By using AR and Geolocation to bind space and time, visitors can now experience the same spot they are physically standing in, the way it was in the past.","caption":"By using AR and Geolocation to bind space and time, visitors can now experience the same spot they are physically standing in, the way it was in the past."},{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/THESIS_WEB_4-1024x576.png","title":"development template","alt":"Development template created to be used as a base for projects with AR+geolocation.","caption":"Development template created to be used as a base for projects with AR+geolocation."}],"tags":[{"name":"History","slug":"history"},{"name":"Mobile","slug":"mobile"},{"name":"Narrative/Storytelling","slug":"narrative-storytelling"},{"name":"UX","slug":"ux"},{"name":"VR/AR/Immersive","slug":"vr-ar-immersive"}],"video_presentation_url":"https://vimeo.com/337308962","video_documentation_url":"https://vimeo.com/manage/269872207/general"},{"student_id":62,"student_name":"Isabella Vento","student_slug":"isabella-vento","advisor_name":"Stefani Bardin","title":"Unearthing Thread","thesis_statement":"Drawing from psychogeography, postnaturalism, and socio-spatial theory, Unearthing Thread is a research-based project that develops methods of engaging with the infrastructure networks of Manhattan. It is the genesis of a speculative and playful action that urges to be reproduced in small slices of any urban landscape.","abstract":"Unearthing Thread is an ongoing collective inquiry of the urban landscape. Through a series of participatory walks, infrastructure space is questioned. With speculative props and tools, groups of attendees become an interdependent entity. And through an archive of documentation &amp; research, the collected data becomes a poetic, digital artifact. The clauses for the happenings that have unfolded are as follows:<br><br>\r\n\r\nThis event is not tourism. <br>\r\nThis event may only be carried out as a group.  <br>\r\nThis event calls to foster attention for material and inanimate things to improve the consideration of human and nonhuman lifeforms. <br>\r\nThis event distills emergence and documents it.<br>\r\nThis event is temporary and fleeting with goals of permanence &amp; intention.<br>\r\n\r\n","context_research":"With a desire to unpack the normative narratives that govern urban dwellers’  regard towards nature, my thesis project began with an academic survey and practical exploration of Manhattan’s environment. These investigations quickly veered towards the infrastructure networks that sustain it and the life forms they govern. Additionally, I acquainted myself with artists, organisations and communities working in this context &amp; took a deep dive into perspectives on space, urbanism and ecology that pull from the humanities and performance studies. There are three practical constituents that have resulted from this research and overlap with each other to frame my inquiry; a series of collective walks, the design and selection of props to support their execution and a digital archive of the documents resulting from them.\r\n<br><br>\r\nThe Theory of the Dérive by Guy Debord has informed solitary and collective walks, and the prompts for the data collected, presented at unearthed.zone. Material elements of systems such as the steam network played as the “attractions of the terrain” that guided the limitations imposed on myself and others to imagine what is invisible and differently encounter the visible. Of particular influence on the practical elements of the thesis have been Sarah Kanouse’s Post-Naturalist Field Kit, Tryst’s Sunk Shore &amp; various works by collective SpaceHiJackers. \r\n","thumbnail_image":{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/thumbnail-17-1024x576.jpg","title":"thumbnail","alt":"thumb","caption":""},"headshot_image":{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/default.png","title":"default","alt":"default","caption":""},"slide_show":[{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/1-4-1024x576.jpg","title":"1","alt":"touch","caption":""},{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/2-2-1024x576.jpg","title":"2","alt":"material","caption":""},{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/web-768x446-1.png","title":"web-768x446","alt":"isa's project image","caption":""},{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/5-768x432-1.jpg","title":"5-768x432","alt":"isa's project image","caption":""}],"tags":[{"name":"Art","slug":"art"},{"name":"Critical Theory Art","slug":"critical-theory-art"},{"name":"Data","slug":"data"},{"name":"Performance","slug":"performance"},{"name":"social practice","slug":"social-practice"}],"video_presentation_url":"https://vimeo.com/336817727","video_documentation_url":""},{"student_id":63,"student_name":"Itay Niv","student_slug":"itay-niv","advisor_name":"Nancy Hechinger","title":"Let&#8217;s Read A Story","thesis_statement":"My thesis project, Let’s Read A Story, is a speculative exploration on how computers and technology can turn story time into a conversation between parents, children and a computer. Human gestures -- speaking, drawing, typing – allows the reader to participate in a new form of conversation on a smart device (tablet or a smart speaker) that yields a surprising new story.\r\n\r\n","abstract":"Technology and smart devices are ever present in children’s everyday lives and their development. Let’s Read A Story investigates the possibilities of enhancing storytime for children with a Machine Learning-based program to engaging a child's creativity, imagination, and inventiveness. The program is intended to be an activity joined by parents and child.\r\n<br><br>\r\nThe project addresses the following questions: \r\n1. can technology augment how parents read and tell stories to children? \r\n2. Can a child interact with a piece of technology to create a meaningful connection through literature, sound and visual art? \r\n<br><br>\r\nUsing recently possible machine learning techniques, various children’s literature corpuses have been analyzed in order to build a conversational platform that allows the reader to navigate through different narrative bits and pieces to weave a new, original immersive story of his own. The core of the experience is in the form of generated text that is a response or an answer to a human gesture (e.g speaking or drawing). The text is the first layer that carries the plot progression forward, on top of which, layers of generative sound and illustration are formed to enhance the text and based on various predictive models.\r\n<br><br>\r\nLastly, the reader can change and bend the story as it progresses, drawing illustrations of their own and changing lines of text as their heart desires.\r\n","context_research":"The rise in popularity of smart devices and speakers has increased exponentially in recent years. \r\nNext year, on average, each American household will have a smart device like the amazon Alexa or Google Home. \r\nKids are talking to technology and technology is starting to talk back.\r\n<br><br>\r\nAdvancements in NLP offer accurate semantic understanding in natural language. In natural language processing tasks, an essential part of the research (and what requires an enormous amount of effort) is to convert text data into vectors. In that manner, it’s easier for a computer to then process and analyze the text. The publicly available pre-trained model, Universal Sentence Encoder, enables users to encode corpuses of text (i.e. both sentences and whole paragraphs) into high dimensional vectors that can be used for text classification, semantic similarity, clustering, and other natural language tasks. \r\n<br><br>\r\nThe Quick! Draw dataset is a dataset of millions of drawings collected from users playing Quick! Draw. These doodles are a unique data set that helps developers train new neural networks, enable them to see patterns in how people around the world draw, and to encourage artists to create things never before imagined.\r\n<br><br>\r\n“Nothing is more important than the impact of parents and others who take care of the child; second in importance is our cultural heritage, when transmitted to the child in the right manner. When children are young, it is literature that carries such information best.” -- Bruno Bettelheim\r\n<br><br>\r\nAesop's Fables, is a collection of fables credited to Aesop, a slave and storyteller who lived in ancient Greece in 620 BCE. Initially the fables were addressed to adults containing social themes, and ethical guides. From the Renaissance onwards they were particularly used for the education of children. Each fable contains: <br>\r\n1. A short title, usually very descriptive of the story’s content and characters.<br>\r\n2. The story itself, usually no more than 30 sentences.<br>\r\n3. The moral of the story, usually contains a metaphor built on the inherent nature or trait of the animals in the story.\r\n","thumbnail_image":{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/header_image-1024x576.jpg","title":"header_image","alt":"itay","caption":""},"headshot_image":{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/profile-01-1.jpg","title":"profile-01","alt":"Itay's profile image","caption":""},"slide_show":[{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/header_image-1024x576.jpg","title":"header_image","alt":"itay","caption":""}],"tags":[{"name":"Animation","slug":"animation"},{"name":"Education","slug":"education"},{"name":"Machine Learning","slug":"machine-learning"},{"name":"Narrative/Storytelling","slug":"narrative-storytelling"},{"name":"Python","slug":"python"},{"name":"Software","slug":"software"},{"name":"Speech","slug":"speech"}],"video_presentation_url":"https://vimeo.com/337313905","video_documentation_url":"https://vimeo.com/itayniv/lets-read-a-story"},{"student_id":36,"student_name":"Ivy Danxiaomeng Huang","student_slug":"ivy-danxiaomeng-huang","advisor_name":"Kathleen Stevens Wilson","title":"Fisherman&#8217;s Song","thesis_statement":"Ancient Chinese poetry is a form of art that is imbued with emotion, inexpressive feelings and the heritage of ancient Eastern culture.  \r\nHow can the poetic meaning of ancient Chinese poetry, which transcends literal translation, be conveyed in interactive visual form?\r\n","abstract":"“Fisherman’s Song” is a multidimensional art installation that creates a space for audiences to experience the beautiful story and deep meaning behind an ancient Chinese poem. <br><br>\r\nThis interactive and immersive piece unfolds as users traverse the space.<br><br>\r\nThe selected poem - “Fisherman’s Song” (渔父词) by Zhu Dunru(朱敦儒), describes the poet’s life experience after deciding to quit his life as a dignitary and live a secluded life next in the forest<br><br>\r\nIn the poem, he scorns the greed and desire of people he encountered as a dignitary and expresses his desire for the lifestyle he had always dreamed of, a life connected to nature and the elements. \r\n","context_research":"“Fisherman’s Song” is an interactive art piece that fuses ancient eastern culture with modern technologies, creating an immersive environment that enables users to experience an ancient culture without the feeling of being surrounded by technology.<br><br>\r\n\r\nStylistically, \"Fisherman's Song\" has been Inspired by ancient Chinese ink painting. It visualizes the content and meaning of the poem as a 3D interactive animation with the ink painting style. Combining material and fabric research, I finally decided to use the technique of projection mapping on layers of traditional Chinese fabric - Silk. The transparency of the silk layers creates the illusion of infinite space. The combination of projection, sound, and interactivity to stimulates the audience’s imagination and allows them to experience the poem in a visual way that transcends language. <br><br>\r\nThe ancient Chinese architecture style - Suzhou Garden, inspired me the most with its' unique design principles. First of all, the garden originated from the ancient Chinese intellectuals' desire to harmonize with nature while cultivating their temperament. In addition, the garden contains a series of separate but interconnected parts, to be discovered and enjoyed gradually. The staging design of  \"Fisherman's Song\" use digital visual work tell the story of the poet's life in nature, which is a harmonious fusion between modern technology with nature and ancient culture. In the meantime, Fisherman's Song follows the layout of the Suzhou Garden which allows audiences to have a personal experience and understanding of the poem. \r\n\r\n","thumbnail_image":{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/YUFUCI-1024x688.png","title":"YUFUCI","alt":"thumbail","caption":""},"headshot_image":{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/IMG_8063-768x432-1.jpg","title":"IMG_8063-768x432","alt":"ivy","caption":""},"slide_show":[{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/slide3-5-1024x576.jpg","title":"slide3","alt":"meimeide222","caption":""},{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/slide222-1024x576.jpg","title":"slide222","alt":"tdprocess","caption":""},{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/slide4-4-1024x576.jpg","title":"slide4","alt":"tracking","caption":""},{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/slide1-2-1024x576.jpg","title":"slide1","alt":"hao!","caption":""},{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/slide5-3-1024x576.jpg","title":"slide5","alt":"meimeide4","caption":""}],"tags":[{"name":"Art","slug":"art"},{"name":"Culture","slug":"culture"},{"name":"History","slug":"history"},{"name":"Installation","slug":"installation"},{"name":"Visual","slug":"visual"}],"video_presentation_url":"https://vimeo.com/336836286","video_documentation_url":""},{"student_id":68,"student_name":"James Huang","student_slug":"james-huang","advisor_name":"Kathleen M Sullivan","title":"Lost in Translation","thesis_statement":"How much information would loss after series of translations? What would machine interpret with series of translations? How would the interpreted result different from our expectation and cognition?","abstract":"As artificial intelligence developing, more and more people worry about machines will replace humans. Although machine learning seems to do some promising works, it still needs effort to catch up human in complicated works, especially those tasks that have no correct answers or need to be interpreted. The reason why we use machine learning is that we want a machine to come up with the results we expect. Accordingly, we feed training data as its knowledge. However, machine learning is a process of translation. Machine only gives the result based on its knowledge, it doesn't deduct like human does. Since machine interprets in its own way, it is hard to control them to have the same thought like us. Therefore, I designed an interactive experience to show that it is difficult to make a machine come up with the result as we expect. The project has a recursive process for human and machine to interpret each other’s results. Human needs to come up with a sentence to describe an image generated by machine and the machine will do multiple machine learning translations from the description from human to a sketch and then to an image in each round of process.","context_research":"The inspiration of my project is Closed Loop by Jake Elwes. It uses machine learning to do feedback loop on images and texts. Image generates texts and the texts generate another image and so on. With the concept of looping and translation, I tried to do series of translations in multiple languages on Google Translation to see how much information is lost or misinterpreted. Moreover, as to series of message passing, I started to do research on Telephone Game. Since I want to apply this concept on images, I found an online image version Telephone Game called Drawception. Moreover, Google Quick Draw gave me inspiration that sketches can be a medium on image translation.\r\n<br><br>\r\nFor the technical research, there are several machine learning models I have researched. <br>\r\n1. im2txt, a project originated from Google that can generate caption from images.<br>\r\n2. AttnGan, it can generate image from text. <br>\r\n3. Word vector, a group of related models that are used to produce word embeddings, which can help me to find out the relationships between two words. <br>\r\n4. SketchRNN, a generative model that can draw sketches.<br><br>\r\n\r\nThere are more technical projects I have researched that I eventually did not use such as Detectron, a high performance object detection model, and SketchyGAN, a model that can generate images from sketches. ","thumbnail_image":{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/output-10-1024x576.jpg","title":"thumbnail","alt":"thumbnail image","caption":""},"headshot_image":{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/self-768x432-1.jpg","title":"self-768x432","alt":"james headshot","caption":""},"slide_show":[{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/output-4-1024x576.jpg","title":"main 1","alt":"main image 1","caption":""},{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/output-5-1024x576.jpg","title":"main2","alt":"main image 2","caption":""},{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/output-6-1024x576.jpg","title":"main 3","alt":"main image 3","caption":""},{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/output-7-1024x576.jpg","title":"main4","alt":"main image 4","caption":""},{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/main2-1-1024x683.jpg","title":"main5","alt":"main image 5","caption":""}],"tags":[{"name":"Machine Learning","slug":"machine-learning"},{"name":"Play/Games","slug":"play-games"}],"video_presentation_url":"https://vimeo.com/336826469","video_documentation_url":""},{"student_id":65,"student_name":"Jarone Wright","student_slug":"jarone-wright","advisor_name":"Kathleen Stevens Wilson","title":"In Panes","thesis_statement":"Exploration of kiln-glass and light to make images. I’ve experimented with creating interactive glass sculptures that can be used to make paintings with light.","abstract":"In Panes is a series of glass sculptures that encourage user exploration with light. The transmissive and reflective properties of glass is used to create multi-dimensional images when illuminated. Viewers are empowered to explore and change the sculpture by manipulating the lights provided.<br><br>\r\n\r\nGlass art is seen as fragile and rigid, something stuck in a moment of time. I encourage viewers to break through the “Pane” and manipulate the composition as they explore the pieces. Several pieces have been created for display, each a different experiment in form, color and transparency.<br><br>\r\n\r\nGlass is a versatile medium but not often utilized in the creative technology field. Why is this and how can we encourage people to view glass in a new light? Various methods of fusing kiln-glass and coldworking have been examined as part of this experiment.","context_research":"For my thesis I wanted to work with a material that requires an artistic touch. While I’ve done work in acrylic, in particular, sculptures made from laser cut acrylic sheets, there was a degree of separation I wanted to remove. Working with glass is a fun but frustratingly unforgiving artform, which is part of the reason I named this thesis “In Panes”.<br><br>\r\n\r\nTo know what I was getting into I researched contemporary glass artists, either for the unique sculptural techniques or meaningful incorporation of technology. Artists such as Michelle Jader, Jed Malitz and Dustin Yellin were good sources of inspiration. Michelle and Jed’s work involves directly stacking layers of acrylic sheets to make pieces, and their pieces have a unique identity and visual language. I hope to develop an art fingerprint like that. In Dustin’s work, He is able to capture a moment in time while being visually dynamic. Being able to view from multiple angles adds to it. I would like to give my work depth even though the starting materials are 2-dimensional.<br><br>\r\n\r\nI also was inspired by an exhibit at LACMA called 3D Double Vision. This exhibit showed the history of 3D art and most of it involves tricking the mind to interpret a perspective that isn’t physically there.<br><br>\r\n\r\nI then took various lessons at UrbanGlass, which is a multi-specialty glass studio. After that and speaking to many glass artists and retailers, I started learning more. But more importantly I started feeling like a member of the glass art community.<br><br>\r\n\r\nFor my user testing, I will exhibit the glass sculptures and allow the viewers to inspect, play and analyze the pieces by only manipulating the light sources. My intention is to make light their hands. At the same time I want to avoid direct physical interactions with the glass which may damage the pieces and harm the viewer.","thumbnail_image":{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/Proj_Thumbnail-1024x576.jpg","title":"Proj_Thumbnail","alt":"Transparent blue glass prism","caption":""},"headshot_image":{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/Headshot-768x432-1.jpg","title":"Headshot-768x432","alt":"jarone portrait","caption":""},"slide_show":[{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/InPanes01-1024x683.jpg","title":"InPanes01","alt":"Transparent blue glass prism with sunlight","caption":""},{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/InPanes03-1024x683.jpg","title":"InPanes03","alt":"Glass sheet with multiple rows of gradients repeated","caption":""},{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/InPanes02-1024x683.jpg","title":"InPanes02","alt":"hand holding a dark blue rectangular prism piece.","caption":""},{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/DSC_0758-1024x680.jpg","title":"DSC_0758","alt":"Blue Glass rectangular prism piece with dark round shape in middle.","caption":""},{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/slideshow5-2-1024x683.jpg","title":"slideshow5","alt":"thin vertical stripes in glass, cobalt, clear and blue.","caption":""}],"tags":[{"name":"Art","slug":"art"},{"name":"Design","slug":"design"},{"name":"Education","slug":"education"},{"name":"Sculpture","slug":"sculpture"},{"name":"Visual","slug":"visual"}],"video_presentation_url":"https://vimeo.com/336836549","video_documentation_url":""},{"student_id":71,"student_name":"Jason S Yung","student_slug":"jason-s-yung","advisor_name":"Nancy Hechinger","title":"Conjunctio","thesis_statement":"My thesis presents milestones from my ongoing investigation into the use of light as an expressive medium for art. To this end, I have created an object that uses projected light, shadow and movement to generate a complex and dynamic light sculpture. ","abstract":"Sometimes one moment of inspiration takes years to unpack. For me, this moment came when I saw how a bent LED strip looked behind a large piece of paper, creating beautiful interplays of light, arching shadows and gradients. Two years at ITP gave me the means to truly explore this insight and push my understanding of the medium of light.<br><br>\r\n\r\nAt ITP, it was not just my technical skills on LEDs and electricity that grew, but it was what I saw in the light that also grew. Danny Rozin remarked once that there seemed to be two types of light in my work: smart and dumb light.  “Smart light” is when it is the information in the light pattern itself that creates form, e.g. how differences of paint colors create a line. “Dumb light” is where the information was not in the light itself but in the darkness, as  when an object in front of a lamp creates shadow. Then, the resulting form is not just due to the light alone, but a co-creation of the light and the darkness. It’s not just the light that creates form -- but also the controlled application of darkness. It is the insight of “dumb light” that my thesis unpacks and builds upon. \r\n<br><br>\r\nMore broadly, my thesis signifies new directions for my light work: from 2D light painting to 3D light sculpture; from the motion of LEDs animation to the motion of stepper motors controlling the shaft of light. \r\n<br><br>\r\nMy thesis also embodies my new understanding of light as a field of possibility that doesn't need to stay on a 2D surface like a painting, but rather the light exists as a field of possibility that can be caught and volumized in different ways. ","context_research":"My major artistic influences are Mark Rothko, James Turrell and Thomas Wilfred: Rothko for his color field paintings that expressed both simplicity and complexity at the same time, and Turrell for his innovations that showed light as no one had ever seen it before.For my thesis the major , major influence is Thomas Wilfred, who pioneered light art back in the 1920s through his “lumia”. I became aware that my light/shadow work was a different path to the same esthetic garden. <br><br>\r\n\r\nMy major influence on concepts/esthetics is the book Art As Experience by John Dewey and his generation theory of art’s value in human life for it’s reconciliatory qualities through the human psychological projection system.\r\n<br><br>\r\nMy major influences on my technical work are: <br>\r\n-Danny Rozin for his approach to design and construction, and his mentality of solving different problems at different stages of design. <br>\r\n-Ben Light for his “make life easier for yourself” approach<br>\r\n-Barak Hemou for his exploration of projective surfaces, modular design ethnic and practical no-nonsense approach to component procurement. <br><br>\r\n\r\nUnderlying it all is my interest in the mysterious aspect of light as a substance, the “thingness of light itself”, as James Turrell says. Light as primordial element, the common thread that ties together religion, science and the beautiful way Washington Square Park looks like at dusk. \r\n<br><br>\r\nMy thesis is entitled Conjunctio, which means \"conjunction\" in latin and is a term taken from medieval alchemy. In alchemy, the conjunction was the part of the alchemical opus when the opposites were united. For me, the control of darkness and combination with light is the conjunction that allowed for this new direction of light sculpture for me.\r\n","thumbnail_image":{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/2H6A9406.MOV.04_53_37_07.Still001-1024x576.jpg","title":"2H6A9406.MOV.04_53_37_07.Still001","alt":"main box","caption":""},"headshot_image":{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/jason.jpeg","title":"jason","alt":"jason headshot","caption":""},"slide_show":[{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/1O3A9994-1024x683.jpg","title":"1O3A9994","alt":"color field","caption":""},{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/2H6A9404.MOV.04_48_30_12.Still001-1024x576.jpg","title":"2H6A9404.MOV.04_48_30_12.Still001","alt":"white on white","caption":""},{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/2H6A9404.MOV.04_52_04_16.Still003-1024x576.jpg","title":"2H6A9404.MOV.04_52_04_16.Still003","alt":"side very red","caption":""},{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/1O3A9951-1024x683.jpg","title":"1O3A9951","alt":"red on blue","caption":""},{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/2H6A9404.MOV.04_52_35_18.Still002-1024x576.jpg","title":"2H6A9404.MOV.04_52_35_18.Still002","alt":"side red","caption":""}],"tags":[{"name":"Art","slug":"art"}],"video_presentation_url":"https://vimeo.com/337313962","video_documentation_url":"https://vimeo.com/332128030"},{"student_id":73,"student_name":"Jenna Xu","student_slug":"jenna-xu","advisor_name":"Adaora Udoji","title":"Self-Portrait as Allegory of","thesis_statement":"To this day, “learned helplessness” is still the most insidious vestige of my history with depression, quietly limiting my sense of self, capability, and possibility. \"Self-Portrait as Allegory of\" is my act of resistance: a data-driven, machine-managed, mental health maintenance system that aims not only to mitigate the pain points of recovery, but restore my sense of agency.","abstract":"Adapting the conceptual format and title of an Artemisia Gentileschi painting from 1638–39, my thesis is at once a self-portrait as depicted by personal data and predictive models, as well as an allegory to an amalgamation of scientific, cultural, and personal ideals of mental health. <br><br>\r\n\r\nIn construction, \"Self-Portrait as Allegory of\" comprises three systems: data collection by a body of trackers I built to collect behavioral metrics; mood prediction by a suite of neural networks that use this data to predict my mood, morale, stress, and fatigue levels; and intervention by a noninteractive voice assistant that responds to these predictions by directing me to perform mood-improving interventions and rituals that, taken together, form a lifestyle shift that optimizes for mental health.\r\n<br><br>\r\nIn manifestation, the project stems from the last system as an n-of-one experiment: a data-driven, tech-directed performance of a composite aspiration comprising optimizations from positive psychology, the wellness industry, self-care culture, the female-empowerment zeitgeist, and my own romanticism of past, present, and future lives forever shaped, stagnated, and propelled by my history with depression. Synthesized into actionable interventions and rituals, these frameworks form the body of allegorical symbolism for idealized mental health, which I perform throughout the day as the system sees fit. The mere act of embodying these ideals allows me to not only live them in the present but also write them into my narrative of the future.\r\n<br><br>\r\nBy transforming mental health maintenance—normally a consciously effortful, continuous act of self-discipline—into a simple performance of externally mandated instruction, my thesis aims to render irrelevant some of the most insidious and persistent depressive symptoms—learned helplessness and fixed mindset—by removing willpower, decision-making, and constant emotional monitoring out of the daily work of self-care and recovery. ","context_research":"The data-collection phase was inspired by research projects and businesses rooted in the field of psychology, in particular trackyourhappiness, a doctoral research project from Harvard that identifies daily patterns associated with happiness; the PHQ-9, a self-reported depression-diagnostic standard; Mindstrong, a company headed by researchers looking at which markers of smartphone usage predict mental illness; and Exist, which links many of your apps to find correlations in behavior.\r\n<br><br>\r\nThe mood-prediction phase consisted of machine learning research and experiments, with guidance from fellow cohort Jim Schmitz and the tutorials of Jason Brownlee.\r\n<br><br>\r\nThe intervention phase was also deeply inspired by psychology, as well as by wellness culture. Examples include You Feel Like Shit, an interactive self-care flow chart; the Headspace app, which offers exercises tailored for nearly every mood possible; Berkeley’s Greater Good Science Center and its spin-off project, Greater Good in Action, a repository of practical applications for its research findings on mental health and wellness; and UPenn’s positive psychology MOOCs.\r\n<br><br>\r\nMy rituals mostly replicate certain aspects of my traveler’s lifestyle that resurrected me years ago: namely, frequent exposure to new situations, experiences, and people. While I borrowed from references like the now-famous paper \"The Experimental Generation of Interpersonal Closeness\", and the public event Skip the Small Talk, these rituals are mainly anchored in the idea of randomness as a way to push past self-limiting boundaries reinforced by routine and narratives of “personality.” A conversation with Max Hawkins about his work on randomized living helped to coalesce this idea.","thumbnail_image":{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/cover-1024x574.png","title":"self-portrait as allegory of","alt":"style transfer from Artemisia Gentileschi's Self Portrait as the Allegory of Painting","caption":"style transfer from Artemisia Gentileschi's Self Portrait as the Allegory of Painting"},"headshot_image":{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/headshot_xu-768x432-1.jpg","title":"headshot_xu-768x432","alt":"jenna headshot","caption":""},"slide_show":[{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/Screen-Shot-2018-10-13-at-1.15.47-PM-1024x640.png","title":"data collection - trackers","alt":"data collection - trackers","caption":"data collection - trackers"},{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/fitterhappier-1024x682.jpg","title":"Fitter Happier","alt":"Fitter Happier - voice assistant","caption":"Fitter Happier - voice assistant"}],"tags":[{"name":"Data","slug":"data"},{"name":"Experiment","slug":"experiment"},{"name":"Machine Learning","slug":"machine-learning"},{"name":"Self-care","slug":"self-care"},{"name":"Speculation","slug":"speculation"}],"video_presentation_url":"https://vimeo.com/336817760","video_documentation_url":"https://vimeo.com/331318826"},{"student_id":70,"student_name":"Jesse Simpson","student_slug":"jesse-simpson","advisor_name":"Gregory Shakar","title":"LIME: Light Interface for Musical Expression","thesis_statement":"LIME is a patchable device that provides the user with a platform for using light as a control medium for musical expression. Through a combination of lighting, sensors, fiber optic patch cables, and processing units, the system allows the user to design cable flows which generate and modulate light patterns before translating the patterned light into musical events interpreted by computer-based virtual instruments and effects.","abstract":"Over the past 80 years, electronics, especially computers, have had a massive impact upon the ways that music is created. In more recent years, technologies have introduced incredible new capabilities, however, these have often come at the cost of increased complexity and a growing level of abstraction between the sounds that are made and the signals used to create them. This phenomena has created some disconnect between performers and the audience as the connection between gestures on stage and the sounds that are heard become increasingly dissociated. A prime example of this can be seen in modular synthesizers where even the player can become confused by the intricate, yet abstract, programming of the instruments, especially on-stage.<br><br>\r\n\r\nBut, what if audio signals could be made visible while they’re communicating?  Could patch cables that expose the underlying signal patterns improve one’s comprehension of their compositions or, perhaps, enhance the experience of composing as well as viewing?  LIME is a response to these questions by offering a semi-modular system for using light as a control medium in musical expression. Where modular synthesizers generate and modulate raw audio, LIME operates in the computer space utilizing the MIDI protocol.  Through a combination of lighting, sensors, fiber optic patch cables, and processing units, the system allows the user to design signal flows made of light patterns which are then translated into sound. The patch cables provide real-time views into the signal flows as they pass between different modules. The pulsing and breathing light visualizes the signal flow in a physical form.  As a composer or performer, this visual component is useful in that it allows for quickly understanding how a signal is affected by different modules and how it fits into a larger musical piece. Another benefit comes in the form of reduced error and easier troubleshooting. While computer software allows for internal signal routing, it can quickly lead to extremely complex scenarios with confusion abound. The physical interaction of ‘patching’ from point to point provides a more tangible understanding of the connections as they are formed. Unfortunately, as patches grow, they too can become a chaotic mess of wires with little ability to quickly discern the meaning of individual connections. With LIME, signal generators, processors, and inputs are combinable to compose sounds and rhythms while simultaneously providing the path taken to achieve them, visually.","context_research":"Light is not an unexplored medium in musical expression.  In 1734, Jesuit priest, Father Louis-Bertrand Castel is largely cited as having developed the first documented visual music tool, the Clavecin Oculaire (Ocular Harpsicord).  It was comprised of a harpsichord paired with colored stained glass revealed in unison with each note.  In 1754, a second model was designed specifically for allowing candlelight to pass through the colored panes.  Two centuries later, in 1915, Russian Composer Alexander Scriabin’s symphony, ‘Prometheus: Poem of Fire’ debuted in New York City, centering around a light organ displaying a tone to color mapping system based on the circle of 5ths; a geometric tonal relationship map used within music theory for describing the chromatic scale.  A different, yet notable approach can be seen in light theremins; a common example implemented using easily accessible electronic components where a user controls the pitch and volume of an audio signal with their hands through blocking or allowing desired amounts of light to the sensors.  This same approach can be seen in many commercially available synthesizers as well.  LIME is the result of harnessing this simple technique and combining it with controlled, physical routing modeled after modular synthesis.\r\n<br><br>\r\nWhile musical patching largely emerged in analog synthesizers in the 1960s, tangible patching is less frequently seen in the digital world of physical software controllers.  While DIY projects exist such as TaViPaCo: Tangible Virtual Patch Cords, there are no commercial products to bridge the worlds of physical patching and digital sound synthesis.  With the growing popularity of node-based audio programming in software such as Audiomulch, Max/MSP, Puredata, and others, a physical controller modeled after computer-based programming is appealing.  \r\n <br><br>\r\nVisual accompaniment has become a mainstay of electronic music performance.  The synesthetic qualities provided by audiovisual performance provide deeper context to the human mind. One series of studies suggests that “variation in visual accompaniment (e.g. animated narrative story video, abstract animated video, musician performance video, no-video control) influenced the way music was effectively interpreted and cognitively perceived” amongst the participants. LIME provides an approach to simplifying signal flow perception, and enhancing tangible interaction with digital media, thus creating a compelling Light Interface for Musical Expression.  \r\n","thumbnail_image":{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/aldenOnLime-for-archive-2-1024x556.jpg","title":"aldenOnLime - for archive 2","alt":"A hand is seen going to grab one of the cables in that is inserted into an input port. The other hand is seen adjusting a knob","caption":""},"headshot_image":{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/2H6A0006-edit-768x513-1.jpg","title":"2H6A0006-edit-768x513","alt":"jesse headshot","caption":""},"slide_show":[{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/LIMEgif1-under5.gif","title":"LIMEgif1 - under5","alt":"Lime Playing","caption":""},{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/LIMEgif2-under5.gif","title":"LIMEgif2 - under5","alt":"lime instrument","caption":""},{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/LIMEgif3-under5.gif","title":"LIMEgif3 - under5","alt":"Lime gif","caption":""},{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/patching-1024x640.jpg","title":"patching","alt":"The user is preparing to patch the LIME device and the cables are already patched with some illuminated","caption":""},{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/unnamed-1-1-1024x557.png","title":"unnamed (1)","alt":"playing nime","caption":""}],"tags":[{"name":"Music","slug":"music"},{"name":"Product Design","slug":"product-design"},{"name":"Sound","slug":"sound"},{"name":"Tool","slug":"tool"}],"video_presentation_url":"https://vimeo.com/336826498","video_documentation_url":"https://vimeo.com/331523790"},{"student_id":74,"student_name":"Jillian Zhong","student_slug":"jillian-zhong","advisor_name":"Adaora Udoji","title":"Person Thing #1-3","thesis_statement":"In the West and the racialization it imposes on the other, East Asian American women or the “yellow woman” exist as people that live as objects. Composed of a series of three pieces made from different mediums, this project explores the race-making logic used to depict east asian femininity in Western visual culture and examines the artist’s relations to them.","abstract":"On the topic of East Asian femininity in Western visual culture, Anne Anlin Cheng writes, “We have roughly marshalled this vast and tenacious history under a broad heuristic that we might roughly label “Oriental female objectification,” refracted through the lenses of commodity and sexual fetishism. Yet we barely know how to process the political, racial, and ontic complications of confronting a human figure that emerges as and through ornament.” This project aims to explore that elusive gray area in between “thing” and “person” by specifically playing with the visual language used in science fiction media to depict both futuristic and atavistic concepts.\r\n<br><br>\r\nPerson Thing #1-3 is a series of experiments where I attempt to create representations of the yellow woman using synthetic and immaterial mediums and examine my relationship with my creations. Will I see my creations as another object? Or as a clone of myself? A new separate being?<br><br>\r\nEach piece is a depiction of a body or a person using synthetic materials ranging from the physical, to the digital, and to the non-visual. The first piece is a sculptural dress made from acrylic and multiple speakers that are connected to portable media playing devices. This dress depicts a body informed by media and does not need a human wearer to feel lifelike. The second piece is a synthetic ghost figure that carries presence despite only being viewable through augmented reality. The third piece is an “hacked” chatbot that tells it’s own story of transitioning from a human computer programmer to an AI.<br><br>\r\n\r\nI designed this project around my research process that started from my own interest in understanding the racialization imposed on me. Rather than create an educational or awareness tool, I decided to frame these pieces as experiments, intimately working with asian femininity in Western visual culture and specifically focusing on techno-orientalism and Japanese animation in the West. This focus is influenced by my experiences growing up as an Chinese American in the 2000s and my career as a programmer.","context_research":"My research was informed by the works of Anne Anlin Cheng, specifically The Melancholy of Race (2000) and Ornamentalism (2018). I was also influenced by “The Cyborg Manifesto” by Donna Haraway and the sculptures of Lee Bul. The garment design was inspired by the Alexander McQueen’s 1999 S/S collection for Givenchy and Paco Rabanne’s modular dresses. The “hacked” chatbot narrative was inspired by the design of Lily, a Chinese language assistant, and its Kickstarter campaign. Overall, the research for this project encompasses all the media references I’ve collected over the years, across different mediums.","thumbnail_image":{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/thumbnail-19-1024x576.jpg","title":"thumbnail","alt":"person thing #1-3","caption":""},"headshot_image":{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/jillian_portrait2_16x9-169x300-1.jpg","title":"jillian_portrait2_16x9-169x300","alt":"jillian headshot","caption":""},"slide_show":[{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/slideshow_top-1024x576.jpg","title":"slideshow_top","alt":"person thing #1","caption":""},{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/slideshow_ar-1024x576.jpg","title":"slideshow_ar","alt":"person thing #2","caption":""}],"tags":[{"name":"3D","slug":"3d"},{"name":"Art","slug":"art"},{"name":"Culture","slug":"culture"},{"name":"Identity","slug":"identity"},{"name":"VR/AR/Immersive","slug":"vr-ar-immersive"}],"video_presentation_url":"https://vimeo.com/336817793","video_documentation_url":"https://vimeo.com/330901057"},{"student_id":66,"student_name":"Jim Schmitz","student_slug":"jim-schmitz","advisor_name":"Kathleen M Sullivan","title":"The Modern World, Painted","thesis_statement":"I designed and implemented a new approach for applying style transfers to 360 pictures and video. Using contemporary and historical paintings and images from Google Street View, I created art that encourages viewers to appreciate what is beautiful or poignant about the modern world, right in front of us, and to look at it with new eyes.","abstract":"Applying a style transfer algorithm to 360 imagery allows us to create immersive experiences that provide the feeling of being inside a painted world.<br><br>\r\n\r\nA style transfer is a computational technique involving a neural network that can re-imagine a photograph in the artistic style of a selected painting. A 360 image is a panoramic (spherical) image that provides the viewer with the opportunity to look in every possible direction instead of the single direction provided by traditional fixed-view images.<br><br>\r\n\r\nThe standard style transfer algorithm can be applied to 360 images, but the result has undesirable artifacts because the algorithm doesn’t work well with the distortions of the equirectangular projection used to store 360 image data. For my thesis, I developed a new approach for applying style transfers that eliminates these artifacts and properly transfers a painting’s style to a 360 image in an even and continuous fashion.\r\n<br><br>\r\nGoogle Street View is an expansive resource of 360 imagery capturing the modern world. In aggregate the images are a reflection of every way the world could possibly be described: beautiful, distressing, amazing, opulent, disorderly, tragic. This richness and complexity is often overlooked by people using the service for mere navigation purposes. By applying my style transfer algorithm to these images, I can draw attention to what is remarkable or meaningful about these locations and encourage viewers to look at them with new eyes and to consider the actual physical locations they depict with a new perspective.","context_research":"The biggest influence on my thesis project is the research paper “Artistic Style Transfer for Videos and Spherical Images” by Ruder, Dosovitskiy, and Brox (2018). The paper presents a technique for applying a style transfer algorithm to 360 imagery by dividing up the image into six cube faces. I greatly appreciated this paper and was inspired to think of ways the algorithm could be further improved.\r\n<br><br>\r\nArtistically I am inspired by the work of video artist Nam June Paik (1932-2006). Although his artistic medium is different from mine, his willingness to explore and modify the underlying electronics of television and video equipment motivates me and my work with machine learning and computational tools. I am also inspired by artist and neuroscientist Santiago Ramón y Cajal (1852-1934). His detailed drawings of neurons pioneered the field of neuroscience and earned him the Nobel Prize in 1906. It is because of his skills as an artist that he distinguished himself as a scientist and it is because of his work in neuroscience that he made a unique contribution to the art world. My ambition is that my background in technology and quantitative research and my new knowledge of the art world will empower me to have a similar impact.","thumbnail_image":{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/260.jpg","title":"260","alt":"360 logo","caption":""},"headshot_image":{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/default.png","title":"default","alt":"default","caption":""},"slide_show":[{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/260.jpg","title":"260","alt":"360 logo","caption":""}],"tags":[{"name":"Art","slug":"art"},{"name":"Machine Learning","slug":"machine-learning"},{"name":"Python","slug":"python"},{"name":"VR/AR/Immersive","slug":"vr-ar-immersive"}],"video_presentation_url":"https://vimeo.com/336826351","video_documentation_url":""},{"student_id":75,"student_name":"Jiyao Zhang","student_slug":"jiyao-zhang","advisor_name":"Nancy Hechinger","title":"A Vociferous Silence","thesis_statement":"“A Vociferous Silence” is a series of reactive masks that attempt to address the complexity of one’s self-concept and self-appraisal by presenting multiple aspects of inner voices.","abstract":"Visitors are invited to put their faces into the masks and cover their ears. A voice is heard through bone conduction, activated by physical touch. What the user hears creates the illusion of having a voice in their head. The narration reveals different aspects of my own self-image. Each mask focuses on one of the following aspects: negativity, positivity, and uncertainty. \r\n<br><br>\r\nAs our filters for Reality, how we see ourselves influence everything we do or say, everything we feel, or otherwise perceive. In a sense, one’s perception of others is actually a reflection of oneself. \r\n<br><br>\r\nThus, I see “A Vociferous Silence” as a VR piece as well but a different kind of virtual, where the experiencer is forced to become another person by wearing a new face and listen to a new self-image. \r\n<br><br>\r\nI have two goals for this project. First, I want to discover the unknown me, with whom I barely communicate but am always influenced by: the hidden character behind the face in the mirror that thinks, dreams, talks, feels and believes. Second, I hope that other people who share similar experiences will come to know that they aren't alone, and, I hope that will be comforting.","context_research":"Self-image is the emotional judgment we make of our self-worth. We assess ourselves continually and the inner voices become a part of the expression for the assessment. A positive self-image leads to confidence and self-acceptance. A negative self-image leads to a sense of inferiority and even depression.\r\n<br><br>\r\nThis has been a deep enduring problem for me, so I hope that this project can help not only me but also people like me. I started the project by talking to Ikuko Acosta, an art therapist and art therapy educator, who explained why the creative process is sometimes a good for people to heal: it requires a long period of time for them to continuously revisit their past and issues. And then, I reached out to others who share similar experiences to me and learned from their stories and feelings. After all the talks and interviews, I immersed myself into different kinds of books and studies. \r\nThe research process helped me to decide the media and interaction of my thesis: masks using bone conduction that reveals inner voices.\r\n<br><br>\r\nHaving no experience in making masks or sculptures, I encountered countless problems making this project happen. Thanks to Robert Benevides, a special effects make-up artist and educator, who showed me the way in, I tried different materials and techniques that eventually helped me make the idea more compelling.\r\n<br><br>\r\nI’m curious about people’s opinions on this project and I wonder if the new self-image visitors perceive affects the way they think. Does the negativity make them depressed? Does the positivity cheer them up? Do any of the aspects reflect their own journey of communicating with themselves?\r\n<br><br>\r\nThis project is the beginning of my investigation into one’s self-concept. How does this topic influence and shape individuals? How can we use different media to present it?","thumbnail_image":{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/1-5-1024x576.jpg","title":"1","alt":"project overview","caption":""},"headshot_image":{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/picture-1-768x432-1.jpg","title":"picture-1-768x432","alt":"jiyao headshot","caption":""},"slide_show":[{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/slide_2-1024x576.jpg","title":"slide_2","alt":"side look","caption":""},{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/slide_3-1024x576.jpg","title":"slide_3","alt":"user pic","caption":""},{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/slide_5-1-1024x576.jpg","title":"slide_5","alt":"user pic","caption":""},{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/slide_1-1024x576.jpg","title":"slide_1","alt":"chin rest","caption":""},{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/slide_4-1024x576.jpg","title":"slide_4","alt":"stand","caption":""}],"tags":[{"name":"Identity","slug":"identity"},{"name":"Installation","slug":"installation"},{"name":"Narrative/Storytelling","slug":"narrative-storytelling"},{"name":"Sculpture","slug":"sculpture"},{"name":"VR/AR/Immersive","slug":"vr-ar-immersive"}],"video_presentation_url":"https://vimeo.com/337314015","video_documentation_url":"https://vimeo.com/334329052/81b45f63cf"},{"student_id":67,"student_name":"Joohyun Park","student_slug":"joohyun-park","advisor_name":"Gregory Shakar","title":"Unknown Universe","thesis_statement":"Unknown Universe is an aesthetic web VR experience of an imagined world beyond the observable universe.","abstract":"The way our universe is designed and unfolding resonates with me. As an artist and as an engineer, I view the indefiniteness of the universe as highly potential. Yes, most part of our universe remains unresolved. And that’s where Unknown Universe starts from. <br><br>\r\n\r\nThe Unknown Universe is a web VR exploration aimed at people with a strong curiosity to the outer world. Amongst different terms, I describe this project as a web art. I would like to invite you to the cosmic world I imagine. It is the multidimensional scene with hidden interaction. Also, the aesthetic experience delivered through technology-driven expression. <br><br>\r\n\r\nWhat is out there?  While fully addressing it will require a significant amount of time, I hope Unknown Universe takes us one step closer to wonders of the universe.","context_research":"My research concentration as an artist was to make the experience visually engaging with a little touch of sound. All components should be delineated in a creative and distinctive context, but at the same time, they must reflect the reality to some extent. I tried to get resource from diverse areas and frame them subtly. The inspiration for each part is as follow. <br><br>\r\n\r\n- Narrative: NASA Exoplanet Archive, Michio Kaku, Stephen Hawking, Carl Sagan, Arthur C. Clarke, René Magritte, Planet Earth (BBC)<br>\r\n- Visual: NASA Hubble Space Telescope Images, Wonders of the Universe (BBC), Hans Zimmer, Max Richter<br>\r\n- Sound: Symphonies of the Planets (Nasa Voyager Recordings), NASA Sound Library\r\n<br><br>\r\nAs an engineer, my research focus was implementing the accessible VR experience, state-based interaction aligned with narrative, and suitable use of high-performance web graphics. Although the outcome was excluded for the final version, research on sound generation process using neural networks (NSynth, WaveNet, Sample RNN) has been done in the early stage of the project for pursuing additional possibilities. \r\n","thumbnail_image":{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/UU-Thumbnail-1024x576.jpg","title":"Unknown Universe","alt":"Unknown Universe","caption":""},"headshot_image":{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/jhp-1.jpg","title":"jhp","alt":"jhp","caption":""},"slide_show":[{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/scenee-1024x576.png","title":"Unknown Universe","alt":"Unknown Universe","caption":""},{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/scene2-1024x576.png","title":"Unknown Universe","alt":"Unknown Universe","caption":""},{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/scene-1024x576.png","title":"Unknown Universe","alt":"Unknown Universe","caption":""},{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/sss-1024x576.png","title":"Unknown Universe","alt":"unknown universe","caption":""},{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/sceneee-1024x576.png","title":"Unknown Universe","alt":"unknown universe","caption":""}],"tags":[{"name":"Art","slug":"art"}],"video_presentation_url":"https://vimeo.com/336826412","video_documentation_url":""},{"student_id":78,"student_name":"Kai","student_slug":"kai","advisor_name":"Kathleen Stevens Wilson","title":"World Loader","thesis_statement":"World Loader is a machine learning powered Unity plugin which aims to accelerate 3D content production workflow. It takes a single 2D image as an input and generates the environment reflected in it through object detection techniques. The result is a scene composed of independent models 3D artists can use to edit the scene after generated.","abstract":"World Loader is a machine learning powered Unity plugin which aims to accelerate the workflow of 3D content production, and it’s also a prototype of a futuristic content creation tool. World Loader takes a 2D image as input and outputs a 3D scene which reflects the environment in the 2D picture. The objects in the generated scene are stand-alone models from the asset and can be edited and swapped, so it’s not just a single mesh with pixels as textures on it. It conserves the context of the environment. Therefore, animation artists can be very flexible as they work with 3D software to develop real-world environments. I expect this could be very helpful in the process of matte painting and composition. Moreover, as we pursue more immersive experiences, being able to copy or map the real world into virtual space is also appealing. \r\nThe plugin combines a set of different pre-trained machine learning models. Each of them is in charge of a different functionality that enables the construction of the whole scene. The Detectron from Facebook Research is in charge of object detection which is able to provide the (x,y) coordinate and object name. The depth estimation model is in charge of the (z) coordinate in the space. The 3D Bounding Box Estimation model outputs the rotation of objects. ","context_research":"Image processing through machine learning is an essential part of this project. To be able to reconstruct a 3D scene based on a 2D image, we need the computer to read more information than just pixels. The research keywords related to this topic are those in the field of 3D machine learning, which includes \"multiple objects detection”, \"scene synthesis/reconstruction”, \"scene understanding”, “3D pose estimation”, “3D bounding box estimation”.  The following projects are especially meaningful references for my project.<br><br>\r\nSoccer On Your Tabletop:<br>\r\nThis project presents a system that transforms a monocular video of a soccer game into a moving 3D reconstruction, in which the players and field can be rendered interactively with a 3D viewer or through an Augmented Reality device. The team uses the MaskCNN algorithm to train on 3D player data extracted from soccer video games. How they compare with state of the art body pose and depth estimation techniques is a really useful technique for my project.\r\n<br><br>\r\nHolistic 3D Scene Parsing and Reconstruction from a Single RGB Image(ECCV2018):<br>\r\nThis team presents an analysis-by-synthesis framework to recover the 3D structure of an indoor scene from a single RGB image using a stochastic grammar model integrated with latent human context, geometry, and physics. Specifically, they introduce a Holistic Scene Grammar (HSG) to represent the 3D scene structure, which characterizes a joint distribution over the functional and geometric space of indoor scenes. This solves the joint parsing and reconstruction problem. Actually, they did most of the things I want to do with a more robust method. However, the scene is still limited to an indoor environment and they are a pure technical research project so they don’t propose applications in real use. (discovered this near the end of the thesis.)","thumbnail_image":{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/2-768x435-1.png","title":"2-768x435","alt":"image","caption":""},"headshot_image":{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/2H6A0017-768x512-1.jpg","title":"2H6A0017-768x512","alt":"kai headshot","caption":""},"slide_show":[{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/img03-1.jpg","title":"img03","alt":"image 3","caption":""},{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/0-768x480-1.png","title":"0-768x480","alt":"image4","caption":""},{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/1-768x480-1.png","title":"1-768x480","alt":"image 5","caption":""}],"tags":[{"name":"3D","slug":"3d"},{"name":"Design","slug":"design"},{"name":"Machine Learning","slug":"machine-learning"},{"name":"Tool","slug":"tool"}],"video_presentation_url":"https://vimeo.com/336836579","video_documentation_url":"https://youtu.be/RPMpUWFpSy0"},{"student_id":82,"student_name":"Katya Rozanova","student_slug":"katya-rozanova","advisor_name":"Gregory Shakar","title":"Sound Playground","thesis_statement":"Sound Playground is a tactile, semi-autonomous ecosystem of objects that emit sound to communicate with one another when they want to but that you can also collaborate with by triggering some of their sonic behaviors. One can linger with these objects alone or in a group. ","abstract":"Sound Playground consists of a set of objects that emit sound upon being moved, touched, placed next to other objects, and activated by outside sounds. The system is semi-autonomous - the objects have a degree of agency. They can emit sound when they want to, sometimes triggering one another’s sonic behaviors. They can decide when they want to react to your tactile or sonic input and when to refuse cooperation by going into sleeping mode. They can decide which sonic behaviors to exhibit at a given time. Finally, they can decide when to record small snippets of environmental sound in order to insert them to an ongoing composition and when to play this composition back into the world. <br><br>\r\n\r\nDue to the ever-shifting behaviors of this, rather punky, rebellious, Sound Playground, your experience with it will never be the same. However, you may be able to notice patterns as you get to know the personality of each sound object and as you observe the socialites that these objects form with one another. While you, as the human, are gently decentralized, you can impress your sounds and interactions onto the playground’s memory, shaping some of its current and future behaviors. I call this collaboration. <br><br>\r\n\r\nThe goal of this project is to create a meditative environment where you can focus on tactile sensations and create sounds with an opaque, autonomous ecosystem by observing and discovering its properties. It is also an opportunity to be with technology that demands respect and that respects your opacity in return. Neither party is expected to be fully knowable in order for collaboration to happen. This experiment aims to examine the effects of such encounters. \r\n<br><br>\r\nSound Playground explores several themes. Opacity, object agency, tactility and sound, therapeutic play, abstracted anthropomorphism, awkwardness of form, relationally, and the intersection of labor and art. The experience invites people to linger and examine how they relate to human and non-human elements alike.\r\n","context_research":"Inspirations:\r\n<br>\r\nJulianne Swartz, Sine Body,<br>\r\nEmily Counts’s Super Mode,<br>\r\nDavid Bernstein’s Bureau of Unspecified Services (B.U.S.),<br>\r\nRosa Sijben and David Bernstein’s “Something to Hold On To”,\r\nFoo/Skou,<br>\r\nMICRO -double helix- by Purring Tiger,<br>\r\nThe Situationist International’s Drifting and Psychogeography observation practice, <br>\r\nDada works that break away from “rationality”<br>\r\nElaine Gan’s work within the Actor Network practice, <br>\r\nI/O: Chamber of a Musical Composer by Yuko Mohri<br>\r\n<br>\r\nGrant:<br>\r\nI received the Fall '18 Prototyping Fund from the Tandon School of Engineering to create a prototype for a Sound Playground with an emphasis on tactile and sonic therapy. The objects would eventually live in waiting rooms in hospitals in order to quiet the mind of patients under stress. While the current iteration of Sound Playground exists as a meditative experience agnostic of place, I feel it still offers people a therapeutic experience and can be used in hospitals and other waiting rooms when the . \r\n<br><br>\r\nSome Readings:<br>\r\n\r\nJohn Cage, Chance Operations, and the Chaos Game: Cage and the \"I Ching” by Marc G. Jensen<br>\r\nJohn Cage: Crafting Randomness by Warren A. Burt<br>\r\nNature's Queer Performativity by Karen Barad<br>\r\nAlien phenomenology by Ian Bogost<br>\r\nPrince of Networks: Bruno Latour and Metaphysics By  Graham Harman <br>\r\n<br>\r\nExpert Interviews:<br>\r\n\r\nElaine Gan, Actor-Network practitioner, professor, Experimental Humanities Department, NYU. <br>\r\nDevi Sambouka, Brooklyn-based sound therapist.","thumbnail_image":{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/picnic_main_1280720-1024x576.jpg","title":"picnic_main_1280720","alt":"Sound Playground thumbnail image","caption":"Sound Playground thumbnail image"},"headshot_image":{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/photo_katyarozanova_1280_720-768x432-1.jpg","title":"photo_katyarozanova_1280_720-768x432","alt":"katya headshot","caption":""},"slide_show":[{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/1920_1080_slide_soundplayground-1024x576.jpg","title":"1920_1080_slide_soundplayground","alt":"sound playground","caption":"sound playground"},{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/1920_1080_slide_soundplayground_PERSON-1024x576.jpg","title":"Someone setting a sound object into motion","alt":"Someone setting a sound object into motion","caption":"Someone setting a sound object into motion"},{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/only_plays-1024x576.jpg","title":"Object that only plays 5 - 8","alt":"Object that only plays 5 - 8","caption":"Object that only plays 5 - 8"},{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/composition_changers_over_time-1024x576.jpg","title":"composition that changers over time","alt":"composition_changers_over_time","caption":"composition_changers_over_time"},{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/object_that_only_works_in_november-1024x576.jpg","title":"object_that_only_works_in_november","alt":"object_that_only_works_in_november","caption":"object_that_only_works_in_november"}],"tags":[{"name":"Art","slug":"art"},{"name":"Experiment","slug":"experiment"},{"name":"Installation","slug":"installation"},{"name":"Play/Games","slug":"play-games"}],"video_presentation_url":"https://vimeo.com/336826625","video_documentation_url":"https://vimeo.com/331363550"},{"student_id":124,"student_name":"Keerthana Pareddy","student_slug":"keerthana-pareddy","advisor_name":"Nancy Hechinger","title":"Ensemble","thesis_statement":"‘Ensemble’ is a multi-sensory collaborative game for children ages 6-9, on the concept of springs in physics. It explores interaction models that foster both learning through play and nurturing mutual care among the group of children. These models can be integrated into various learning applications that I hope to introduce in low resource schools in India. ","abstract":"'Ensemble' is a multi-sensory collaborative game on the concept of springs in physics. It invites four 6-9 year old children to play together to understand the concepts of force and motion displacement in springs. Using a tangible controller that mimics the physics of spring, children work together to reveal pictures on a projected tabletop board. Adding sound to the game further enriches the play. \r\n <br><br>\r\nThey pass the controller around for multiple rounds until the entire image is revealed on the game board. Interpersonal interactions are designed to invoke patience and collaboration among children. Initial user tests show that the interaction works as predicted.\r\n","context_research":"Government schools in India have low resources with respect to the budget, equipment, infrastructure, and staff(teachers, lab staff, etc). During my exploratory research, I visited 3 such schools in India and was appalled to see a lack of practical learning in these schools. Thus placing the students at a disadvantage for the current world. I learned that the schools have televisions, projectors, and computers - but for the most part they don’t work or are not used. So how can I use technology to turn these non-working labs into playgrounds of Physics and Chemistry, using the existing resources?\r\n\r\nJulia Atkin in Chapter 3 of \"Designing for Education, Transforming Spaces for Learning\" summarizes learning in five points that guide my approach to designing for learning. My research has revealed the importance of promoting and nurturing social relationships at a young age, especially for children from low-income communities and troubled families. When students notice the value of their input and effort, a more internal locus of control and belief in one's ability is fostered, thus embedding social and work skills. This further strengthened my desire to design a collaborative environment for learning through play.\r\n\r\nTraditional board games are so much fun and benefit children's mental development. They strengthen executive functions such as working memory, inhibitory control, cognitive flexibility and also foster social skills through collaboration and negotiation. However, traditional board games lack the interactivity of a screen device that kids love and have endless options for content. 'Ensemble' is an amalgamation of the two mediums that encourages learning through collaborative play.\r\n","thumbnail_image":{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/thumbnail-18-1024x576.jpg","title":"thumbnail","alt":"Project image of 'ensemble'. A picture projected on the game board with a controller on the side.","caption":""},"headshot_image":{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/picture-768x432-1.jpg","title":"picture-768x432","alt":"keerthana","caption":""},"slide_show":[{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/gameboard_collage-1024x576.jpg","title":"gameboard_collage","alt":"A collage of 4 pictures. In picture 1 the controller is green, picture 2 it is yellow, picture 3 blue and picture 4 red.","caption":""},{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/controller_archive-1024x576.jpg","title":"controller_archive","alt":"hand holding the controller","caption":""},{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/controlleR_pull_archive-1024x576.jpg","title":"controlleR_pull_archive","alt":"Hand pulling the handle of the controller","caption":""}],"tags":[{"name":"Design","slug":"design"},{"name":"Education","slug":"education"},{"name":"IOT","slug":"iot"},{"name":"Play/Games","slug":"play-games"},{"name":"UX","slug":"ux"}],"video_presentation_url":"https://vimeo.com/337314277","video_documentation_url":""},{"student_id":76,"student_name":"Kellee D Massey","student_slug":"kellee-d-massey","advisor_name":"Nancy Hechinger","title":"The Field Guide to the Black Experience","thesis_statement":"The aim of this auditory sound walk through Harlem, is to give others an insight to the experiences that Black people have as they navigate their world. These experiences are told in the form of auditory conversations and narratives, told by the people I interviewed, in their own voices.  ","abstract":"I’m investigating the experiences black children and young adults have as they learn to navigate their world. Specifically, building a narrative around ‘the talk’, police brutality, navigating environments, and situations dealing with authority figures.<br><br>\r\n\r\nThe Talk, narrowly defined, is a conversation Black parents/parental figures have with their children to tell them how to act when dealing with police/authority figures, in the hope that they come home alive at the end of the encounter.  More broadly, the talk can encompass other situations that, as Black people, we have to consider to navigate the world we live in.  The conversations found in the field guide, often begin with the talk and continue into a broader range of conversation.  \r\n<br><br>\r\nThese conversations will be heard while a person walks through Harlem.  By having the user listen to people telling their own stories, while walking through a neighborhood steeped in Black history, it is my hope to not only engage the user, but also to bring about a sense of empathy.  \r\n<br><br>\r\nThese conversations are honest, raw, and deal with sensitive topics that can be upsetting to some people.  Still, I feel like these conversations are important to have in the hopes of starting conversations. \r\n<br><br>\r\nThere will also be a call to action section that will give the audience resources on steps that they can take to be more aware of what’s going on around them, and how to be better allies. \r\n","context_research":"My research has been a combination of readings, museum visits, interviews, watching news clips, and exploring technologies that could be used to tell a narrative. I’ve looked at VR and 360 video projects, as well as listened to audio guides(sound walks), and podcasts. <br><br>\r\n\r\nSimilar projects that I looked at initially VR projects, as I was initially hoping to do a VR project.  Even with the pivot to an audio piece, I feel that those projects are still relevant based on the topics, and the way they handled the subject matter. \r\n<br><br>\r\n‘The Talk: Race in America’ is an example of this.  It covers a very timely and sensitive topic with vulnerability and care.  These are stories and experiences that are difficult to tell and hear, and while it could be easy to turn it into a sad and depressive piece, there’s a underlying theme of resilience. \r\n","thumbnail_image":{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/user-test-768x895-1.jpg","title":"user test","alt":"user test","caption":""},"headshot_image":{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/headshot-7-1024x990.jpg","title":"headshot","alt":"headshot of Kellee Massey","caption":""},"slide_show":[{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/user-test-879x1024.jpg","title":"user-test","alt":"picture of user accessing the field guide on mobile phone","caption":""},{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/IMG_5644-1-225x300-1.jpeg","title":"user test","alt":"user test","caption":""}],"tags":[{"name":"Culture","slug":"culture"},{"name":"Identity","slug":"identity"},{"name":"Justice","slug":"justice"},{"name":"Narrative/Storytelling","slug":"narrative-storytelling"},{"name":"Social Good/Activism","slug":"social-good-activism"}],"video_presentation_url":"https://vimeo.com/337314114","video_documentation_url":""},{"student_id":80,"student_name":"Kimberly Lin","student_slug":"kimberly-lin","advisor_name":"Kathleen M Sullivan","title":"Super Frustrated NYC Modern Love Stories","thesis_statement":"Super Frustrated NYC Modern Love Stories is a living archive of location based audio stories that provides a glimpse into how millennials date in New York City.","abstract":"For many millennials, finding romantic love in digital age New York City appears to be unbearably challenging. We are active participants in the swipe economy which attempted to disrupt romance but actually sabotaged our love lives. After the launch of Tinder in 2012, online dating is now the norm. We re-invented heterosexual relationships in self-destructive ways: we added ghosting to communication and regard monogamy as an outdated idea. Why not? Unlimited choices are presented right in front of us! Paradoxically, in a hidden corner of our subconscious, we still expect our date to text back to us and somehow hope to find the one big love of our life. Yes, I am one of these millennials who is burned out by modern dating. But instead of staying unhappily single and questioning our approaches, maybe we should collectively voice out our hopes and disappointments of this NYC phenomenon. Let’s honor our stories as solace to those who shared the same frustrations and entertaining guidance for those who did not have the opportunity to experience our dating culture.","context_research":"Inspired by speculations on future romance like Spike Jonze’s “Her”, Yorgos Lanthimos’ “The Lobster”, Black Mirror’s “Hang the DJ”, Gary Shteyngart’s “Super Sad True Love Story” and love cliches from early 2000s romantic comedies like Donald Petrie’s “How to Lose a Guy in 10 Days” and Darren Star’s “Sex and the City”, Super Frustrated NYC Modern Love Stories depicts how millennials currently fall in love in the age of online dating. Who cares? Popular books about contemporary relationship like Aziz Ansari’s “Modern Romance” and Blythe Roberson’s “How to date men when you hate men” as well as Netflix’s recently released reality TV show “Dating Around” confirm that there is a fairly high demand for this subject. Millennials who are single and dating like to talk about their experiences that many of those who are not part of the group enjoy listening to. Super Frustrated NYC Modern Love Stories re-imagined New York Times Modern Love essays, Overheard New York’s Instagram posts and Humans of New York’s photo journal through voice and space. It provides you a series of audio stories that pop up on a mobile site as you walk through New York City. Why voice? Ansari discussed in his book that many millennials are terrified of phone calls as our ability to converse spontaneously weakens in a text-filled world. It is time to rebuild what we have lost and reintroduce voice into our lives. \r\n<br><br>\r\n\r\nWorks Cited: <br>\r\nAnsari, A. (2016). Modern romance. London: Penguin Books.<br>\r\nBarden, Evan Ford. “One Hundred Dates.” One Hundred Dates, 6 Jan. 2014, onehundreddates.com.<br>\r\nDating Around, created by Chris Culvenor, season 1, Netflix, 14 Feb. 2019.<br>\r\nFisher, H. E. (2005). Why we love: The nature and chemistry of romantic love. New York: St. Martins Griffin.<br>\r\n“Hang the DJ .” Black Mirror. Directed by Tim Van Patten, written by Charlie Brooker, season 4, episode 4, Netflix, 29 Dec. 2017.<br>\r\nJones, Daniel, editor. “Modern Love.” The New York Times, www.nytimes.com/column/modern-love.<br>\r\nJonze, Spike, director. Her. Warner Bros. Pictures, 2014.<br>\r\nLanthimos, Yorgos, director. The Lobster. A24, 2016.<br>\r\n“Overheard New York.” Overheard New York, www.instagram.com/overheardnewyork/?hl=en.<br>\r\nPetrie, Donald, director. How to Lose a Guy in 10 Days. Paramount Pictures, 2003.<br>\r\nRoberson, B. (2018). How to date men when you hate men. New York: Flatiron Books.<br>\r\nSex and the City, created by Darren Star, HBO, 6 June 1998.\r\nShteyngart, G. (2011). Super Sad True Love Story. Random House Trade Paperbacks.<br>\r\nStanton, Brandon. “Humans of New York.” Humans of New York, 4 Sept. 2010, www.humansofnewyork.com/.<br>\r\nW. (2019, February 13). Machine Love: Dating in the Digital Age [Audio blog post]. Retrieved from https://www.wsj.com/podcasts/wsj-the-future-of-everything/machine-love-dating-in-the-digital-age/6ba51076-d036-436e-a5b7-f68d5889dd1c<br>","thumbnail_image":{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/logo_16by9-1024x683.jpg","title":"logo_16by9","alt":"Logo","caption":""},"headshot_image":{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/small-768x432-1.jpg","title":"small-768x432","alt":"kim headshot","caption":""},"slide_show":[{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/16to9_main_small-1024x576.jpg","title":"Super Frustrated NYC Modern Love Stories","alt":"An iphone with a screen display of Super Frustrated NYC Modern Love Stories, headphones and an upside down dead flower.","caption":""},{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/P1150940-1024x576.jpg","title":"Super Frustrated NYC Modern Love Stories","alt":"A couple sitting in the park sharing a pair of headphones while listening to dating stories from Super Frustrated NYC Modern Love Stories.","caption":""},{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/keybar-16-1024x576.jpg","title":"Super Frustrated NYC Modern Love Stories","alt":"Three girlfriends listening to dating stories from Super Frustrated NYC Modern Love Stories at a bar.","caption":""},{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/keybar-2-1024x576.jpg","title":"Super Frustrated NYC Modern Love Stories","alt":"Three girlfriends listening to dating stories from Super Frustrated NYC Modern Love Stories at a bar.","caption":""},{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/UX.001-1024x576.jpeg","title":"Super Frustrated NYC Modern Love Stories","alt":"Super Frustrated NYC Modern Love Stories user journey.","caption":""}],"tags":[{"name":"Art","slug":"art"},{"name":"Culture","slug":"culture"},{"name":"Identity","slug":"identity"},{"name":"Mobile","slug":"mobile"},{"name":"Narrative/Storytelling","slug":"narrative-storytelling"}],"video_presentation_url":"https://vimeo.com/336826561","video_documentation_url":"https://vimeo.com/333329541"},{"student_id":77,"student_name":"Krizia Fernando","student_slug":"krizia-fernando","advisor_name":"Stefani Bardin","title":"Emojispeak: Accessible Emojis","thesis_statement":"EmojiSpeak is a platform that attempts to expose how emoji is currently interpreted on screenreaders, through a text-to-speech message board simulator; and a community-driven emoji dictionary to mitigate its visual inequity on the web. The goal of a crowdsourced dictionary is to encourage culturemaking between sighted allies and blind users.","abstract":"The rise of “visual content as interface” on touch screens and mobile devices has paved the way for users to adopt emojis in daily conversations since 1999 when Shigetaka Kurita first released the original 176 emoji for mobile phones, through Japanese telecom, NTT DOCOMO.<br><br>\r\n\r\nIn recent years, emoji has evolved in usage as it started appearing in court documents, and in 2015, the “Face with Tears of Joy” emoji landed as the Oxford Dictionary Word of the Year.\r\n<br><br>\r\nAs online interactions become increasingly visual and less accessible to people with vision impairments, I’m proposing to redesign emoji through a platform that enables a community to redefine emoji’s context, its usage and meaning, through a crowdsourced dictionary and a message board simulator with Text-to-Speech.<br><br>\r\n \r\nMy project aims to inquire about the visual inequity of emoji’s. Who is excluded from this social phenomenon? How do emojis appear in screenreaders? Microsoft’s Inclusive Design Toolkit encourages that designers find touchpoints of exclusion in their design process. Their principle is heavily inspired by the Social Model of Disability, which states that “Removing barriers creates equality and offers disabled people more independence, choice and control.” The Social Model of Disability is a new way of approach that contradicts medical model of disability which focuses on people as being disabled by their impairments or differences. The medical model looks at what is 'wrong' with the person, not what the person needs. This creates low expectations and leads to people losing independence, choice and control in their lives.","context_research":"The objective of the research is to explore emoji through the lens of web accessibility, and conduct a “solve for one, extend to many” inclusive design principle ultilized by Microsoft. The research is based on a case study with a completely blind user, who uses three applications to tweet a message with emoji.\r\n<br><br>\r\nDo emoji present visual inequity in communication? Frequent exchange of visual media like memes, gifs or emoji contribute to “Glance Culture”, a term coined by Damon Rose, a blind BBC reporter. Rose exposes the barrier that emoji presents in communication, in which he stated that emoji adds to an exclusionary experience for the blind community as it is used frequently with not much reference.<br><br>\r\n\r\nFor this particular study, the researcher will be focusing on visually impaired users. CDC reports that there are twenty-one million Americans report functional vision problems or eye conditions that may compromise vision.\r\n<br><br>\r\nBased on key findings that came out of the initial user research, there are two main challenges that contribute to the visual inequity of emoji: Firstly, existing technical barriers, or how descriptions are read through screenreaders. This is a texting etiquette issue for blind users which excludes them from the culture of using emoji. Secondly, existing language barrier of emoji becoming a substitutive and highly visual language. Emoji leans toward oculo-centricism/visual first bias of graphical user interfaces, to compensate for the inability to convey facial expression, tone of voice and gesture in digital communication.","thumbnail_image":{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/Thumbnail-1-1024x576.png","title":"Logo Thumbnail","alt":"Draft Logo of EmojiSpeak","caption":"Hand-drawn emoji with words Have You Heard Emoji Speak?"},"headshot_image":{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/Headshot-768x432-1.png","title":"Headshot-768x432","alt":"krizia headshot","caption":""},"slide_show":[{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/Thesis-Slideshow-2-Copy-1024x576.png","title":"Emoji Dictionary","alt":"Homepage of EmojiSpeak","caption":"EmojiSpeak dictionary enables the Accessibility co-create emoji descriptions and usage context aka Urban Dictionary of emojis"},{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/Thesis-Slideshow-2-1024x576.png","title":"Emoji Composer","alt":"Text to Speech Message Board","caption":"This platform plays the description of the emoji to expose possible inaccessible description"},{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/Thesis-Slideshow-5-1-1024x576.png","title":"Case Study - Blind Participant","alt":"Laptop screen showing 3 apps","caption":"Composer is inspired by collapsing all 3 of the apps a blind user uses to send a tweet with Emoji"},{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/Thesis-Slideshow-1-1024x576.png","title":"Sketches","alt":"3 sketches that contain a chatbot","caption":"Initial Designs leverage existing solutions for predicting search, and other Voice UI options such as a chatbot to define emoji"},{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/Thesis-Slideshow-1-Copy-1024x576.png","title":"Inclusive Design","alt":"Photo of mobile with emoji keyboard and Persona Spectrum addressing emoji keyboard problem","caption":"For future considerations, the designer attempts to expand the use case to redesign the emoji keyboard"}],"tags":[{"name":"Accessibility","slug":"accessibility"},{"name":"Culture","slug":"culture"},{"name":"Design","slug":"design"},{"name":"Speech","slug":"speech"},{"name":"UX","slug":"ux"}],"video_presentation_url":"https://vimeo.com/336817812","video_documentation_url":"http://emojispeak.net"},{"student_id":85,"student_name":"Lauren Race","student_slug":"lauren-race","advisor_name":"Stefani Bardin","title":"Designing Tactile Schematics","thesis_statement":"To make electronics more accessible to blind and low vision learners, a set of design standards and best practices were developed for converting schematics into tactile schematics.","abstract":"Accessibility is the heart of experience design because it’s not usable if it’s not accessible. For a sighted designer, it’s an opportunity to improve the design process since understanding the user’s needs require listening to and working alongside them to design something together. <br><br>\r\n\r\nThe particular accessibility use case came from making the Physical Computing coursework more accessible, since the schematics on the class’s site are images. While sighted learners rely on schematic images, blind and low vision learners rely on circuit descriptions to understand how electronics work. No graphical representation has yet been able to compete with circuit descriptions. This pain point became the focal point of the subsequent design research.\r\n\r\nUsing participatory and human-centered design with 5 blind and low vision participants through NYU’s Institutional Review Board (IRB), a set of design standards and best practices were developed to illustrate how to design a readable tactile schematic. These standards were then applied to the 50+ schematics from the Physical Computing site. The standards and best practices and book of tactile schematics were made available for download by the public.\r\n","context_research":"Competitive analysis disclosed that there are electronics educational resources for blind and low vision learners with different learning styles: verbal descriptions or interactive simulations for auditory learning, Braille translations for reading/writing learning, blind Arduino workshops for constructivist learning, and tactile graphics for kinesthetic/tactile learning (the focus of this research).\r\n<br><br>\r\nIn order to determine the optimal design standards and best practices for tactile schematics (labeling, scaling, layout, and contrast), a usability study was conducted through NYU’s IRB with 5 low vision and blind participants, ranging in learning style, finger variables (sensitivity and size), electronics experience, Braille literacy, and level of vision. Learners were presented with tactile versions of The Big 6, or the six schematics crucial to understanding Physical Computing, given informed consent, a series of tasks, and follow up questions.","thumbnail_image":{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/Designing-Tactile-Schematics-3-1024x576.jpg","title":"Designing Tactile Schematics","alt":"Close up of two hands exploring a tactile schematic.","caption":""},"headshot_image":{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/LRace-4-768x432-1.jpg","title":"LRace-4-768x432","alt":"lauren race headshot","caption":""},"slide_show":[{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/LED-Regulator-Resistor-Before-1024x576.jpg","title":"LED Resistor Regulator Before","alt":"Schematic of an LED, Resistor, Regulator in Series, downloaded from the Physical Computing site, before the re-design. It doesn't have Braille labels, optimal sized components, or consistent lines.","caption":"Schematic of an LED, Resistor, Regulator in Series, downloaded from the Physical Computing site, before the re-design."},{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/LED-Regulator-Resistor-After-1024x576.jpg","title":"LED Resistor Regulator After","alt":"Hands exploring one of the final iteration of the LED, Resistor, Regulator in Series schematic after the re-design. There's Braille labels, optimal sized components, and consistent lines.","caption":"One of the final iteration of the LED, Resistor, Regulator in Series schematic after the re-design."},{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/Style-Guide-Example-Page-1-1024x576.jpg","title":"Style Guide Example Page 1","alt":"Example page from the style guide that shows how to set the Braille and text minimum/maximum font sizes.","caption":"Example page from the style guide that shows how to set the Braille and text minimum/maximum font sizes."},{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/Style-Guide-Example-Page-2-1-1024x576.jpg","title":"Style Guide Example Page 2","alt":"Example page from the style guide that shows optimal measurements, in inches, of common circuit components.","caption":"Example page from the style guide that shows optimal measurements, in inches, of common circuit components."},{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/Style-Guide-Example-Page-3-1024x576.jpg","title":"Style Guide Example Page 3","alt":"Example page from the style guide that shows how to put .25 inch breathing room between all of your components for tactile clarity.","caption":"Example page from the style guide that shows how to put .25 inch breathing room between all of your components for tactile clarity."}],"tags":[{"name":"Accessibility","slug":"accessibility"},{"name":"Design","slug":"design"},{"name":"UX","slug":"ux"}],"video_presentation_url":"https://vimeo.com/336817936","video_documentation_url":"https://vimeo.com/331350194"},{"student_id":90,"student_name":"Lin Zhang","student_slug":"lin-zhang","advisor_name":"Kathleen Stevens Wilson","title":"Unwind &#8211; Conflict Resolution for Daily Practice","thesis_statement":"Unwind is a set of voice-controlled exercises that help young professionals to better understand others and resolve conflicts in collaborative work environments.","abstract":"In our modern work environment, knowledge-based professionals not only need to have the skill to perform complicated project goals and tasks, they also need to learn how to navigate and negotiate creative differences with their co-workers, supervisors, and clients.\r\n<br><br>\r\nWith this goal in mind, Unwind is designed to help young professionals with their daily work-related challenges and improve their ability to handle difficult situations.\r\n<br><br>\r\nUsing Unwind is easy. All you need to do is download the Google Assistant App or use Google Home device and say, “Talk to unwind”.  Then, Unwind will provide you with a series of questions and exercises to help guide you through a daily exercise review.","context_research":"My research for this project includes literature on conflict resolution, in-person experience with a professional mediator, testing out existing self-improvement apps, and technical documentation. Each category is listed as below:\r\n<br><br>\r\nLiterature on conflict resolution:\r\n<br><br>\r\nStone, Douglas, Bruce Patton, and Sheila Heen. Difficult Conversations: How to Discuss What Matters Most. New York, N.Y: Penguin Books, 2000.<br>\r\nFisher, Roger, Bruce Patton, and William Ury. Getting to Yes: Negotiating Agreement Without Giving in. Rev. ed. New York: Penguin Books, 2011.<br>\r\nRandolph, Paul. Psychology of Conflict: Mediating in a Diverse World. Bloomsbury Publishing, Feb 25, 2016.<br>\r\nTwo one-on-one session with Assistant Director for student conduct and conflict resolution, Colleen Maeder.<br>\r\n<br>\r\nFirst session we identified my personal conflict style and discussed differences between styles, and introduced PIN model of conflict resolution<br>\r\nColleen talk though a conflict in my life to using PIN model\r\nSecond session we further discussed listening and communication skills<br>\r\n<br>\r\nSimilar Products / Projects:<br>\r\n<br>\r\nRelax Guru<br>\r\nHeadspace<br>\r\nLucky Trivia<br>\r\nMusical Chair<br>\r\n<br>\r\nTechnical Documentations and books:<br>\r\n<br>\r\nHall, Erika. Conversational Design.  A Book Apart, Mar 6, 2018<br>\r\nGoogle, “Conversation Design”. Google, 2018, designguidelines.withgoogle.com/conversation/conversation-design/welcome.html<br>\r\nGoogle, “Building Actions for the Google Assistant (Level 1)”, Google, 2018, codelabs.developers.google.com/codelabs/actions-1/#0<br>\r\nGoogle, “Building Actions for the Google Assistant (Level 2)”, Google, 2018, codelabs.developers.google.com/codelabs/actions-2/#0<br>\r\nAmazon, “Alexa Voice Service Tutorials”, Amazon, https://developer.amazon.com/alexa-voice-service/learn","thumbnail_image":{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/thumbnail-9-1024x576.jpg","title":"Unwind","alt":"a person using unwind at the end of the day to relax and review","caption":"a person using unwind at the end of the day to relax and review"},"headshot_image":{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/default.png","title":"default","alt":"default","caption":""},"slide_show":[{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/thumbnail-9-1024x576.jpg","title":"Unwind","alt":"a person using unwind at the end of the day to relax and review","caption":"a person using unwind at the end of the day to relax and review"},{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/dan-farrell-unsplash-768x512-1.jpg","title":"dan-farrell-unsplash-768x512","alt":"image4","caption":""},{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/slideshow2-768x512-1.jpg","title":"slideshow2-768x512","alt":"image5","caption":""}],"tags":[{"name":"Business","slug":"business"},{"name":"Culture","slug":"culture"},{"name":"Identity","slug":"identity"},{"name":"Self-care","slug":"self-care"},{"name":"Tool","slug":"tool"}],"video_presentation_url":"https://vimeo.com/336836664","video_documentation_url":"https://vimeo.com/331479004"},{"student_id":86,"student_name":"Lucas Kuen Kule'a Chung","student_slug":"lucas-kuen-kule'a-chung","advisor_name":"Kathleen Stevens Wilson","title":"Shush?","thesis_statement":"Shush? is an installation that reacts to the noise levels of a space. Comprising a series of sensor nodes that are outfitted with kinetic “bloom” structures, Shush? provides a visual representation of activity within an area.","abstract":"What happens when our surroundings are given the capacities once limited to our phones and computers? Will they then also strive to capture our attention for their own ends? Shush? is an installation that I hope will offer an alternative approach.\r\n<br><br>\r\nShush?’s own objectives are agnostic. It instead will exist just beyond the foreground of a person’s attention. It lives above the user and reacts only to sound. When noise levels are elevated, the nearest bloom structures will close, and when it is quiet again, the bloom structures will open again.\r\n<br><br>\r\nEach bloom/sensor node is supported by a wifi enabled microcontroller that will send information to a remote server. Each node also will await instructions on whether it will open or close. This allows easy calibration and recalibration in order to observe user behaviors, eccentric spatial conditions, and other unknown factors that need to be accommodated. \r\n<br><br>\r\nUltimately I hope to create an experience that shows that simple gestures can have a profound impact on our built environment while utilizing technologies that allow these interventions to be scalable, adaptable, and decentralized.","context_research":"Many of the ideas behind this project were inspired by the technologies that are becoming more affordable and easier to access. Additionally, I looked at some other installations that were made using similar tools with similar objectives.\r\n<br><br>\r\nI first looked at how to use a wifi enabled microcontroller as a sensor node, how to take the data recorded from each node and process it, and how to then remotely send instructions back. Much of this can be done using MQTT.\r\n<br><br>\r\nI then focused on what this installation will look like. How might it work? What will be the final visual cue that results from audio input. I came across “Diffusion Choir,” an installation that uses dozens of umbrella-shaped objects to open and close, and “Lift” an installation that reacts to temperature fluctuations in a room.\r\n<br><br>\r\nWhile considering the actual bloom structure of each node, I took inspiration from the work being done at the Jet Propulsion Laboratory on their Starshade project and the mechanics of Chuck Hoberman’s sphere objects.","thumbnail_image":{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/RENDERING01-1-1024x576.jpg","title":"RENDERING01","alt":"A pair of silhouettes of human figures stand in conversation beneath a series of shush units.","caption":"The machine is designed to scale and work concert with multiple units."},"headshot_image":{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/2H6A1860-768x512-1.jpg","title":"2H6A1860-768x512","alt":"lucas headshot","caption":""},"slide_show":[{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/archive-001-2-1024x682.jpg","title":"archive-001","alt":"A machine made of acrylic with stainless steel hardware. It comprises a ring of linkages that shrink and expand when it perceives sounds of varying levels below it.","caption":"Version 1 of the Shush? sound reactive machine."},{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/archive-003-3-1024x683.jpg","title":"archive-003","alt":"A closeup view of the shockmount mic holder on the underside of the shush machine","caption":"Each Shush unit is outfitted with a directional sound sensor and a shockmount microphone holder to isolate vibrations."},{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/isometric-1024x683.png","title":"isometric","alt":"An exploded diagram of a shush unit showing each part individually with labels identifying the electronics, stepper motor, accordion ring, microphone, and pvc pipe.","caption":"Exploded isometric diagram"},{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/RENDERING01-1-1024x576.jpg","title":"RENDERING01","alt":"A pair of silhouettes of human figures stand in conversation beneath a series of shush units.","caption":"The machine is designed to scale and work concert with multiple units."},{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/comp-copy-1024x683.jpg","title":"comp copy","alt":"The shockmount mic holder is made of rubber bands in tension supporting the microphone as a means of isolating vibrations. The stepper motor is held in place by acrylic brackets supported by stainless steel screws and aluminum standoffs. The electronics of the device are contained in a sandwich of two acrylic panels supported by standoffs as well.","caption":"Closeups of the shockmount mic holder, stepper motor and electronics enclosure"}],"tags":[{"name":"Architecture","slug":"architecture"},{"name":"Data","slug":"data"},{"name":"Design","slug":"design"},{"name":"Installation","slug":"installation"},{"name":"IOT","slug":"iot"}],"video_presentation_url":"https://vimeo.com/336836616","video_documentation_url":""},{"student_id":87,"student_name":"Luna Olavarria Gallegos","student_slug":"luna-olavarria-gallegos","advisor_name":"Gregory Shakar","title":"HOUSE PARTY FEDERATION","thesis_statement":"A set of digital and physical objects inspired by local music scenes across the Black Atlantic, which offer decentralized methods of distributing and consuming music.  \r\n","abstract":"“The triangle trade” is a historical term referring to the exchange of enslaved people and sugar cane between Africa and the Americas, which has evolved into the Atlantic trade infrastructure of the 21st century. What happens if we think about the triangle trade as an exchange of culture, not of just bodies and sugar? Through complicating this trade, new vectors are revealed and the boundaries of Euclidean geometry within trade routes become impractical to the reality in which we all live.\r\n</br> </br>\r\nThrough research of the music industry, as well as local music scenes in Colombia, Jamaica, Puerto Rico, Nigeria and Panama throughout the 70s, 80s and 90s, I demonstrate the ways in which the current music distribution and consumption infrastructure has failed artists in the very places which birthed pop-culture trends and I offer alternatives to this infrastructure. I propose that the introduction of the Internet did not solve issues of connection of artists with other artists, but rather creates new ways of obstructing conversation of diaspora. \r\n</br> </br>\r\nHOUSE PARTY FEDERATION is an archive of physical and digital objects and knowledges that recognize a greater Black-Atlantic network for what it is: a collection of places / times that constantly produce global pop culture. The project re-imagines what the triangle trade means to us. This is the most realistic place because it is the place in which all the conditions for our art have been created —the space in which we are not slaves, but Gods– creators of food, buildings, railways, canals and culture. ","context_research":"Much of my early research focused on the constraints of the global digital music industry, which disproportionately affects artists of the Global South through digital infrastructure as well as corporate and government censorship. These obstructions include Spotify not being available in much of the world, the raids the National Guard carried out on music stores in Puerto Rico in the 90s in order to stop the distribution of reggaeton tapes, elite algorithmic playlists favoring corporate artists, and Sony’s plans to defund all distribution for non-English speaking music internationally. \r\n</br> </br>\r\nTo offer alternatives to this system, I did in-depth research on various local music scenes and created three objects based on the sounds, aesthetics and political economies of those time/place manifestations of global pop culture. The three objects are below: \r\n</br></br>\r\nLa Red Radio is a user-generated map which provides an easy way to listen to music from across the globe. Artists (or fans) add their own music using a form which allows them to input a Youtube link. \r\n</br></br>\r\nLa de Ahora is an MP3 player that only works with a USB input. Pulling inspiration from Cuba's \"el paquete\", and potlatch \"gift-giving\" culture of indigenous people of the Pacific Northwest and Canada, the MP3 player imagines practice of intentional sharing of music as gift-giving. \r\n</br></br>\r\nReparation Machine is a prototype website that redirects listeners from one video to another video to highlight and uplift the music of artists that have been structurally uncompensated, robbed or erased. ","thumbnail_image":{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/Screen-Shot-2019-04-17-at-1.50.56-AM-1024x576.jpg","title":"map","alt":"map of the Black Atlantic","caption":""},"headshot_image":{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/default.png","title":"default","alt":"default","caption":""},"slide_show":[{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/Screen-Shot-2019-04-17-at-1.50.56-AM-1024x576.jpg","title":"map","alt":"map of the Black Atlantic","caption":""},{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/Screen-Shot-2019-05-09-at-9.27.32-PM-1024x577.png","title":"la red radio","alt":"screenshot of luna's la red radio","caption":"screenshot of la red radio"},{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/IMG_4846-1024x517.jpg","title":"IMG_4846","alt":"la de ahora mp3 player","caption":"la de ahora"},{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/Screen-Shot-2019-05-07-at-4.24.19-PM-1024x442.png","title":"reparation machine","alt":"reparation-machine","caption":"screenshot of luna's \"reparation machine\""}],"tags":[{"name":"Culture","slug":"culture"},{"name":"Justice","slug":"justice"},{"name":"Memory","slug":"memory"},{"name":"Music","slug":"music"},{"name":"Networks","slug":"networks"}],"video_presentation_url":"https://vimeo.com/336826667","video_documentation_url":"https://vimeo.com/333674769"},{"student_id":97,"student_name":"Mai Arakida Izsak","student_slug":"mai-arakida-izsak","advisor_name":"Adaora Udoji","title":"Salon109","thesis_statement":"Salon109 proposes a framework for creating meaningful connections in Social VR, by collaboratively constructing a space to safely start conversations and take ownership of the virtual world-building process.","abstract":"Salon109 is virtual place created on the High Fidelity social VR platform. While social dynamics in open virtual worlds have largely been unfavorable towards women, we have the means to create our own curated virtual places. Salons have historically been an important social force where women facilitate an exchange of ideas and culture in their living rooms. I am recreating this format within High Fidelity’s decentralized platform, which allows me to truly play host with my own domain and server. Like in the real salons, I can decide who can come in, who’s allowed to make changes, and best of all, I am able to invite my family and friends to create the world with me from within.\r\n<br><br>\r\nMy ethnic and cultural background is highly diasporic, and social VR metaverses represent a form of freedom wherein physical representations become less important, as we exist somewhere in the cloud. In a virtual social sphere, bodies are not threatened in the way some are in the physical world, allowing for the exchange of ideas and meeting new people without risk to physical safety. I have been developing my virtual identity, embodied in a unique avatar I uploaded, while extending my lifestyle to places that forsake geography.\r\n<br><br>\r\nThe collaborative creation of Salon109 takes place at https://hifi.place/salon, culminating in a virtual singing recital by my sister Aili. To best mitigate the reality that access to VR is limited, those without headsets are able to follow via a Youtube livestream and send in chat messages. When the space is in its final form, it will be packaged and sold at the High Fidelity marketplace on the blockchain for 1HFC (approx $0.01), as an offering to the platform.","context_research":"I began my research on networked virtual worlds with a project I developed in VRChat, Maispace, a safe place I call my virtual home. The privacy of the world allowed me to invite friends to explore the space, but I wanted to extend the project in a way that would allow me to host a semi-public space that others could contribute to as well. \r\n<br><br>\r\nOver the last year, I have been going to virtual events across several platforms, including Altspace, VRChat, and High Fidelity, in order to compare the community of each as well as new safety features and interactions. I have been inspired by Jessica Outlaw’s research on the relationship between virtual spaces and rules of behavior, and what makes a welcoming Social VR experience. I have also incorporated Facebook Research’s article on “Harassment in Social VR: Implications for Design”, and “Lessons from the Frontiers of Social VR” by Mike Booth. I am more aware of emerging findings thanks to the Voices of VR podcast by Kent Bye, and I’ve been reading Peter Rubin’s Future Presence: How Virtual Reality Is Changing Human Connection, Intimacy, and the Limits of Ordinary Life. I have learned about the history of virtual social dynamics through studies on Second Life and Real Virtuality: about the Destruction and Multiplication of World. by Gehmann, Ulrich, et al. \r\n<br><br>\r\nI was greatly inspired by Chris Milk's \"Life of Us\", and the performance piece “Becoming Dragon: a mixed reality, durational performance in second life” by Micha Cárdenas for their approach to becoming virtual and bridging the gap between realities.  ","thumbnail_image":{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/Screen-Shot-2019-05-09-at-11.29.03-PM-1-1024x575.png","title":"Screen Shot 2019-05-09 at 11.29.03 PM","alt":"1","caption":""},"headshot_image":{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/2H6A9827-768x512-1.jpg","title":"2H6A9827-768x512","alt":"mai headshot","caption":""},"slide_show":[{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/Screen-Shot-2019-05-09-at-11.29.34-PM-1-1024x640.png","title":"Screen Shot 2019-05-09 at 11.29.34 PM","alt":"1","caption":"1"},{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/stage3-1-1024x476.png","title":"stage3","alt":"1","caption":""},{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/Screen-Shot-2019-05-05-at-2.06.13-AM-1-1024x693.png","title":"Screen Shot 2019-05-05 at 2.06.13 AM","alt":"1","caption":""},{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/Chin-Drawing.00_00_01_23.Still001-1-1024x574.png","title":"Chin Drawing.00_00_01_23.Still001","alt":"1","caption":""},{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/stage2-1-1024x484.png","title":"stage2","alt":"1","caption":""}],"tags":[{"name":"3D","slug":"3d"},{"name":"Art","slug":"art"},{"name":"Culture","slug":"culture"},{"name":"Identity","slug":"identity"},{"name":"Performance","slug":"performance"},{"name":"social practice","slug":"social-practice"},{"name":"Speculation","slug":"speculation"},{"name":"VR/AR/Immersive","slug":"vr-ar-immersive"}],"video_presentation_url":"https://vimeo.com/336818226","video_documentation_url":"https://vimeo.com/331521973"},{"student_id":96,"student_name":"Marco Matteo Wylie","student_slug":"marco-matteo-wylie","advisor_name":"Nancy Hechinger","title":"Undercover","thesis_statement":"Undercover is an autobiographical performance that weaves vignettes of memory, music and pop culture imagery into a narrative that explores misogyny, gender, and identity from the perspective of a transman.","abstract":"As a transgender man, I’ve realized that there are things that men say to each other in the absence of women and things women say to each other in the absence of men. In fact, there are many changes I’ve noticed, particularly in the way that people treat and perceive me after transitioning. I now find myself in the predicament of being held accountable for a social history of misogyny that I’ve lived on the receiving end of for many years prior. Undercover shares this perspective through a 5-minute show.\r\n<br><br>\r\n The viewer doesn’t know any of this backstory when they enter the space. During the piece, the viewer listens and watches a narrative that uses sound, light, images, a two-way mirror, with an element of surprise at the end. It takes place inside of a curtained off, dark space, similar to a photo or fortune-telling booth, where the viewer enters and sits down on the chair in front of a black wall that frames a 12” x 12” mirror and puts on headphones. The narration begins with the viewer looking at their own reflection. A minute in, the lights are gradually dimmed, and images relating to the audio are projected on a screen on the other side of the mirror. In the last 45 seconds,  the images disappear and the light inside the space changes to reveal the narrator (me) sitting on the other side of the mirror. Putting myself in the space with the viewer on the other side of the divider, and making eye contact through the two-way mirror during the last moments of the show, breaks down the fourth wall and further humanizes the story. I understand that this may be a bit uncomfortable and that is by design.\r\n","context_research":"The Marina Abramovic piece The Artist Is Present was the inspiration behind having this be a one on one show. I like the intimacy it provides and the uncomfortableness of staring into a stranger's eyes. Because transitioning is a process that a person goes through on their own, I wanted to highlight this quality and have the audience member experience this installation alone while partially looking into their own reflection.<br><br>\r\nThe artist Cassils, in their piece Becoming An Image, fights with a large chunk of clay in total darkness. The audience only sees what’s going on when a single camera flash happens and a photograph is taken. This inspired me to begin in darkness and play with the idea of seeing and hearing glimpses of experiences without giving the full picture. I eventually decided not to include any direct interaction with the viewer, just like Cassils’ piece, because the purpose of the space is to give people a sense that they are alone with their feelings and thoughts, just as I felt while transitioning.     ","thumbnail_image":{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/Thesis-Picture-1-1024x576.jpg","title":"Thesis-Picture","alt":"marco","caption":""},"headshot_image":{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/profile-pic.jpg","title":"profile pic","alt":"profile pic","caption":""},"slide_show":[{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/Thesis-Picture-1-1024x576.jpg","title":"Thesis-Picture","alt":"marco","caption":""}],"tags":[{"name":"Identity","slug":"identity"},{"name":"Memory","slug":"memory"},{"name":"Narrative/Storytelling","slug":"narrative-storytelling"},{"name":"Performance","slug":"performance"}],"video_presentation_url":"https://vimeo.com/337314215","video_documentation_url":"https://vimeo.com/331463321"},{"student_id":102,"student_name":"Max Horwich","student_slug":"max-horwich","advisor_name":"Gregory Shakar","title":"Audance","thesis_statement":"Audance is a networked interactive music web app that allows users to play together over the internet in real time, using their computer keyboard, mouse and webcam as instruments, regardless of musical training or experience.","abstract":"I came to ITP with a very specific goal: to use interactive media technology to make musical expression available to the widest possible audience. I’ve explored this in past work, creating web-based musical interfaces that lean away from traditional forms — like written notation and piano keys — to create something more inviting to users with no formal musical training. These projects now serve as prototypes and early experiments toward the development of Audance. <br><br>\r\n\r\nWhile my previous works have empowered users to make music on their own, this is my first web-based project explicitly designed for musical collaboration, and as such, my most fully-realized work to date. Musical expression is a fundamentally collaborative endeavor, relying on a shared language -- both among performers and between performers and listeners -- for the form to be fully realized, and for the benefits of engaging with that form to be fully felt. To that end, I set out to build an environment where that shared language can be explored in a format that is intuitive and inviting to the widest audience possible.  ","context_research":"Research for this project was varied and widespread, but essentially sought to answer one of two questions: what am I making and why am I making it? <br><br>\r\n\r\nThe question of “why?” led me to the field of music therapy, where the benefits of playing music, and the ways to achieve those benefits, have been most thoroughly formalized. Music therapist Kenneth Bruscia writes extensively on improvisational musical therapy (essentially, “jamming” in a clinical setting) as a tool for strengthening group skills and feelings of interpersonal intimacy. Musician-turned-neuroscientist Daniel Levitin builds on this line of thinking, arguing that music, a form of communication older than language, evolved in parallel with the psychological development of early humans, helping to facilitate the cognitive payload that made society possible at the interpersonal level.<br><br>\r\n\r\nThe “what?” part of my research explored existing tools to realize these benefits in the most approachable way possible. I drew inspiration from the networked creative capabilities of cloud-based DAW Indaba; the social music experience of DJ chat room plug.DJ; the accessibility of camera-controlled iOS instrument AUMI; the playfulness of browser-based instruments like Patatap and Groove Pizza; and the rich immersion of interactive music games like Panoramical. These features came together to inform the core of Audance, the first platform for real-time musical collaboration over the internet designed specifically with the non-musician as the target user. ","thumbnail_image":{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/audanceMain-1024x576.jpg","title":"Audance","alt":"Screenshot of the web app in use with colored bars and circles","caption":"Audance screenshot"},"headshot_image":{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/methesisportrait-768x432-1.jpg","title":"methesisportrait-768x432","alt":"max portrait","caption":""},"slide_show":[{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/audanceSlide-1024x576.jpg","title":"audance in action","alt":"Screenshot of the web app in use with colored bars and circles","caption":""},{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/audanceOren-1024x576.jpg","title":"audance Oren","alt":"man in headphones standing and looking at screen with web app displayed","caption":""},{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/audanceLouise-1024x576.jpg","title":"audance Louise","alt":"woman in headphones standing and looking at screen with web app displayed","caption":""},{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/audanceScreen-1024x576.jpg","title":"audanceScreen","alt":"screen hanging on brick wall with web app displayed","caption":""},{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/audanceScreenshot2-1024x576.jpg","title":"audance Screenshot","alt":"Screenshot of the web app in use with colored bars and circles","caption":""}],"tags":[{"name":"Design","slug":"design"},{"name":"Music","slug":"music"},{"name":"Networks","slug":"networks"}],"video_presentation_url":"https://vimeo.com/336826879","video_documentation_url":"https://vimeo.com/331470497"},{"student_id":93,"student_name":"Meicheng Jia","student_slug":"meicheng-jia","advisor_name":"Stefani Bardin","title":"Wu Wei","thesis_statement":"   An immersive projection installation experience inspired by the Chinese philosophy Wu Wei( peaceful mind). This experience is to reflect user's brain activity through visual art and to help people realize the importance of tranquility.","abstract":" Wu Wei was designed in order to encourage people to relax both their body and mind. It is an immersive interactive installation which exhibit the importance of tranquility through visual and sound. \r\n Wu Wei symbolizes the essence of a peaceful mind, by which means one should not force out any ideas, but to embrace the peacefulness and let ideas come to oneself, and that peaceful state of mind is the key concept from the philosophy of Daoism.<br><br>\r\n  The fast-paced modern life has brought people nothing but anxiety, people are often working under high pressure and the competitiveness of our culture are forcing people to try and to strive, which opposes the philosophy of Wu Wei. However, a lot of times constantly trying and striving can be the most inefficient way when it comes to generating ideas. For instance, for artists and musicians, a lot of the times creative ideas comes for us automatically, we can’t force it to come us.<br><br>\r\n  I want people to think this installation as the physical embodiment of a mind, each particle represents one idea, and when their brain is at ease, these small particles would form into a much larger sphere.The idea of using sphere instead of other shapes comes directly from Daoism, the Ba Gua Map, which represents balance and tranquility. ","context_research":"    During my research I read a book wrote by Edward Slingerland who is a professor of Asian Studies at the University of British Columbia. The book he wrote talked about the philosophy behind Wu Wei is the paradox of trying not to try, and he gave an example of a Mindball game. The game is a physical table where two players sit opposite to each other wearing EEG  headsets that senses their brain signals.The player who is most relaxed will have their ball score the opponents goal and win. I found that this game can perfectly explain the philosophy of Wu Wei, which is the more peaceful your mind is , the better result you will get. From this game I got inspiration to crate my installation.  My installation is a immersive projection room where users will use their brain to control the visual elements that projected in the room by wearing a EEG headset that monitor the peaceful level of their brain. The more tranquil the person is the more he will form the entire image.   \r\n\r\n","thumbnail_image":{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/33BA3A6E-35B4-4393-866C-6A07A44B4FEA-1024x639.jpg","title":"33BA3A6E-35B4-4393-866C-6A07A44B4FEA","alt":"wuwei1","caption":""},"headshot_image":{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/me-nyu-photo-768x432-1.jpg","title":"me-nyu-photo-768x432","alt":"meicheng headshot","caption":""},"slide_show":[{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/33BA3A6E-35B4-4393-866C-6A07A44B4FEA-1024x639.jpg","title":"33BA3A6E-35B4-4393-866C-6A07A44B4FEA","alt":"wuwei1","caption":""},{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/IMG_7937-1024x719.jpg","title":"IMG_7937","alt":"wuwei3","caption":""},{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/IMG_7940-1024x701.jpg","title":"IMG_7940","alt":"wuwei4","caption":""},{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/Screen-Shot-2019-05-07-at-9.35.03-PM.png","title":"Screen Shot 2019-05-07 at 9.35.03 PM","alt":"wu wei","caption":""}],"tags":[{"name":"Art","slug":"art"},{"name":"Installation","slug":"installation"},{"name":"Performance","slug":"performance"}],"video_presentation_url":"https://vimeo.com/336817979","video_documentation_url":"https://vimeo.com/330915199"},{"student_id":105,"student_name":"Mengzhen Xiao","student_slug":"mengzhen-xiao","advisor_name":"Adaora Udoji","title":"IntoAR: Intuitive AR Notifications Design System","thesis_statement":"What’s the next generation of AR interfaces? How can we design immersive AR notifications other than the traditional overlaid textual representations of information? IntoAR is a design system for designing intuitive notifications in augmented reality. It consists of a series of experiments aimed at demonstrating how to create universal and non-text based AR notifications by applying physical affordances.","abstract":"Mobile App notifications, notes, memos - our lives are constantly overloaded with them to the point that we get used to them. To reduce unnecessary notifications and provide effective notice, AR technology is a speculative solution. Through augmented reality, we can both enhance and simplify our everyday experiences, through intentional design of notifications. However, most AR notifications are text-based. Text-based notifications are hard to read and in some cases, it needs to support multiple languages. So, how can we design immersive AR notifications other than the traditional overlaid textual representations of information? How can we create universal and non-text based AR notifications? \r\n\r\nIntoAR is a design system for designing intuitive AR notifications. By constructing and testing a series of AR design prototypes, the system demonstrates how to create universal and non-text based AR notifications by applying physical affordances. The system consists of different categories, such as utility, capacity, temperature, navigation, and gesture. Each category lists several different ways to design AR notifications, and each option provides AR demos of both a cube example and an object application example for users to download and test on their mobile devices.","context_research":"The purpose of this study is to create a design system for designing universal and non-text based AR notifications. <br><br>\r\n\r\nAugmented reality is an emerging technology that is becoming mainstream. AR has evolved over the past years, but it still faces several challenges. Most AR notifications are text-based. Text-based notification is hard to read and in some cases, it needs to support multiple languages. As augmented reality becomes more accessible, there will be a more diverse user archetype spanning different ages, cultures, and comfortability with technology. User diversity becomes a big challenge when designing intuitive AR notifications. \r\n<br><br>\r\nOne possible way to meet the challenge is to apply the understanding of physical affordances. Physical affordances are the object's properties that show the possible actions users can take with it, thereby suggesting how they may interact with that object. Leveraging physical affordances can enable intuitive interaction through embodied knowledge. I have done research on related projects such as Shapeshift by Dixon Lo and Sublimate by MIT. \r\n<br><br>\r\nTo make a reliable design system, I conducted one-on-one user testing with several AR design prototypes and then made a quantified system for measurement and comparison. I also did research on AR design toolkits and system design guidelines such as Google Augmented Reality Design Guidelines, Apple AR human-interface-guidelines, Frog Design Toolkit, Civic Service Design Tools, and Motion Periodic Table.","thumbnail_image":{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/Thesis-Thumbnail-image-1024x576.jpg","title":"IntoAR","alt":"IntoAR","caption":""},"headshot_image":{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/my_photo-768x432-1.jpg","title":"my_photo-768x432","alt":"mengzhen headshot","caption":""},"slide_show":[{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/thesis-mainimage-01-1024x576.jpg","title":"thesis-mainimage-01","alt":"thesis-mainimage-01","caption":""},{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/thesis-mainimage-02-1024x576.jpg","title":"thesis-mainimage-02","alt":"thesis-mainimage-02","caption":""},{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/thesis-mainimage-03-1024x576.jpg","title":"thesis-mainimage-03","alt":"thesis-mainimage-03","caption":""},{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/thesis-mainimage-05-1024x576.jpg","title":"thesis-mainimage-05","alt":"thesis-mainimage-05","caption":""}],"tags":[{"name":"Design","slug":"design"},{"name":"Speculation","slug":"speculation"},{"name":"UX","slug":"ux"},{"name":"VR/AR/Immersive","slug":"vr-ar-immersive"}],"video_presentation_url":"https://vimeo.com/336821782","video_documentation_url":"https://vimeo.com/330364925"},{"student_id":91,"student_name":"Michael Fuller","student_slug":"michael-fuller","advisor_name":"Kathleen Stevens Wilson","title":"Touch-An Interactive Art Installation","thesis_statement":"In a world of digital touch screens there is a disconnect with the touch of physical objects. My thesis is an exploration the interface between the physical object and the digital output through the installation of an interactive art object. Specifically, the relationship between doing a physical action and getting a digital reaction.","abstract":"Touch - An Interactive Art Installation speaks about the relationship between the physical object and the digital representation. There is an interactive experience that represents the physical touch of the object to create a digital experience in sound and image.\r\n<br><br>\r\nThe installation<br><br>\r\nThe display of a piece of Western desert Juniper wood on top of a pedestal with a piece of draped fabric mounted behind. <br><br>\r\nThere is a distance proximity sensor mounted on the front of the pedestal that activates an audio clip and an image of a desert thunder storm when people stand 2 -3 feet in front and the volume of the audio increases as people approach the pedestal.<br><br>\r\nThere are multiple close proximity sensors mounted on the surface of the pedestal around/beneath the juniper that activate different audio clips of desert sounds - wind, birds, etc. when people touch and move their hands around the surface of the juniper. As audio clips are activated, different images related to the different sounds and the desert are projected on the fabric hanging behind the Juniper.<br><br>\r\nThe relationship between the physical touch of the object and the digital output is an elusion. The touching of the physical object is being mapped in space by the sensors that are not connected, they are just sensing touch.","context_research":"Most of the research I have discovered is software and installations that delight in the interactive experience interface without the tension or effort I am looking to illustrate and convey in the interaction. I am researching natural materials as the interface with the digital translation like natural wood or stone. The key to the interface from physical interaction to the digital translation is the hardware. All of the research is still open ended as I clarify the concept and implementation.\r\n<br><br>\r\nResearch<br><br>\r\ninteractive touch breath art<br>\r\n7 Ways Technology is Changing How Art is Made<br>\r\nPlease Touch The Art<br>\r\nbreathe on digital screen create art<br>\r\nInteractive generative art<br>\r\n\r\nUseless machines<br>\r\n\r\ntraditional material use in a digital world<br>\r\n\r\nJuniper Trees Moab Desert\r\n\r\n","thumbnail_image":null,"headshot_image":{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/default.png","title":"default","alt":"default","caption":""},"slide_show":[{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/Screenshot-2019-05-20-20.36.07-1024x576.png","title":"Screenshot 2019-05-20 20.36.07","alt":"michael fuller project image","caption":""},{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/Screenshot-2019-05-20-20.36.29-1024x576.png","title":"Screenshot 2019-05-20 20.36.29","alt":"michael fuller","caption":""}],"tags":[{"name":"Art","slug":"art"}],"video_presentation_url":"https://vimeo.com/336836725","video_documentation_url":""},{"student_id":94,"student_name":"Michael J. Blum","student_slug":"michael-j.-blum","advisor_name":"Stefani Bardin","title":"Paralang","thesis_statement":"Through an educational learning hub and an interactive playground, both hosted on the same web app, Paralang aims to cultivate literacy, inspire curiosity, and arouse concern with respect to emerging neural language models.","abstract":"Recently released, state of the art language models have been shown to be able to produce text that is nearly indistinguishable from that produced by humans. \r\n<br><br>\r\nThese recent advances, which have proved plenty controversial within machine learning circles, have caused ripples in the general media landscape as well, where coverage has been largely hyperbolic, excessive, and occasionally uninformed or even incorrect. \r\n<br><br>\r\nWith the belief that this natural language generation technology, more than mere novelty, will gradually assume a more and more pervasive role in our everyday lives, I wanted to intervene, however modestly, and provide an accessible, beginner-friendly platform to help secularize this technology and elaborate on some of its inner-workings as well as its repercussions both for us as individuals and a society. I’d like to help answer questions like: what makes these recent advances so compelling and new? Or: how might existing societal problems by reproduced and reinforced by these advanced language models?\r\n<br><br>\r\nUltimately, my aim is to help cultivate a more level-headed literacy as well as inspire both a sense of informed curiosity and concern with respect to these emerging models and their ramifications, with an emphasis on the recent and state of the art (particularly Google’s BERT and OpenAI’s GPT-2).\r\n<br><br>\r\nThe platform consists of two components, both hosted on a single web app. One is educational, revolving around a learning hub, glossary, and resources curated for all skill levels — newcomer, intermediate, and advanced. The other is interactive, comprising of a “playground” encouraging hands-on experimentation with some of the language models featured in the educational component. \r\n<br><br>\r\nAltogether, the platform is built to accommodate non-linear engagements — users can begin with the learning hub and progress through to the playground, or simply jump to the playground, or maybe even just skip around between glossary and resources.","context_research":"The ground and basis of my research consisted in familiarizing myself with the field of natural language processing, from different strategies of word and sentence embedding to classification, dependency parsing, understanding, and generation, as well as more advanced approaches involving recurrent neural networks and sequence to sequence models. From there, my primary focus was on state of the art language models, particularly those powered by the Transformer neural network architecture. Towards this end, Stanford’s CS224n course, Jay Alammar’s illustrated blog posts, as well as Google and OpenAI’s research papers on arxiv.org were particularly illuminating.\r\n<br><br>\r\nSome of the undergirding conceptual motivations of the project were spurred on by various sources, from academic and non-academic articles on bias baked into datasets used in machine learning pipelines to Benjamin Bratton’s writings, in which he delineates a compelling, original conception of the relationship between human being, human creation and artifice, and the machinic reflection of what “human” has been, is, and can be. \r\n<br><br>\r\nWhile some of the practical and technical motivations of the project were inspired by similar educational deployments of neural network models such as Joel Simon’s Ganbreeder and a project jointly helmed by Google Brain and Georgia Tech called GANLab.","thumbnail_image":{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/Subtract.jpg","title":"Subtract","alt":"Logo","caption":""},"headshot_image":{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/michealblum.png","title":"michealblum","alt":"micheal blum portrait","caption":""},"slide_show":[{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/Recent-SOTA-1024x640.jpg","title":"Recent SOTA","alt":"Learning hub screenshot","caption":""},{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/learning-hub-test-1024x640.jpg","title":"learning-hub-test","alt":"Leaning hub screenshot","caption":""},{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/syllabus-1024x640.jpg","title":"syllabus","alt":"Syllabus screenshot","caption":""}],"tags":[{"name":"Data","slug":"data"},{"name":"Education","slug":"education"},{"name":"Machine Learning","slug":"machine-learning"}],"video_presentation_url":"https://vimeo.com/336818022","video_documentation_url":""},{"student_id":99,"student_name":"Mohammad \"MH\" Rahmani","student_slug":"mohammad-\"mh\"-rahmani","advisor_name":"Kathleen M Sullivan","title":"reFrame","thesis_statement":"“reFrame” is an interactive installation that shows you different ways of perceiving and understanding the same subject. It reveals and shifts your internal cognitive framework to give a visceral understanding of how subjective our world view is. \r\n","abstract":"We trust our worldview so dearly that we argue, fight, and go to war over it; but we are probably more wrong than we are right. We experience only a slice of the world around us, and we perceive it through not only our limited senses, but also through our limited semantics. Does being conscious of these fundamental limitations lead us to better conversations and less tension in society?\r\n<br><br>\r\nMetacognition - awareness of our subjective cognition -  is already a well known concept these days, both in academia and pop culture; therefore we know that mere knowledge of it is not introspective enough to change our discourse. “reFrame” tries to communicate this concept through first-hand intuitive experience: it shifts your mindset to derive different meanings from the same subject, revealing to you the paradigms that are controlling what you see.  \r\n<br><br>\r\nThis installation is made of three large vertical frames at eye level that stand between the user and a visual subject. Within each frame is a custom-built transparent display that superimposes text and graphics over the subject - essentially turning the frame into a large AR Heads Up Display. It also tracks your eyes and adjusts the image based on where you look at it or how far you are from it. \r\n<br><br>\r\nEach frame represents a different point of view and reveal a unique way of understanding the subject. They also play with your distance by showing different ways of grouping and analyzing the subject based on how much of it is cropped by the frame. \r\n","context_research":"\"The present day shows with appalling clarity how little able people are to let the other man's argument count, although this capacity is a fundamental and indispensable condition for any human community. -- For, to the degree that he does not admit the validity of the other person, he denies the 'other' within himself the right to exist -- and vice versa.  The capacity for inner dialogue is a touchstone for outer objectivity.\"\r\n<br><br>\r\nThis quote by Carl Jung from 1945 was randomly given to me in the middle of my research, and by the end of it I really puts my efforts into context.\r\n<br><br>\r\nI was mainly inspired by Dr. Dale Purves classes on visual perception and the brain. Studying perception from an empirical point of view opened my eyes to appreciate artists like Magritte, Escher, Turrell, and Irwin who tackle with perception and self-awareness. I experienced a similar introspection in psychology from the works of Piaget, C.G. Jung,  Neumann’s “Origins and History of Consciousness”, Haidt’s “Emotional Dog and its Rational Tail”, Pinker’s “Blank Slate”, and Peterson’s “Psycho-ontological Analysis of Genesis”; to name a few.\r\n<br><br>\r\nFrom there I saw connections with Middle Eastern philosophy, especially Persian mystics such as Rumi and Hafez. Later learning about Cybernetics from Paul Pangaro, and studying works of Heinz von Foerster and Humberto Maturana, helped put things in a functional context.\r\n<br><br>\r\nI also discovered others currently dealing with expressing the same general concepts. Beau Lotto and his book “Deviate” became a great resource. Later inspirations include Caroline Bergvall’s VIA, Games by Nicky Case, Kyung Woo Han, and Daihei Shibata.\r\n<br><br>\r\nDiscrete subjects include Godel’s uncertainty theorem, Kuhn’s paradigms, plus unsupervised learning and reinforcement learning in Neural Networks.\r\n<br><br>\r\nOn the technical side Zach Lieberman’s “Body Sketches” inspired me to build my own transparent display. Also, I believe my former obsession with Prezi presentation app was a key to figure out the UX. \r\n","thumbnail_image":{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/reframe-theframe-2-3-1024x576.jpg","title":"reframe-theframe-pipe","alt":"reframe detecting pipe on magrite with 0.985 accuracy","caption":""},"headshot_image":{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/mh_photo.png","title":"mh_portrait","alt":"Portrait of M.H. Rahmani","caption":""},"slide_show":[{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/IMG_20190507_161246-Edit-1024x576.jpg","title":"reframe-perojector-setup","alt":"A pico projector hung by a manfrotto magic arm attached to a manfrotto video head","caption":""},{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/reframe-theframe-2-1024x576.jpg","title":"reframe-theframe-front","alt":"reframe the frame front view with square projection","caption":""},{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/reframe-theframe-1-1024x576.jpg","title":"reframe-theframe-left-profile","alt":"reframe the frame from left three-quarters view with the projector on magic arm visible","caption":""},{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/reframe-theframe-2-2-1024x576.jpg","title":"reframe-theframe-pipe-magritte","alt":"reframe the frame detecting pipe on magritte","caption":""},{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/reframe-theframe-5-1024x576.jpg","title":"reframe-theframe-5","alt":"reframe - left profile","caption":""}],"tags":[{"name":"Art","slug":"art"},{"name":"Hologram","slug":"hologram"},{"name":"Installation","slug":"installation"},{"name":"Narrative/Storytelling","slug":"narrative-storytelling"},{"name":"VR/AR/Immersive","slug":"vr-ar-immersive"}],"video_presentation_url":"https://vimeo.com/336826800","video_documentation_url":""},{"student_id":108,"student_name":"Namsoo Kim","student_slug":"namsoo-kim","advisor_name":"Adaora Udoji","title":"GALLARY","thesis_statement":"GALLARY is an augmented mobile gallery for young artists by connecting their artworks on their Instagram. ","abstract":"Young artists usually upload their art pieces on their Instagram to showcase their works globally because they really struggle with looking for a place where they are able to exhibit their works. This problem also includes not only limited physical restriction but also a high cost of renting the place.<br><br>\r\n\r\nMy thesis projects initiated to address this social phenomenon and issues for young artists in order to offer better accessibility and more dynamic interactions by using mobile augmented reality.\r\n","context_research":"The museum is generally physically based, and most of the traditional museums are socially exclusive. I believe this issue makes artists and art-lovers to access to only a small percentage of the world art.<br><br>\r\n\r\nUnlike the traditional venue, Nowadays, young artists use Social Media as their own virtual art gallery to showcase their artworks globally. Although this is a small screen, it has infinite space and accessibility all around the world. I would say that this virtual space is a new type of museum where we can appreciate their works.\r\n<br><br>\r\n“…today artists use Instagram as their own virtual art gallery, playing both dealer and curator while their fans become critics and collectors…”  - Vogue Magazine","thumbnail_image":{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/GallARy-768x415-1.jpg","title":"GallARy-768x415","alt":"image 1","caption":""},"headshot_image":{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/Vince_Rec-768x781-1.jpg","title":"Vince_Rec-768x781","alt":"vince portrait","caption":""},"slide_show":[{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/GallARy-768x415-1-2.jpg","title":"GallARy-768x415-1","alt":"gallery","caption":""}],"tags":[{"name":"Art","slug":"art"},{"name":"Design","slug":"design"},{"name":"Mobile","slug":"mobile"},{"name":"VR/AR/Immersive","slug":"vr-ar-immersive"}],"video_presentation_url":"https://vimeo.com/336821895","video_documentation_url":"https://vimeo.com/vinskim"},{"student_id":58,"student_name":"Nathier Fernandez","student_slug":"nathier-fernandez","advisor_name":"Stefani Bardin","title":"Genetically Generated Texts [5’ GGT 3’]","thesis_statement":"5’ GGT 3’ is a series of experimental artifacts that speculate the act of renaming genetics as literature by implementing linguistic rules and computational arts to living organisms. This set of in-vitro inspired fictions focus on the ‘otherness’ of the microbiome that constitutes us; becoming a subversive seed for new [biotech] futures. ","abstract":"Genetically Generated Texts [5’ GGT 3’] is a series of experimental artifacts that speculate the act of renaming genetics as literature. This is created by implementing linguistic rules based on the central dogma of microbiology. <br><br>\r\n\r\nThis dogma of microbiology creates 'gene expression', in which information from a gene is read to build a protein. By mapping these set of rules to parts of speech in English grammar, the gene of a preselected organism [Aichii (Virus) and Escherichia Coli (Bacteria)] builds a text-based fictional output. This is then translated to DNA code in order to be embedded inside the organism that provided the first DNA input.<br><br>\r\n\r\n\"To say that DNA is 'read' or that is a 'program' is to make use of metaphors\" Pablo Schyer\r\n\r\n","context_research":"And every natural being is making communications        \r\nAnd we’re just sparks, tiny parts of a bigger constellation\r\nWe’re minuscules molecules that make up one body.\r\n<br><br>\r\n                                     Tunnel Visions by Kate Tempest\r\n<br><br>\r\n\r\nPoets like Christian Bok, who created the first 'living' poetry, by encoding his poems to bacteria and encouraging mutations that change the poems continuously over time. [The Xenotext]. Or Artists like Neri Oxman and her Mediated Matter Group at MIT;  Eduardo Kac’s concrete poetics and genetic-based media were influential to Genetic Generated Texts.\r\n<br><br>\r\nThe plastic explorations with living organisms that artist like Anika Yi achieves or Alisson Kudla’s interventions between technology and speculative biology not only showed the path but how infinite the metaphors around human and non-human relationships could be.\r\n<br><br>\r\nIf the basic unit of life is sign, and not the molecule as Jesper Hoffmayer said, then one must use the most powerful of all human symbols: language, relying on semiosis to create meaningful scenarios. Then, exploring a connection between language and genetics;\r\nwhich is heavily based on signs and molecules, should allow an intersection between art and biological sciences, even if they only live in the speculative realm. After all, language is a  powerful tool to create relationships with other living things.<br><br>\r\n\r\nBut Molecules themselves are not visible, so are some biological organisms. At some point in history, they didn't 'exist' because we couldn't see them. Until the development of some apparatus [e.g, microscopes], they were only part of speculation, theories and even wild imaginations. Once these objects emerged, an 'apparatus-based vision' appeared. And with any new medium, humankind has always found a way to represent and create things.\r\n<br><br>\r\nExperimental artifacts are in the context of this project, both errors and physical objects, they should be understood by their cultural, scientific and visual meaning. With 'errors' as a particular experimental practice, encouraged and expected. For aesthetic and metaphorical purposes we are gonna call them 'mutations'. \r\n<br><br>\r\n\"Artifacts may emerge from experiments in science, the \"artifact\" is an outlying bit of data-an erroneous often human-induced thing that can be ignored, like the distortion caused by the curvature of a lens. Conversely =, for the artist or designer, the artifacts is the focus of our intention: We are actively making things\". \r\n<br><br>\r\nSynthetic Aesthetics. Alexandra Daisy Ginsberg, Jane Calvert, Pablo Schyfter, Alistair Elfick and Drew Endy. The MIT press.\r\n<br><br>\r\n“The word is now a virus. The flu virus may have once been a healthy lung cell. It is now a parasitic organism that invades and damages the central nervous system. Modern man has lost the option of silence (..) serving no internal function other than to replicate itself” William. S. Burroughs","thumbnail_image":{"src":null,"title":"the_virus_is_now_a_word","alt":"WCAG violation: this image will not be displayed due to lack of alternative text.","caption":""},"headshot_image":{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/2H6A9918-768x512-1.jpg","title":"2H6A9918-768x512","alt":"nathier headshot","caption":""},"slide_show":[{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/ggt-1024x622.jpg","title":"ggt","alt":"ggt image","caption":""},{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/Screen-Shot-2019-04-19-at-2.12.13-PM-1024x753.png","title":"Screen Shot 2019-04-19 at 2.12.13 PM","alt":"genetically generated texts","caption":""},{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/Screen-Shot-2019-04-16-at-8.16.40-PM-1024x749.png","title":"Screen Shot 2019-04-16 at 8.16.40 PM","alt":"project image","caption":""},{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/Screen-Shot-2019-04-19-at-2.12.34-PM-1024x756.png","title":"Screen Shot 2019-04-19 at 2.12.34 PM","alt":"Screen-Shot-2019-04-19-a","caption":""},{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/thevirusdnaencoding-1024x622.jpg","title":"thevirusdnaencoding","alt":"project image","caption":""}],"tags":[{"name":"Art","slug":"art"},{"name":"Experiment","slug":"experiment"},{"name":"Python","slug":"python"},{"name":"Science","slug":"science"},{"name":"Sculpture","slug":"sculpture"},{"name":"Speculation","slug":"speculation"},{"name":"Visual","slug":"visual"}],"video_presentation_url":"https://vimeo.com/336814947","video_documentation_url":""},{"student_id":110,"student_name":"Nick Wallace","student_slug":"nick-wallace","advisor_name":"Kathleen M Sullivan","title":"Climb.It Weather System","thesis_statement":"How can we improve the safety of outdoor activities in remote areas? If outdoorspeople had access to accurate, hyper-local weather data, they could make more informed decisions about weather risks and their safety. Existing satellite-based weather forecasts do not take into account the variety of micro-climates that exist in expansive remote areas.","abstract":"For people who live or spend time in extremely remote areas, unreliable weather data is a major safety concern which can lead to unnecessary risk and misinformed decision-making. Climb.It Weather System (CWS) aims to solve this problem. \r\n<br><br>\r\nCWS is a system of transmitters and receivers collecting on-the-ground data from remote areas and publishing it online via radio transmission. These transmitters live in the field, running on a combination of solar panel and battery power, in order to broadcast sensor data over high frequency packet radio (APRS). CWS receivers live areas with WiFi or 3G infrastructure, receive sensor data directly from a transmitter (or APRS repeater), and publish this data to a database server. \r\n<br><br>\r\nOutside the scope of this proof of concept, this project will expand to include a system for serving this data, as well as forecasts based on this data, to the public.","context_research":"In its early stages, I envisioned Climb.It to be an answer to the gaps in aggregate weather data networks like Weather Underground. These systems do an excellent job of providing localized weather forecasts for urban and suburban areas where it is possible to collect weather data over WiFi or 3G. However, these networks do not provide coverage of remote areas outside the range of these technologies.\r\n<br><br>\r\nMy early technical research involved researching and testing potential longer range communication technologies, such as LTE and LoRa. After determining that nothing off the shelf offered the type of range I needed, I decided to build my own radio frequency (RF) transmitter. In order to stay legal, I studied for and passed the FCC amateur radio technician license exam.\r\nI was inspired by low frequency radio and amplifiers from the 80s and early 90s that were designed to operate on unlicensed frequency bands (lowFER / 160-190KHz). Low frequency radio waves are larger than high frequency ones, and, generally speaking, travel further--this why AM radio can be heard further away from the transmitter than FM radio can be. Furthermore, unlicensed bands do no require an operator's license to transmit or receive on, and are the basis for many of the technologies we use today, including WiFi and Bluetooth. \r\n<br><br>\r\nI spent many, many hours developing prototypes based on the lowFER designs, through which I produced low cost and low power transmitters, but they ultimately turned out to be unreliable, and I was unable to reproduce the claimed ranges in the real world. \r\n<br><br>\r\nFinally, I redesigned the entire system to use very high frequency radio (2 meter / 144.14MHz), transmitting data packets over FM (APRS). Initial research and development for this was done by reverse engineering handheld 2 meter radios and piping in my data stream, before moving to building my own transmitting circuits.","thumbnail_image":{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/climbit-987x1024.jpg","title":"climbit","alt":"Climb it field install thumbnail","caption":""},"headshot_image":{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/Thesis-profile-169x300-1.png","title":"Thesis-profile-169x300","alt":"headshot","caption":""},"slide_show":[{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/Screen-Shot-2019-05-09-at-4.10.23-PM-1024x582.png","title":"Screen Shot 2019-05-09 at 4.10.23 PM","alt":"Climb.It Control Box Description","caption":""},{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/Thesis-RMNP-1024x576.png","title":"Thesis - RMNP","alt":"Off the shelf wireless map","caption":""},{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/8W0B6371-1024x683.jpg","title":"8W0B6371","alt":"Field test install","caption":""},{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/Climb-It-v2-Render-1024x576.png","title":"Climb It v2 Render","alt":"climb it modem circuit render","caption":""}],"tags":[{"name":"Data","slug":"data"},{"name":"Electrical Engineering","slug":"electrical-engineering"},{"name":"Experiment","slug":"experiment"},{"name":"IOT","slug":"iot"},{"name":"Networks","slug":"networks"},{"name":"Product Design","slug":"product-design"}],"video_presentation_url":"https://vimeo.com/336826975","video_documentation_url":""},{"student_id":109,"student_name":"Nicolas Escarpentier","student_slug":"nicolas-escarpentier","advisor_name":"Kathleen M Sullivan","title":"Inner Cadence","thesis_statement":"Inner Cadence is an interactive video wall that captures and amplifies people’s characteristic movements. By combining machine learning with motion capture, it reveals the audience’s individual identities by enhancing motion as a form of expression.","abstract":"Over the past year I have been exploring the idea of movement as a form of expression that’s inherently linked to our identity. It conveys individuality and emotion: we can be identified by our gait, or infer someone's mood by their pose. I want to maximize this expressiveness potential and explore ways of enhancing people's movements. I want to foreground motion by separating it from the body, silhouette, features, or clothes, making people rethink how they build their identity and their relation to others.\r\n<br><br>\r\nFor this purpose I created a 3-part video wall that analyzes people’s characteristic movements, classifies and amplifies them, enhancing its expressiveness. I used motion capture hardware and machine learning algorithms to showcase expanded forms of motion which feature different textures, forms and colors. Each wall is a single-user experience, and by placing the three walls next to each other, the audience will hopefully reflect and make connections between the repeating patterns that connect them together. \r\n","context_research":"I started my research by looking at choreography and what has been done around it. This pushed me to study diverse performance works from Merce Cunningham’s algorithmic choreography and Lucinda Childs’ “Dance” to Kate Sicchio’s “Hacking Choreography”. I also looked at movement depictions, such as “Ballet Rotoscoping” and “Performance in Zero Gravity”, and movement amplifications like “Forms” by Memo Atken and Quayola. While very useful for inspiration and overall context, these works go in the exact opposite direction I wanted to go: they generate choreography from certain parameters, where I want to generate parameters by analyzing movement. More on the technical side, I studied the “Choreographic Language Agent” by Wayne McGregor and the Open Ended Group, “Reactor for Awareness in Motion” by YCAM, and “Synchronous Objects” by William Forsythe. These descriptions of movements, while interesting, foreground the body, skeleton or silhouette, making the movement an action performed by a body, not an act of interest by itself. And it is here where I want to challenge the representations and how we think about motion on itself.\r\n<br><br>\r\nI also met with experts on the field of movement, dance and their intersection with technology: Mimi Yin, Elizabeth Coker and Kat Sullivan. From them I learned about different ways of tracking bodies and what matters in each case, as well as their experiences and conclusion. They also gave me their own outlooks on my ideas, helped me expand on how to accurately amplify the movements, and pointed me to more resources. This increased the list of books, articles and videos I researched on movement, dance, improvisation and identity.\r\n<br><br>\r\nMy own experiments started with a motion reactive Processing sketch, which pixelated and stylized the camera input only where there is motion. While interacting, I recorded people’s actions and skeletal data with a GoPro and Kinect camera respectively. This gave me a starting point on studying how people’s movements vary and what they do when faced with an interactive motion-based sketch. Later data captures, and the selection of joints to analyze for each movement type and to capture for the live amplification were all derived from these findings. \r\n","thumbnail_image":{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/IC_archive_logo.jpg","title":"IC_archive_logo","alt":"Inner Cadence logo","caption":""},"headshot_image":{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/npe_pixlr.jpg","title":"npe_pixlr","alt":"Nicolás Escarpentier","caption":""},"slide_show":[{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/ic_screen-1024x576.jpg","title":"ic_screen","alt":"Inner Cadence screen prompt \"come and become movement\" with particles on the background","caption":""},{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/ic_UnfReal02-1024x576.jpg","title":"ic_UnfReal02","alt":"User moving with their amplified movement as particles","caption":""},{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/ic_prompt-1024x576.jpg","title":"ic_prompt","alt":"User standing in front of the screen with the prompt \"come and become movement\"","caption":""},{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/ic_UnfReal01-1024x576.jpg","title":"ic_UnfReal01","alt":"User moving with their amplified movement as particles","caption":""}],"tags":[{"name":"Art","slug":"art"},{"name":"Identity","slug":"identity"},{"name":"Installation","slug":"installation"},{"name":"Machine Learning","slug":"machine-learning"},{"name":"Visual","slug":"visual"}],"video_presentation_url":"https://vimeo.com/336826936","video_documentation_url":"https://vimeo.com/331508586"},{"student_id":16,"student_name":"Nicolas Sanin","student_slug":"nicolas-sanin","advisor_name":"Stefani Bardin","title":"Slow numbers","thesis_statement":"How “random” real events are? How random can they be? How can we predict them?<br><br>\r\nSlow numbers is an exploration of “randomness”, focusing on testing the degrees of effectiveness of different “random” generators. The goal is to reveal the nature of these methods by using them to produce “random” data that we will have the chance to analyze, observe and compare. That way, revealing subtleties of this fascinating subject and also raising new questions. \r\n\r\n","abstract":"Slow numbers is an exploration of randomness, focusing on testing the degrees of effectiveness of random generators such as six-sided dice, digital algorithms and “human simulated six-sided die results”. In this process, the idea is to “harvest random results” from each method, so we can hopefully reveal possible biases and patterns on each random generation system. And we can also compare them after, to see how the definition for “randomness” works according to each method.\r\n<br><br>\r\nThe goal of this project is to look at what we call Chance or Randomness, and real it’s subtleties. It is an effort to understand it by means of an interdisciplinary dialogue. And also to highlight the beauty behind it, from a conceptual point of view, and from an Aesthetical point. \r\n<br><br>\r\nThe project is based on an empirical method, with an artistic vocation, inspired by the scientific methods of thinking and creating knowledge by creating practical experiments that can be analyzed after some action has been taken. Very much in the spirit of Intermedia: the collaboration between art and other disciplines. In this case, setting up a dialogue between Art, Mathematics, Probability, Electronics, Computer Science, Design, Philosophy, and Performance.\r\n<br><br>\r\nSlow numbers also pretend to raise more questions than to give true facts. The idea is that after all, we can ask ourselves many questions. Such as:\r\n<br>\r\nHow “random” Dice Are? \r\nHow “random” can they get to be?\r\nHow “random” are different computer algorithms?\r\nHow successfully can humans simulate random outcomes?\r\nWhat do we mean when we say something is “random”?\r\nIs there such a thing as “randomness”? \r\nDo we call random what we can’t fully explain? \r\nIs probability right?\r\nHow can we make “randomness” useful in our lives? \r\n\r\n<br><br>\r\n\"The world is governed by chance. Randomness stalks us every day of our lives. \"   Paul Auster\r\n\r\n","context_research":"For my thesis, my research was based on the ideas of probability and randomness. For this, I consulted different resources like books about mathematics, risk, and probability. Also, essays about the subject. To name the most important sources, I would say. “Chances Are…” by Ellen Kaplan and Michael Kaplan, “Fooled by Randomness” by Nassim Nicholas Taleb, and “Against the Gods, The Remarkable Story of Risk” by Peter L.Bernstein. I also consulted Joey Cain, a remarkable undergraduate student from the Mathematics Department at New York University. He gave me his feedback about the methods for the dice testing experiments, and also important insights about how to analyze the results. Other than that, I also looked at randomness from a philosophical point of view, focusing on the books by Luke Rheinhardt. His focus is on how can we embrace randomness in life in different ways, how we deal with it, and how we can use it to make our lives much interesting, fun and happier. Another part of my investigation was on the essays related to what is Known as “Fluxus art”. My interest was the ideas of play and experimentation, and also the concept of intermedia. That is the collaboration between art and other fields of knowledge. I also looked carefully at the work of different artists that have addressed the topic of randomness. To name the most relevant for this project, I would have to name Francois Morellet, Ellsworth Kelly, John cage, On Kawara, Rafael Lozano Hemmer and Ryoji Ikeda. ","thumbnail_image":{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/DATA_BASE_MAIN-768x432-1.jpg","title":"DATA_BASE_MAIN-768x432","alt":"DATA BASE MAIN","caption":""},"headshot_image":{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/autorretrato_1280x1920-768x432-1.jpg","title":"autorretrato_1280x1920-768x432","alt":"nico headshot","caption":""},"slide_show":[{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/humanDice-1-copy-copy_SIZE-768x432-1.png","title":"humanDice-1-copy-copy_SIZE-768x432","alt":"human Dice","caption":""},{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/open_cv_test_probe_april4-768x444-1.png","title":"open cv test","alt":"open cv test","caption":""},{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/numbers_SIZE-768x432-1.jpg","title":"numbers size","alt":"numbers size","caption":""},{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/ITUNE_PLAY_COUNT_size-768x432-1.png","title":"ITUNE_PLAY_COUNT_size-768x432","alt":"ITUNE PLAY COUNT","caption":""},{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/aleaaa_SIZE-768x432-1.jpg","title":"aleaaa_SIZE-768x432","alt":"aleaaa SIZE","caption":""}],"tags":[{"name":"Art","slug":"art"},{"name":"chance","slug":"chance"},{"name":"Experiment","slug":"experiment"},{"name":"probability","slug":"probability"},{"name":"randomness","slug":"randomness"},{"name":"Science","slug":"science"}],"video_presentation_url":"https://vimeo.com/336814600","video_documentation_url":"http://www.nicosanin.co/2019/04/19/slow-numbers-video-documentation/"},{"student_id":111,"student_name":"Oren Shoham","student_slug":"oren-shoham","advisor_name":"Gabriel Barcia-Colombo","title":"Viral Media","thesis_statement":"What are the artistic possibilities of computer viruses? What's the line between productivity software and malware? How can user interfaces express humor?","abstract":"\"Unexpected behavior of common Windows makes you meditate about techno-determinism. We call it misuse of technology; we do it consciously; we create the new beauty.\" - Alexei Shulgin\r\n<br><br>\r\nViral Media is a series of experiments in writing malware as a creative practice. These programs use hacks and exploits to elicit unexpected behavior from familiar user interfaces, taking the computer desktop as a site for playful intervention. The final output of this project is a set of three pieces of malware masquerading as productivity software produced by f(utility) labs, a research division of a fictional company called the Functional Utilities Corporation.\r\n<br><br>\r\nThe first of these productivity tools / viruses is a \"document optimizer\" that hijacks the copy/paste clipboard to insert generic business stock photos into any open text editor. The second is a \"break timer\" that periodically reminds you to take a break from your work by showing you an unhideable popup alert that actively moves away from your mouse when you try to close it. The third is a \"distraction manager\" that minimizes any open windows by taking control of the mouse and automatically clicking on the minimize button for each window.\r\n<br><br>\r\nWhy was I interested in the desktop? The computer desktop is an everyday visual environment that mediates our digital interactions, an interface so ubiquitous as to be almost invisible. The desktop is a private space, a virtual extension of our mental landscape that we rarely allow others to access. The desktop is sterile, functional, and full of corporate branding. All of these qualities combined make the desktop an interesting target for intervention.\r\n<br><br>\r\nMy research for this project touches on several conceptual threads: the voyeuristic tension that occurs when the desktop is made public in a performance context, a feeling of estrangement or defamiliarization that is evoked by misbehaving interfaces, and questions of control and trust that arise when someone is asked to run a “virus”-like program on their own computer.","context_research":"I first became interested in the idea of \"art malware\" after seeing two different projects in person several years ago. The first was Descent.exe, a video virus by Peter Burr and Mark Fingerhut that depicts scenes loosely inspired by Bruegel the Elder's painting The Triumphs of Death while filling your desktop with a plague of rat files. The other was DesktopBAM, a performance piece by the Japanese media art duo Exonemo in which a computer mouse plays beats by triggering sound and video with inhuman speed and accuracy. These two projects showed me that it was possible to take user interface elements as raw materials for an art work.\r\n<br><br>\r\nAnother reference for this project was the user interface games of Pippin Barr, particularly Let's Play: Ancient Greek Punishment: UI Edition, in which the user acts out well-known myths through Windows 95-esque UI interactions. Barr's conceptual framing of interfaces as expressions or performances of emotion was very influential on my thought process.\r\n<br><br>\r\nNathalie Lawhead’s game A_DESKTOP_LOVE_STORY is probably the best example that I found of an interactive narrative that plays out on the computer desktop and reacts to the location of files and folders within the filesystem.\r\n<br><br>\r\nLastly, net artist Alexei Shulgin’s curatorial project Desktop IS was a useful visual reference for prepared desktops, and was helpful for figuring out how to talk about the desktop as a space in my writing.\r\n<br><br>\r\nFor a full bibliography, see the “Further Reading” section.","thumbnail_image":{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/functional-utilities-background-dark-1280-1024x576.png","title":"Thumbnail Image","alt":"Company logo for the Functional Utilities Corporation.","caption":""},"headshot_image":{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/2H6A9793-copy-768x432-1.jpg","title":"2H6A9793-copy-768x432","alt":"oren headshot","caption":""},"slide_show":[{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/icons-1024x576.png","title":"Productivity Software Icons","alt":"Icons for the three f(utility) labs productivity tools.","caption":""},{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/3-1-1024x576.jpg","title":"Thesis Documentation - Notepad Interruptions.","alt":"Many instances of the Windows Notepad app, each displaying the text \"hi\".","caption":"Notepad interruptions."},{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/2-1-1024x576.jpg","title":"Thesis Documentation - Windows as Portals","alt":"4 transparent windows overlaying a computer desktop, each of which reveals a crowd of humanoid figures who otherwise can't be seen.","caption":"Windows as portals."},{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/document_optimizer-1024x576.png","title":"Document Optimizer","alt":"An email to Jeff Bezos containing business stock photos pasted by a virus.","caption":""},{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/break_timer-1024x576.png","title":"Break Timer","alt":"An uncloseable popup alert.","caption":""}],"tags":[{"name":"Art","slug":"art"},{"name":"Experiment","slug":"experiment"},{"name":"Play/Games","slug":"play-games"},{"name":"Software","slug":"software"}],"video_presentation_url":"https://vimeo.com/337309033","video_documentation_url":"https://vimeo.com/331306487"},{"student_id":119,"student_name":"Rebecca Skurnik","student_slug":"rebecca-skurnik","advisor_name":"Gabriel Barcia-Colombo","title":"Absurd Algorithms","thesis_statement":"Can we the trust systems and algorithms that we are currently relying on? What would the world look like if I make my own systems and algorithms?","abstract":"We’re relying on more and more systems or algorithms that we do not fully understand how they work. For example, we use apps to get us what we want, but do we know exactly what these apps are doing to deliver our desired output? Allegations have been made that algorithms are biased, written by white males only. But who knows for sure? For all we know, these algorithms may as well be absurd. \r\nWe rely on these apps to help us and we trust in them yet we do not understand how they operate. My thesis is a series of artistic demonstrations that challenges the neutrality and reliability of the algorithms we rely on. I created my own algorithms and made them absurd. The algorithms are to be used in tandem with the apps in order to get my desired output. After creating my absurd algorithms, I relied on them, and had my friends and family rely on them as well. \r\n<br><br>\r\nAlgorithm 1: Finding a partner<br>\r\nUsing PoseNet (machine learning) to get the placement of your facial features, as well as the placement of the facial features of someone’s picture on Tinder (or another dating app). If the facial feature placements on your picture match the facial feature placements on the other person’s picture, you are a match. The algorithm will tell you to swipe right. Otherwise, you are not a match, and the algorithm will tell you to swipe left. <br>\r\nhttps://vimeo.com/331451712\r\n <br><br>\r\nAlgorithm 2: Finding an apartment<br><br>\r\nUsing (scraping) your past orders on Seamless via a chrome extension to determine what apartment you should get on StreetEasy. <br>\r\nhttps://vimeo.com/331449686\r\n<br><br>\r\nAlgorithm 3: Finding what to watch<br>\r\nUsing your birthday (zodiac sign) to determine which shows/movies you should watch on Netflix.<br>\r\nhttps://vimeo.com/331451135\r\n","context_research":"Research and Reading\r\nBefore finalizing my topic, I was researching the relationship between humans and AI- how we treat AI devices, and how AI devices have impacted our daily lives. I took a step back and started researching the relationship between humans and technology in general. I looked at Lauren McCarthy’s work for inspiration and found her piece Lauren particularly interesting. I also looked at Sam Lavigne’s work and spoke to him for advice. I read a few books, and the one that inspired me most was Your Happiness Was Hacked: Why Tech Is Winning the Battle to Control Your Brain--and How to Fight Back by Vivek Wadhwa and Alex Salkever. In this book, the authors speak about a study that was conducted where participants wanted to lose weight. The participants were split into two groups- one received Fitbits, and the other did not. At the end of the study, the group that did not receive Fitbits lost more weight than the group that had the Fitbits. This was because the group that received the Fitbits relied too much on the technology to tell them what to do, rather than focusing on their bodies to tell them what to do. \r\nThis brought me to think about the topic of reliance and trust. We trust in Fitbits, yet do we really know what they are measuring and how it is all calculated? As a result, I decided to make my own systems for my thesis. I decided to focus on apps in particular. Below is a picture of my thought process- we rely on apps to get us what we want- to watch shows, order food, etc. yet we have no idea how they do this. Therefore, using apps, I decided to make my own fun and absurd algorithms that I will rely on and that will get me what I want. \r\n","thumbnail_image":{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/aa-logo-01-01-1024x1024.png","title":"aa-logo-01-01","alt":"Absurd Algorithms","caption":""},"headshot_image":{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/headshot-2-169x300-1.jpg","title":"headshot-2-169x300","alt":"rebecca headshot","caption":""},"slide_show":[{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/rebecca_2-1024x576.png","title":"rebecca_2","alt":"algorithms","caption":""},{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/rebecca_1-1024x576.png","title":"rebecca_1","alt":"experiment 1","caption":""}],"tags":[{"name":"Experiment","slug":"experiment"},{"name":"Identity","slug":"identity"}],"video_presentation_url":"https://vimeo.com/337309077","video_documentation_url":""},{"student_id":116,"student_name":"Ridwan Madon","student_slug":"ridwan-madon","advisor_name":"Adaora Udoji","title":"Rakan","thesis_statement":"How can I combat toxic masculinity by creating a safe space for men to exercise their emotions? \r\n","abstract":"Toxic masculinity stems from stereotypical masculine gender roles that prevent men from expressing their emotions. The research shows men are thought to be the dominant 'alpha male' and to limit their emotional range primarily to expressions of anger.\r\n<br><br>\r\nWhile there are men who can express their emotion, many are taught to suppress it. I was brought up in a household where I could not express my emotions. It was always a constant battle between what I felt and what I was taught to feel. \r\n<br><br>\r\nI was also a part of a deeply misogynistic, male-dominated space where my male friends behaved in a sexist way, verbal abuse was common.  I witnessed how they  internalized the societal message that  sexual objectification is innocuous. They lack empathy toward women and feel entitled to objectify women. They disturbingly see issues like harassment, verbal and physical abuse, and violence as normal. Their ignorance is an affirmation of their masculinity.\r\n<br><br>\r\nBut there are men who want to speak out against misogyny. However, because they feel isolated and alone in their discomfort, they do not say anything. Their silence, in turn, reinforces the false perception that only a few men want to engage in conversations around gender politics.\r\n<br><br>\r\nRakan, which means ‘companion’ in the Malay Language, is an experiment that explores the relationship of a human conversation and the programmed chatbot. Rakan allows men to express their emotions. Users navigate open-ended questions designed to help them exercise their emotional intelligence. Because Rakan is a mobile wearable, users can also interact with it at their own time. \r\n<br><br>\r\nIn conclusion, Rakan is the first step for men to exercise their emotions without social pressure. By giving them an intimate space to navigate through conversations, men can build their empathy, emotional intelligence, and interpersonal skills. \r\n","context_research":"Toxic masculinity is a colossal challenge that will take time and extensive effort to overturn since it’s based on thousands of years of culture building. Men have been told to conform to a preconceived ideal that hurts women. From harassment to assault, misogyny is understood to men as ordinary [Drury, B J: Allies against Sexism].<br><br>\r\n\r\nFurther perpetuating this issue is the male gaze. Women are always portrayed as objects to sate men, leaving negative influences for boys and men [Middleton, Peter : The inward gaze : masculinity and subjectivity in modern culture. Studies have shown that in the U.S alone, 1 in 3 women has experienced harassment in their lifetime [National Domestic Violence Statistics,2017].\r\n<br><br>\r\nThere is a need for men to find allies in other men [Jackson Katz: Tough Guise]. There have been studies showing a significant number of men uncomfortable with the way their male peers talk about and treat women [Jackson Katz : The Macho Paradox]. However, only a few men in our society have dared to speak out publicly against toxic masculinity.\r\n<br><br>\r\nInclusion and visibility of advocacy are important. Campaigns like #metoo and #heforshe provide a public platform for individuals to be heard and speak up. Others like EVRYMAN, create spaces for men to exercise their emotion, coaching them to express their emotional vulnerability.\r\n<br><br>\r\nFeminist artist Zoe Buckman uses written words in her works. It made me realize that words can be a strong factor to push my work further. Annouk Wipperecht, a Hi-Tech Fashion Designer and Innovator, her works show an emotional function of wearables.\r\n","thumbnail_image":{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/fazdlyimage-1.jpg","title":"fazdlyimage","alt":"fazdlyimage","caption":""},"headshot_image":{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/profile-pic1-768x432-1.jpg","title":"profile-pic1-768x432","alt":"ridwan headshot","caption":""},"slide_show":[{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/website-1024x576.png","title":"Rakan chatbot","alt":"Two iphone, one with a home screen of rakan.","caption":"Rakan chatbot"},{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/redwan_phone-1024x576.jpg","title":"Rakan Chatbot","alt":"A guy holding on to a phone with rakan application chatbot open","caption":"Rakan Chatbot"},{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/khalid2-1024x576.jpg","title":"Rakan Wearable Chatbot","alt":"Guy wearing wearable chatbot using Rakan","caption":""},{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/2withlogo-1024x576.jpg","title":"Wearable Chatbot","alt":"Mannequin wearing a wearable cap with bone conduction headphones","caption":""}],"tags":[{"name":"Design","slug":"design"},{"name":"Experiment","slug":"experiment"},{"name":"Identity","slug":"identity"},{"name":"Machine Learning","slug":"machine-learning"},{"name":"Mobile","slug":"mobile"},{"name":"Product Design","slug":"product-design"},{"name":"Python","slug":"python"},{"name":"Self-care","slug":"self-care"},{"name":"Social Good/Activism","slug":"social-good-activism"},{"name":"Speech","slug":"speech"},{"name":"Wearables","slug":"wearables"}],"video_presentation_url":"https://vimeo.com/336821935","video_documentation_url":"https://vimeo.com/339777060"},{"student_id":112,"student_name":"Roland Arnoldt","student_slug":"roland-arnoldt","advisor_name":"Kathleen M Sullivan","title":"EDEN","thesis_statement":"As we are trying to create new digital/physical paradises with \"intelligent\" machines, will those machines ultimately love us? To start with, how can we find new ways to relate to digitally constructed entities? <br><br>\r\nMy ITP master thesis project on sonic storytelling through spacial sound with neural network agents in a simulation: Deconstruct a paradise. To reconstruct a paradise. ","abstract":"A machine learning agent explores in a game-engine a simulated Garden of Eden with the ultimate goal to break out of it. Every major element in this garden has a distinct place and sound. The audience does not see the simulation, the agent's journey in paradise can only be experienced through sound in space: with a quadrophonic speaker system in a physical setting in real time. This creates a three dimensional sonic space for the simulated paradise, we are hearing the new world through the agent's ears as an ever changing 3D-soundscape. To create a direct bond between the human artist and the digital perfomer, the agent can only move when the artists heartbeat is detected and sent over into the simulation. The sonification abstracts the story of the Garden of Eden and gives the audience the freedom to reconstruct and rethink their relationship towards AI on an emotional and subconscious level.\r\n","context_research":"The theoretical part of my piece is influenced by the works of system theorists/philosophers/sociologists Theodor Adorno, Max Horkheimer, Niclas Luhmann, Juergen Habermas, Jacques Derrida, Byung Chul Han and current research in the field of neural networks, especially deep reinforcement learning. My artistic approach is rooted in the Fluxus-movement, namely Joseph Beuys' performative focus on art as a collective form of healing, Ian Cheng's works on simulations and Louise Bourgois and Christoph Schlingensief's approach to personal healing and seeing through art. \r\n<br><br>\r\nI experimented with different media for the representation of the de/reconstructed simulation: a physical installation piece (interactive and non-interactive), a mobile experience and an online version. I finally settled for a sonification of the simulation to give the 3D-world of the agent a 3D sonic space.\r\n","thumbnail_image":{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/thesis_title_image-1024x683.jpg","title":"thesis_title_image","alt":"title image showing a human head between golden letters for the word \"eden\"","caption":""},"headshot_image":{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/profile_pic-768x427-1.jpg","title":"profile_pic-768x427","alt":"roland headshot","caption":""},"slide_show":[{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/boat_sound-1024x576.png","title":"sound_boat","alt":"main installation showing a felt cube on an inflatable boat inside a quadrophonic speaker setup","caption":""},{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/eden_backend-1024x559.jpg","title":"eden_backend","alt":"depiction of the agent in simulation facing the horizon","caption":""},{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/hand_apple_watch-1024x576.jpg","title":"hand_apple_watch","alt":"apple watch on hand showing heartbeat, agent viewpoint as word and charging button","caption":""},{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/thesis_title_image_big-1024x576.jpg","title":"thesis_title_image_big","alt":"title image showing a human head between golden letters for the word \"eden\"","caption":""}],"tags":[{"name":"3D","slug":"3d"},{"name":"Art","slug":"art"},{"name":"Machine Learning","slug":"machine-learning"},{"name":"Narrative/Storytelling","slug":"narrative-storytelling"},{"name":"Sculpture","slug":"sculpture"},{"name":"Simulation","slug":"simulation"},{"name":"Sound","slug":"sound"},{"name":"Spatial Audio","slug":"spatial-audio"}],"video_presentation_url":"https://vimeo.com/336827024","video_documentation_url":"https://vimeo.com/335244699"},{"student_id":115,"student_name":"Roxanne Kim","student_slug":"roxanne-kim","advisor_name":"Kathleen M Sullivan","title":"Future IVX (In-Vehicle Experience)","thesis_statement":"\tFuture IVX is a simulated installation of the future In-Vehicle Experience. In this installation, future automobile works as a moving space. Based on user tests and surveys, I create a user-friendly environment and observe how users interact and response. As a result, I examine how we can develop and how people accept when the age of autonomous vehicles comes.","abstract":"\tThe age of self-driving vehicles has come. For decades, the main purpose of the car was to keep me moving. But what can people do if they say the problem is solved? Personally, I am interested in cars, one of which is a fun driving experience. If all cars are fully automated, why buy a car? However, BMW's M series is for the fun driving experience. If we go in the era of autonomous driving, who will guarantee that fun. Therefore, I will research how future human-machine interaction can coexist and how automobile machinery can cooperate with people. What about the appearance of the car in the near future? There are several levels of automation, but in the next few years, the future may mainly consist of purely autonomous vehicles like the Google X auto-driving car without pedals or steering wheel. Does that mean people can do nothing? it's not like that. In terms of human-machine interaction, machines can be being in a car more fun. \t\r\n<br><br>\tLet's take a few examples. First of all, assuming a user is driving, the computer can act as a pacemaker during driving. For example, driving in the city, it improves navigation and helps the user by communicating with pedestrians and obstacles. Another example is, if this person is on the highway, to encourage fun driving experiences such as high-speed driving and gear shifting. Secondly, looking at the function as an assisting friend requires a more emotional interface. It will interact not only in cars but also in life. For example, the system will integrate with your other smart devices. In terms of the hardware side, it provides an ergonomic custom seat or sound system that uses only the frequencies that specific passengers can hear. Considering the software approach, the lighting system will be triggered by the user's emotional mood or sleep mode when he/she tired. Synchronize information without borders to listen to music that you heard right before from home. So I focus on what people can do in that personal moving space and how they respond to the autonomous car environments and interact with it.","context_research":"\tAmong the various types of prototyping, the reason why I chose a simulating installation is an exhibition - The Road Ahead: Reimagining Mobility by Cooper Hewitt. Despite there was a great exhibition, I felt a lack of car experience. Especially, there were two surveys about what people want to a future car? One tends to the approach of the vehicle culture. Although people get the self-driving car, some of them still want to own their car instead of using a taxi or transportation. The other survey was that what people want to do in your car if it’s fully autonomous. The prior feedback was about time usage or consuming. Many people want to spend ‘non-driving time’ to sleep, relax or work. Nevertheless,  it’s hard to find experience simulation. Therefore, I create a simulating installation. \r\n<br><br>\tMostly, I referred to research papers related to Autonomous Car and HMI(Human Machine Interaction). I looked through some academic papers about autonomous cars. From those papers, I got the more idea; the revolution of (autonomous) car, how it changes our life, and how much it shifts our vehicle culture. In terms of user tests, I was helped how I approached users and designed user test by Using embodied design improvisation as a design research tool by David, S. and Wendy, J.","thumbnail_image":{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/thumbnail-3-1024x576.png","title":"thumbnail","alt":"logo","caption":""},"headshot_image":{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/roxanne_kim_headshot_03-768x432-1.jpg","title":"roxanne_kim_headshot_03-768x432","alt":"roxanne headshot","caption":""},"slide_show":[{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/slide2-1-1024x576.jpg","title":"slide2","alt":"Installation Sketch","caption":""},{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/slide3-2-1024x576.jpg","title":"slide3","alt":"installation","caption":""},{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/side_show_imge.png","title":"side_show_imge","alt":"Mobile Application Screenshots","caption":""},{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/slide5-1-1024x576.jpg","title":"slide5","alt":"Documentation","caption":""},{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/side_show_image_002.png","title":"side_show_image_002","alt":"image 6","caption":""}],"tags":[{"name":"Car","slug":"car"},{"name":"Design","slug":"design"},{"name":"Mobile","slug":"mobile"},{"name":"UX","slug":"ux"},{"name":"VR/AR/Immersive","slug":"vr-ar-immersive"}],"video_presentation_url":"https://vimeo.com/336827088","video_documentation_url":""},{"student_id":122,"student_name":"Sam Chasan","student_slug":"sam-chasan","advisor_name":"Kathleen Stevens Wilson","title":"Chaff Map","thesis_statement":"Chaff Map is a web platform to share and find by-products, and projects made from by-products. It aims to help tackle the issue of climate change through proactive collaborative innovation.\r\n","abstract":"Chaff Map aims to reduce the amount of solid waste heading to landfills through a few methods:<br>\r\n1) Inspiring individuals to create interesting things from free materials<br>\r\n2) Helping people save money by producing less garbage<br>\r\n3) Informing people about the benefits of sharing by-products, and tutorials for interesting projects<br>\r\n(4) Informing people about the climate consequences of a lackadaisical approach to waste. If Chaff Map can reduce the amount of solid waste heading to landfills by even 1%, that would reduce methane emissions from landfills by approximately 2 million cubic feet each day.\r\n","context_research":"Every year, the United States generates over two hundred and fifty million tons of municipal solid waste. Much of this is useful material that has only been discarded because its immediate use has been exhausted, and it is cheaper for the owner of the material to discard it than to maintain, fix, or clean it. \r\n<br><br>\r\nI discovered this first-hand in two primary ways: First, I learned that discarded coffee husks - “Chaff” - is a perfect substrate for growing oyster mushrooms, so I took some that would have otherwise been trashed from my local coffee roaster, and grew mushrooms in my backyard. Second I took discarded plastic from an experience room I worked at and used it as a drop-cloth to protect my floors when I paint. In both circumstances the owners of the trash I used were more than happy for me to take their waste off their hands. Their only agenda was to bag it up, and put it on the curb for removal, despite the many potential uses of the material.\r\n<br><br>\r\nThe consequences of this lax approach are dire, and numerous (https://19january2017snapshot.epa.gov/climate-impacts_.html). Therefore, it is  incumbent upon us as a species and society to develop proactive preventative solutions. Chaff Map aims to be one of these solutions. There are many services for sharing free items, such as Craigslist or Freecycle, and there are also many tutorial sharing sites, such as Pinterest and Youtube. However, there is no centralized platform for repetitively generated waste such as by-products. This incredible amount of waste being generated daily by businesses world wide needs to be addressed. As over 85% of people have the internet in their pocket, I chose to develop this software tool to connect to, and be used, by the world. ","thumbnail_image":{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/logo-1024x576.png","title":"logo","alt":"chaffmap logo, trash can with a map pin above it, inside the map pin is a cycle icon","caption":""},"headshot_image":{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/headshot-sexy-221x300-1.jpg","title":"headshot-sexy-221x300","alt":"sam headshot","caption":""},"slide_show":[{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/Screen-Shot-2019-05-09-at-9.19.00-PM-1024x562.png","title":"Screen Shot 2019-05-09 at 9.19.00 PM","alt":"chaffmap.com home page","caption":""},{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/Screen-Shot-2019-05-07-at-2.11.33-PM-1-1024x536.png","title":"Screen Shot 2019-05-07 at 2.11.33 PM","alt":"chaffmap.com about page","caption":""},{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/slide-photo-1024x576.jpg","title":"slide-photo","alt":"Chaffmap icon above chaff, bricks of mycelium, and oyster mushrooms","caption":""}],"tags":[{"name":"Product Design","slug":"product-design"},{"name":"Social Good/Activism","slug":"social-good-activism"},{"name":"Sustainability","slug":"sustainability"},{"name":"Tool","slug":"tool"}],"video_presentation_url":"https://vimeo.com/336836823","video_documentation_url":"https://vimeo.com/331481388"},{"student_id":123,"student_name":"Sam Hains","student_slug":"sam-hains","advisor_name":"Gabriel Barcia-Colombo","title":"Jack and Sam&#8217;s eDream Portal","thesis_statement":"\"Jack and Sam’s eDream Portal\" is a real-time video simulation, about the search for the human and the authentic within a simulated world. ","abstract":"“While most tools produce effects on a wider world of which they are only a part, the computer contains its own worlds in miniature.” - Wendy Hui Kyong Chun.\r\n<br><br>\r\nAs reality is drafted into digital environments, the computer simulation offers the opportunity to create worlds and bodies without unwanted complexity. It allows us to devise private games and internally consistent worlds in the face of absurdity and paradox. Advances in computer imaging technology towards “photorealism” further seduce us into believing that we are looking at concrete realities rather than ideological assemblages of math and code. As reality is increasingly reflected through the small mirrors of digital simulation, we risk losing sight of the mysterious nature of our lived experience.\r\n<br><br>\r\nBy creating automated worlds that make no gesture towards fetishized “graphic realism” or instrumental modes of seduction, we begin to see the simulation for what it is: A world we can’t escape from. A future predetermined by various corporate, political and ideological entities. A prison where an emancipatory politic is a fleeting and distant reality.\r\n<br><br>\r\nFor my final work, I created a triptych of simulations based on an ironic reading of Bosch’s Christian creation triptych - \"The Garden of Earthly Delights\".  The appropriation of this material, provided a way of engaging directly with the world making capabilities of computer systems through falsified mythology.  The result is a 6 channel video installation that explores the way in which computers create worlds and realities in their own image. \r\n","context_research":"Some notable influences:\r\n<br><br>\r\nThe concept of \"video games that play themselves\" as an art practice, has been pioneered by artist, Ian Cheng. His work exploring the relationship between worlds and simulations is foundational to my practice.\r\nHis and my work are both developed using the kind of multi-agent simulation technology associated with video game bots, military planning systems and corporate \"crash tests\". They are the \"Type A\" personality type of the artificially intelligent world.  Although, artificially stupid would be more accurate. I am fascinated by their absurd simplification of the human form into a series of loop-based instructions\r\n<br><br>\r\nI also spent a lot of time as a tourist inside existing simulations; drawn into the inhuman choreography of their inhabitants and other interstitial weirdness.  I have tried to bring into the feeling of my video works. Grand Theft Auto 5’s simulation of Los Angeles, and FlexSims corporate logistics software are notable references.  The main characters of \"Jack and Sam's eDream portal\" are appropriated from corporate simulation software FlexSim.\r\n<br><br>\r\nThe writings of Philip K Dick and his redeploying of the struggle for authenticity and freedom within a simulated universe, was another very important reference for bringing my ideas together. \r\n","thumbnail_image":{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/6-channel-1024x576.png","title":"Jack and Sam's eDream Portal","alt":"6 images. top left image shows a man dressed as jesus and a zebra walking through reflective water. the bottom left image shows eden, a garden paradise. the middle top image shows a deconstructed office environment on the verge of destruction. smoke and fires burning, money flying everywhere. the bottom middle image shows a first person perspective view of the office. a hand reaches forward and presses a device. the top right image shows large stalactites protruding from a reflective ground. fires are burning and strange video game characters populate the scene. the bottom right image shows a first person perspective of someone shooting a gun at another person.","caption":"Screenshot of 6 channel video simulation."},"headshot_image":{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/self-portrait-2-1024x576.png","title":"self portrait","alt":"self portrait","caption":""},"slide_show":[{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/EDEN-1024x576.png","title":"Garden of eden","alt":"2 images of simulated garden of eden. one from first person perspective. other from 'gods eye' perspective. lephant moves through water. birds in the sky. green trees.","caption":"Screenshot of 'Eden' simulation"},{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/OFFICE-1024x576.png","title":"Office","alt":"Image of an office environment, abstract. reflective, water-like floors. Fires are burning. Another image from first person perspective inside the office. burning fires and a stack of televisions. The workers sit around on couches, as their world burns.","caption":"Humanity at the brink of madness and destruction."},{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/HELL-1024x576.png","title":"Hell","alt":"The world of corporate agents, Jack and Jill has been invaded by creatures from other simulations. The distinction between who belongs in the simulation and who is an invader is blurred as Jack and Jill become locked in an eternal DeathMatch against eachother.","caption":"Jack and Jill's world descends into dark chaos."},{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/6-channel-1024x576.png","title":"Jack and Sam's eDream Portal","alt":"6 images. top left image shows a man dressed as jesus and a zebra walking through reflective water. the bottom left image shows eden, a garden paradise. the middle top image shows a deconstructed office environment on the verge of destruction. smoke and fires burning, money flying everywhere. the bottom middle image shows a first person perspective view of the office. a hand reaches forward and presses a device. the top right image shows large stalactites protruding from a reflective ground. fires are burning and strange video game characters populate the scene. the bottom right image shows a first person perspective of someone shooting a gun at another person.","caption":"Screenshot of 6 channel video simulation."},{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/JackAndGods-1024x576.png","title":"Gods and Worlds","alt":"a man sits at a chair in front of a computer, facing the wrong direction. the world is in flames","caption":"A screen capture from Hell, one of the three simulations of 'Jack and Sam's eDream Portal'"}],"tags":[{"name":"3D","slug":"3d"},{"name":"Art","slug":"art"},{"name":"Critical Theory Art","slug":"critical-theory-art"},{"name":"Narrative/Storytelling","slug":"narrative-storytelling"},{"name":"Simulation","slug":"simulation"}],"video_presentation_url":"https://vimeo.com/337309112","video_documentation_url":"https://vimeo.com/samhains/edream"},{"student_id":143,"student_name":"Sandy Hsieh","student_slug":"sandy-hsieh","advisor_name":"Adaora Udoji","title":"Modular Patternmaking","thesis_statement":"Modular Patternmaking is my approach to systems thinking for the design and manufacture of wearable technology. To achieve seamless integration between hardware and soft wear, it is essential to leverage patternmaking at the intersection of fashion design and technology.","abstract":"Unlike fast fashion or PCBs, wearables are not easy to design or mass produce. The problem resides in the lack of communication and collaboration between two vastly different fields of expertise. Googling “wearable clothing” will return a myriad of IoT compatible sportswear and LED-enhanced garments that have failed to gain traction or acceptance in mainstream fashion. With limited understanding and access to what is possible outside of their respective industries, it’s proven difficult for fashion designers and engineers not to fall into the trap of designing gimmicky solutions for problems that don’t exist.\r\n<br><br>\r\nModular patternmaking is my careful dissection of the anatomy of clothing to examine how each parts of a whole can be manipulated, segmented, and/or combined to assemble a garment with integrated technology. When significant form factors such as garment type, silhouette, fit, design details, materials, trims, and finishes for accommodating hardware are identified and taken into account, can wearables find a place in mainstream fashion? \r\n<br><br>\r\nFor my thesis, I want to explore how modular patternmaking can be leveraged within the framework of product design to develop wearables of high value, support the integration of electronics, and be scaled for mass production. \r\n<br><br>\r\nTo demonstrate and test the viability of modular patternmaking, I designed a case study where I conducted qualitative interviews with 40 people about their style and how they envision the future of wearables. A thorough analysis and aggregation of common themes and insights led to the ideation of ‘Timepiece’, a leather motorcycle jacket that explores gesture as a wearables solution. \r\n","context_research":"For context and research, I read books and papers on the psychology of human-centered design, and multiple frameworks for product design and optimizing user experiences. I studied articles on the fashion supply chain, hardware hacking and manufacturing, connected devices, and the taxonomy of innovations for wearable products and services. I analyzed the traction of smart watches and hearables, and identified the major players, trends, and projections for the global wearables market. In addition, I interviewed industry professionals in wearables consulting, product design, physical computing, and the fashion industry. \r\n","thumbnail_image":{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/MPM.jpg","title":"Modular Patternmaking","alt":"Modular Patternmaking","caption":""},"headshot_image":{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/Sandy-768x512-1.jpg","title":"Sandy-768x512","alt":"sandy headshot","caption":""},"slide_show":[{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/framework-1-1024x715.png","title":"framework","alt":"modular patternmaking product design framework","caption":""},{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/Interviews-1024x767.jpg","title":"Interviews","alt":"design research interviews","caption":""},{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/Working-1-1024x613.jpg","title":"Working","alt":"Woman patternmaking using CAD software","caption":""},{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/hardware-1-1024x683.jpg","title":"hardware","alt":"Digital clock hardware prototype","caption":""},{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/timepc-1024x766.png","title":"timepiece","alt":"Motorcycle jacket with embedded time and gesture on left sleeve","caption":""}],"tags":[{"name":"Design","slug":"design"},{"name":"IOT","slug":"iot"},{"name":"Product Design","slug":"product-design"},{"name":"UX","slug":"ux"},{"name":"Wearables","slug":"wearables"}],"video_presentation_url":"https://vimeo.com/336822126","video_documentation_url":""},{"student_id":139,"student_name":"Shawn Ma","student_slug":"shawn-ma","advisor_name":"Adaora Udoji","title":"Hyper-Device","thesis_statement":"How to integrate Augmented Reality contents with smart toys?","abstract":"This is a project of how to integrate AR with smart toys. More specifically, this project explored and compared different possible way to integrate AR with smart toys from the very beginning - tracking. The whole process would be Detection, Augmentation, Tracking, and Interaction. Detection and Tracking, are the most two essential parts. The possible solutions for tracking smart toys/objects in AR are Image Target, 3D Object Detection and Tracking, Direct location information sent by smart toys and Machine Learning. This project compared and experimented those possible ways of detection and tracking, and finally decided to go with Machine Learning.  The project also experimented and investigated different approach towards better interactions in AR. ","context_research":"3D Object Detection and Tracking:<br>\r\nhttps://developer.apple.com/documentation/arkit/scanning_and_detecting_3d_objects<br>\r\nhttps://blog.viromedia.com/arkit-2-0-continuous-image-tracking-and-object-detection-with-viroreact-6823b94b0eb1<br>\r\n<br>\r\nVision + CoreML for real-time object detection and tracking:<br>\r\nhttps://developer.apple.com/documentation/arkit/using_vision_in_real_time_with_arkit<br>\r\n<br>\r\nInteraction in AR:<br>\r\nhttps://medium.com/web-ar/interaction-design-principles-for-augmented-reality-903a597ef4be\r\n","thumbnail_image":{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/Cozmo-768x432-1.jpg","title":"Cozmo-768x432","alt":"logo","caption":""},"headshot_image":{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/Portrait-768x432-2.jpg","title":"Portrait-768x432","alt":"shawn ma portrait","caption":""},"slide_show":[{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/shawn_1.png","title":"shawn_1","alt":"shawn 1","caption":""},{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/shawn_2.png","title":"shawn_2","alt":"shawn2","caption":""},{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/shawn_3.png","title":"shawn_3","alt":"shawn 3","caption":""}],"tags":[{"name":"3D","slug":"3d"},{"name":"Machine Learning","slug":"machine-learning"},{"name":"Mobile","slug":"mobile"},{"name":"VR/AR/Immersive","slug":"vr-ar-immersive"}],"video_presentation_url":"https://vimeo.com/336822034","video_documentation_url":"https://xiaoma.space/thesis-video"},{"student_id":121,"student_name":"Shreiya Chowdhary","student_slug":"shreiya-chowdhary","advisor_name":"Kathleen Stevens Wilson","title":"Itivrit: Travel through time","thesis_statement":"Can recently possible technologies be used to enhance current methods of cultural preservation and exhibit design for visitors to heritage sites around the world?","abstract":"Itivrit is an Augmented Reality museum application that enhances a visit to an ancient palace in India by allowing visitors to experience oral histories about the creators and history of the palace, its rooms, and the objects on display there in an audio-visual format.<br><br>\r\nForgotten narratives are brought back to life through audio narration and the superimposition of explanatory images. Virtual, 3D representations of human figures and objects belonging to different eras of the palace’s history guide the user through the site. Hence, a deeper understanding of the culture and history of the palace is achieved by the end of the tour.","context_research":"Itivrit, like all great endeavours, is an amalgamation of some of the finest technological discoveries made for historical preservation. It finds its inspiration from:\r\nRoi Lev’s Inventing America - An Augmented Reality experience based on Governor’s Island where you can experience the land as a 17th century colonist.\r\n<br><br>\r\nItivrit here gains from the concept of an experience taking place at a physical location where the user is made to feel like they have traveled back in time. It educates and enlightens them about the history of New York City using Augmented Reality.\r\n<br><br>\r\nThe Tenement Museum - A National Historical Landmark in New York City that is a Museum which lives to retell forgotten and shared narratives of the settlers of the tenement.\r\n<br><br>\r\nItivrit was born after my multiple visits to the Tenement. The Tenement Museum is a historical location which has been preserved just the way it was when it was being lived in. Additionally, the administration takes visitors through narratives about the daily lives of the residents. Similarly, Itivrit is based on India’s Forts and Palaces which have been preserved and educate visitors about the reasons for their existence and how they were lived in by the royal families.<br><br>\r\nThe Giza Project - A 19 year long project where the Pyramids and Tombs of Giza have been 3D modelled to perfection so as to educate children across the world who cannot physically travel to Egypt.\r\n<br><br>\r\nUsing new media and technologies, the Giza Project is educating the public on the intricacies of the Pyramids and Tombs of Egypt. Similarly, Itivrit is also using recently possible technologies to illuminate a rich and vibrant culture and its history.\r\n<br><br>\r\nAll in all, Itivrit combines the learnings from all these projects to retell narratives and allow a visitor to experience a history that no longer exists.","thumbnail_image":{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/thumbnail-16-1024x576.jpg","title":"Itivrit","alt":"This is the Itivrit logo.","caption":""},"headshot_image":{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/Shreiya-copy-768x576-1.jpg","title":"Shreiya-copy-768x576","alt":"shreiya profile","caption":""},"slide_show":[{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/theFort-1-1024x576.jpg","title":"Mehrangarh Fort","alt":"This is an image of the exterior of Mehrangarh Fort.","caption":""},{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/Fort-1024x576.jpg","title":"Fort","alt":"This is an image of the interiors of the Mehrangarh Fort.","caption":""},{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/king-1024x446.gif","title":"Maharaja Takhat Singh","alt":"This is a gif of a 3D model of Maharaja Takhat Singh walking.","caption":""},{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/TakhatOtherGif-1.gif","title":"TakhatOtherGif","alt":"This is a gif of Takhat Vilas's 3D model moving in orbit.","caption":""},{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/IMG_2434-1024x576.jpg","title":"IMG_2434","alt":"Itivrit: Travel through time","caption":""}],"tags":[{"name":"Culture","slug":"culture"},{"name":"History","slug":"history"},{"name":"Installation","slug":"installation"},{"name":"Narrative/Storytelling","slug":"narrative-storytelling"},{"name":"VR/AR/Immersive","slug":"vr-ar-immersive"}],"video_presentation_url":"https://vimeo.com/336836771","video_documentation_url":"https://vimeo.com/328028372"},{"student_id":127,"student_name":"Simon Jensen","student_slug":"simon-jensen","advisor_name":"Nancy Hechinger","title":"Safety Last","thesis_statement":"Would more creative applications in software be unleashed if we didn’t start by saddling designers and developers with privacy and security concerns? I propose a “Safety Last” approach to software development. ","abstract":"Despite our supposed concerns that private data is collected and used by third parties, we willingly agree to provide personal information in exchange for online utilities: email, calendars, social media and e-commerce. “Safety Last” is a series of software applications exploring the possibilities that might emerge if we intentionally sacrifice computer privacy and safety. <br><br>\r\n\tThe project explores what software might look like if we removed a current main principle in software development: that is, the assumption that software should be safe. The applications derived from this project are built-out thought experiments that suggest a different approach to exploring digital interactions and privacy. “Safety Last” consists of a file sharing application called “Open Desktop” and two remote control projects “Participate” and “Notify”. All the projects are intended to have a useful functionality to them which plays out against the control the user must sacrifice in order to use them. ","context_research":"\"We don't have a physical response or intuition for what it feels like to have all your data looked at by an algorithm. We do have a really clear understanding of what it means to be looked at by another person.\" - Lauren McCarthy\r\n<br><br>\r\nInspired by this idea, “Open Desktop” is intended to challenge the perception of the desktop as a personal space. This application allows users to see and manipulate files located on other connected devices. By authorizing them to move, share and delete files with one another, it reimagines the desktop as a communal environment. “Open Desktop” is a comment on our willful sharing of information with online platforms.    \r\n<br><br>\r\nThe idea for “Participate” was inspired by readings in Zuboff’s “The Age of Surveillance Capitalism”. Do we trust random users enough to let them into our private system? Do we trust people creating the software we download? “Passage” is a remote Desktop Control Application to test those questions. It serves your screen, mouse and keyboard to any online user visiting a specified webpage, giving them absolute control. <br><br>\r\nWe trust the companies and the unknown designers who produce software but we are appalled by the idea of letting even a friend take over our computer. Why do we think of a person as malware and trust the companies that make money from us?  \r\n<br><br>\r\n“Notify” is a tool to change our behavior on a computer. This app is seen as an alternative to page-blockers, timers and self-control. Simply, the application allows other users to go to a webpage and see if you are online. From the webpage they can give you a notification, screen lock or turn off your computer.       \r\n","thumbnail_image":{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/exp3photo-1024x723.png","title":"exp3photo","alt":"participte","caption":""},"headshot_image":{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/thesisImage-768x512-1.jpg","title":"thesisImage-768x512","alt":"simon headshot","caption":""},"slide_show":[{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/simon2.png","title":"simon2","alt":"open desktop","caption":""},{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/theOne.gif","title":"theOne","alt":"the one","caption":""},{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/exp3photo-768x542-1.png","title":"exp3photo-768x542","alt":"participate","caption":""},{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/longone.gif","title":"longone","alt":"longvid","caption":""},{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/better-1.gif","title":"better","alt":"bestone","caption":""}],"tags":[{"name":"Data","slug":"data"},{"name":"Design","slug":"design"},{"name":"Networks","slug":"networks"},{"name":"Privacy/Security","slug":"privacy-security"},{"name":"Software","slug":"software"}],"video_presentation_url":"https://vimeo.com/337314328","video_documentation_url":"https://vimeo.com/331502620"},{"student_id":125,"student_name":"Sofia Luisa Suazo Monsalve","student_slug":"sofia-luisa-suazo-monsalve","advisor_name":"Gabriel Barcia-Colombo","title":"Post-photographic Topographies","thesis_statement":"An exploration of the contemporary state of photography and its effects on contemporary image-making, viewing practices and world-view imagery.","abstract":"Post-photographic Topographies is a series of artistic experimentations focused on different aspects of the photographic nonhuman gaze of the physical and digital world. Collectively, the three pieces of the project enable the emergence of an allegorical topography that serves as a documentation and delineation of the world-making power of nonhuman photography.","context_research":"The project is framed as an artistic representation of various media archeology concepts and ideas on contemporary photography (and other related light-based mediums), but the project specifically focuses in the post-humanist concept of “nonhuman photography” proposed by the writer and artist, Joanna Zylinska. \r\n<br><br>\r\nAs the author explains, the concept can be understood as “the execution of technical and cultural algorithms that shape our image-making devices as well as viewing practices”. It is the photo making practice powered by the symbiosis between human vision and security cameras, mobile photography, satellite images, and other platforms and technologies that enable the unfolding of a post-photography that is continuously decoupling from human vision but at the same time inevitably shaping it. \r\n<br><br>\r\nConsidering that the authenticity of the “real” world has historically been optically and visually validated, nonhuman photography (as also traditional photography does) not only transforms human vision and perception, it also actively constructs and deconstructs the setting from where it emerges  and sustains itself from, namely, our world.  \r\n<br><br>\r\nThrough the implementation of three artistic experimentations, Post-photographic Topographies explores and questions the world-making power of nonhuman photography, by addressing the following inquiries: \r\n1) How is the environment being seen and experienced by automated vision systems and how is this specific way of world seeing affecting the way humans interact, navigate and position themselves on Earth?; \r\n2) Can nonhuman photography, as an artistic practice, delineate, document and explore a post-human representation of the contemporary world?; \r\n3) Is nonhuman photography enabling the emergence of a post-human topography of the world?\r\n\r\n\r\n \r\n","thumbnail_image":{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/thesis-main-1.jpg","title":"post-photographic topographies","alt":"processed imaged of a map","caption":""},"headshot_image":{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/sofia.jpg","title":"sofia","alt":"sofia portrait","caption":""},"slide_show":[{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/1-6-1024x576.jpg","title":"post-photographic geology","alt":"projection mapping on rock","caption":""},{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/2-3-1024x576.jpg","title":"post-photographic cartography","alt":"3D model of a google street view glitch","caption":""},{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/3-3-1024x576.jpg","title":"post-photographic landscapes","alt":"framed photographic print of a machine learning synthesized image","caption":""},{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/4-1-1024x576.jpg","title":"post-photographic topograghies","alt":"exhibition of post-photographic topographies","caption":""}],"tags":[{"name":"3D","slug":"3d"},{"name":"Art Theory","slug":"art-theory"},{"name":"Machine Learning","slug":"machine-learning"},{"name":"Photography","slug":"photography"},{"name":"Projection Mapping","slug":"projection-mapping"}],"video_presentation_url":"https://vimeo.com/337309191","video_documentation_url":"https://vimeo.com/335213670"},{"student_id":128,"student_name":"Stephanie Paige Chambers","student_slug":"stephanie-paige-chambers","advisor_name":"Nancy Hechinger","title":"The HOTSpot","thesis_statement":"The HOTSpot is a curriculum and newly-founded organization whose mission is to increase levels of access, awareness, and active participation in STEAM programming amongst underserved and underrepresented community members of the Greater Newark Area of New Jersey.","abstract":"A history of personal interest and involvement, and a network of mentorship and support lit the fire under my mission to connect motivated individuals who may be interested in Science, Technology, Engineering, Art, and Mathematics (STEAM) with STEAM Professionals (and semi-pros) who have a relationship or general affinity with the underserved community. My goal of nurturing and mentoring the former into developing paths to collegiate-level STEAM education and the STEAM workforce gave rhyme and reason to my plan. I would pull from my experiences and skills acquired at ITP and pour them into the design of a fun and culturally relevant STEAM program curriculum for my community members.\r\n<br><br>\r\nIn alignment with my mission and in light of my past experiences and new discoveries, I have posed the question: “How can I help to increase the levels of awareness, access, and active participation in STEAM-related programs amongst residents (aged 11-17) of underserved communities, specifically the Greater Newark Area?”\r\n<br><br>\r\nOver the course of the semester, I have researched and spoken with several educators and parents regarding what has been available to students in Newark, NJ and surrounding neighborhoods, as far as STEAM programming goes. I found that while science is appreciated and art beloved within the Greater Newark community, extracurricular STEAM-related programming geared toward its core residents is, at best, inaccessible to the masses.\r\n<br><br>\r\nIn an effort to reach those black and brown teens within Greater Newark who will be going to college fairly soon, I attempted to conduct outreach for workshop participants on social media, through family and friends, at two high schools that I had  attended, a public library, and the Newark Housing Authority via the Training Recreation Education Center (TREC) where I now hold a partnership and will be hosting The HOTSpot’s STEAM workshops on a weekly basis.","context_research":"While underserved minority students may not be graduating from STEAM programs at the same rate as their peers - despite their potential interest in STEAM comparing in rate to their White and Asian counterparts - we must acknowledge the differences in what has been accessible to each population. I would argue that there are a number of reasons for the gap, including but not limited to:\r\nmany minority students attending public schools whose circumstances don’t allow for the best quality of education;\r\navailable STEAM-related programs cost money and students lack financial assistance; and\r\nlimited mentorship and extracurricular STEAM opportunities within these communities altogether.\r\n<br><br>\r\nAfrican American, Native American, and Hispanic college students who are interested in STEAM career paths tend to: enroll in these majors but switch before completion; earn STEAM degrees but not pursue careers in the field upon graduation; avoid enrolling in STEAM-related majors at all. As a result, these underrepresented people make up only about 10% of those working in science and engineering occupations. This number pales tremendously in comparison to the 73% of White and 17% of Asian people who fill these same roles.\r\n<br><br>\r\nInspired by programs like Girls Who Code, Black Girls Code and Made in Brownsville, and events like Afrotectopia, my expectation had been to expose STEAM-enthusiastic and STEAM-weary high school students to a day full of workshops. “Wowing” them just enough could allow me to promote their eagerness to learn more and eventually increase their probability of following a STEAM path through the professional career level.","thumbnail_image":{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/thsminilogo169-1024x576.jpg","title":"theHOTSpotMiniLogo169","alt":"The Hotspot Mini Logo","caption":""},"headshot_image":{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/headshot169-768x432-1.jpg","title":"headshot169-768x432","alt":"stephanie headshot","caption":""},"slide_show":[{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/THSPilotDay5-1024x683.jpg","title":"Stephanie_THSPilotDay","alt":"Stephanie Paige with Pilot Day Flyer, Founder of The Hotspot at The Training Recreation Education Center","caption":""},{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/THSPilotDay2-1024x683.jpg","title":"THSPilotDay","alt":"Teen Participant @ THS Pilot Day","caption":""},{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/StarWarsDay1-1024x683.jpg","title":"StarWarsDay1","alt":"Child Participants at the Hotspot's Star Wars Day Event","caption":""},{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/StarWarsDay2-1024x683.jpg","title":"TheHOTSpotPresents...","alt":"Left displays The HOTSpot's Star Wars Day Event Flyer; Right displays Stephanie Paige Chambers, Founder of The HOTSpot, with Mini Lightsaber Cards created at the Star Wars Day event.","caption":""},{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/CraftYoda-1024x683.jpg","title":"CraftYoda","alt":"Fortune Telling Yoda Figures created at Star Wars Day","caption":""}],"tags":[{"name":"Accessibility","slug":"accessibility"},{"name":"Culture","slug":"culture"},{"name":"Education","slug":"education"},{"name":"Networks","slug":"networks"},{"name":"Social Good/Activism","slug":"social-good-activism"}],"video_presentation_url":"https://vimeo.com/337314376","video_documentation_url":""},{"student_id":131,"student_name":"Terrick Gutierrez","student_slug":"terrick-gutierrez","advisor_name":"Adaora Udoji","title":"Ride Home","thesis_statement":" Ride Home places users at the center of a virtual reality narrative which shines light on police violence through the lens of a vehicle passenger. The intent behind Ride Home is to explore how immersive technology can be used to inform, educate, and potentially change the minds of those who do not live these experiences in their daily lives.","abstract":"Police brutality is a racial issue that plagues our nation, one that is largely rooted in racial discrimination, social control, and surveillance. It’s one that has affected me directly. My personal and indirect experience of police harassment and violence have influenced me to create Ride Home, a virtual reality narrative that shines light on police violence through the lens of a vehicle passenger. The objective of Ride Home is to explore how immersive technology, namely virtual reality, can be used to inform, educate and potentially alter the minds of people who do not live these particular experiences. Research shows that the more immersive an experience is, the greater potential impact it has on attitudes and behaviors. ","context_research":"Police brutality is a racial issue that plagues our nation, one that is largely rooted in, racial discrimination, social control, and surveillance. Its origin dates back to slavery and took the form of slave patrolling, a system that enabled groups of Southern White men to discipline and surveil enslaved Africans. Police brutality disproportionately targets black and brown people. I have experienced this injustice first hand when I was thirteen-years-old. On my way home from the store, I was stopped and frisked by a White police officer. My personal and indirect experience of police injustice have influenced the creation of Ride Home, a virtual reality narrative that sheds light on police violence through the lens of a vehicle passenger. In this story, a virtual driver gets pulled over by a police officer who is then asked to get out of the car. Shortly after, an incident unfolds between the two. This experience incorporates actual footage of police traffic stops and images of victims of police shootings. Ride Home explores how immersive technology, namely virtual reality can be used to inform, educate and potentially alter the minds of people who not live these particular experiences. Studies have revealed that 3D immersive technologies such as VR can give users the opportunity to emotionally engage with content or narratives. Additionally, research shows that the more immersive an experience is, the greater potential impact it has on attitudes and behaviors which is precisely why my approach to discussing police harassment, violence, and shootings takes place in VR.\r\n","thumbnail_image":{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/Gutierrez_MainImages_1-768x513-1.jpg","title":"Gutierrez_MainImages_1-768x513","alt":"Gutierrez_MainImages_1","caption":""},"headshot_image":{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/Gutierrez-768x515-1-1.jpg","title":"Gutierrez-768x515-1","alt":"Terrick portrait","caption":""},"slide_show":[{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/Gutierrez_MainImages_1-1-1024x684.jpg","title":"Gutierrez_MainImages_1","alt":"Gutierrez_MainImages_1","caption":""},{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/Gutierrez_MainImages_3-1024x680.jpg","title":"Gutierrez_MainImages_3","alt":"Gutierrez_MainImages_3","caption":""},{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/Gutierrez_MainImages_6-1024x682.jpg","title":"Gutierrez_MainImages_6","alt":"Gutierrez_MainImages_6","caption":""},{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/Gutierrez_MainImages_2-1024x679.jpg","title":"Gutierrez_MainImages_2","alt":"Gutierrez_MainImages_2","caption":""}],"tags":[{"name":"Narrative/Storytelling","slug":"narrative-storytelling"},{"name":"Social Good/Activism","slug":"social-good-activism"},{"name":"VR/AR/Immersive","slug":"vr-ar-immersive"}],"video_presentation_url":"https://vimeo.com/336821978","video_documentation_url":"https://docs.google.com/document/d/1W26xd12u2QMDzxh9hnqvqxWpaOeDkUsv31_jwk-ZeoE/edit?usp=sharing"},{"student_id":134,"student_name":"Tong Wu","student_slug":"tong-wu","advisor_name":"Nancy Hechinger","title":"Daily Dividuals","thesis_statement":"This is a series of avatar-based, Augmented Reality body sculptures of surreal scenes from everyday life in an imaginary future where the roles of human and machine are reversed. Combining social commentary and satire, this project reflects alienation of and between individuals and their surrounding environments due to increasing complexity and capability of technology in the age of algorithm. ","abstract":"“Daily Dividuals” includes a series of Augmented Reality (AR) sculptures presented in short movie clips to provide context. To reflect on the core concept, human alienation in the digital age, the project layers the theme and presents, through an AR lens, the imaginary transformation of the human body merging with and functioning as everyday objects. \r\n\r\nThe project contains two experiments with three examples in each. The student scanned her body to create a hyper-flexible avatar model, and used the model as the key material to construct scenes in the project. The first experiment creatively associates body avatars with everyday objects in shape and function, and explores the possibility and flexibility to duplicate and modify avatar models in an AR environment. \r\n\r\nThe second experiment is a continuation of the first. It purposely reverses the conventional ways a human interacts with common devices, thus presenting an unorthodox perspective in which to reexamine the alienation of humans. The second experiment has more interactivity involved. The audience can explore layers of the AR sculptures through various actions. Therefore, the “seeing” and the “being seen” together fulfill the concept of this experience. \r\n\r\nPlaying with dystopian connotations through the jarring and surreal images, the project prompts viewers to pause and consider the phenomena of estrangement observed in our evolving relationship to and dependence on machines. \r\n\r\nWhen the public becomes insensitive to being treated as measurable data and samples; when people are used to only see highly abstract representation of the complex digital world; when intensive, repetitive human labor is constantly fed into the artificial intelligence industry, are we still dominating the machines, or are we being dominated? We strive to make machines more like us, but it may be that we are becoming more like machines. In a way, we are meeting machines in the middle. ","context_research":"The core concept of this project, human alienation, is a famous philosophical concept used by Karl Marx and Michel Foucault to describe the failure to realize oneself in one’s bodily activities under the capitalist mode of production. Laborers were forced to engage in specialized, fragmented, monotonous one-sided labor, they were estranged from their own potentialities as creative, self-realized many-sided beings. <br><br>\r\n\r\nIt might sound cliché  to bring up this century-old theory, but we are actually undergoing another wave of alienation in this dazzling century. As an artist working in and thinking within the intersection between technology and art, my experiences interacting with the digital world constantly brings me the feeling of being alienated and objectified. In many cases, the interaction between human and machines is becoming so unequal and superficial that it only requires such simple triggers from us as sound, movement or even just the existence of a body with warmth. <br><br>\r\n\r\nIn Gilles Deleuze’s Postscript of Modern Society, he coined the term “dividual”, as “individual” can no longer represents the smallest unit that society could be reduced to. The evolving modern technologies of control makes humans to lose their whole self, and “become ‘dividuals,’ and masses, samples, data, markets, or ‘banks.’ (Deleuze, 1992)” With a social system constantly turning each person into trackable, measurable and virtually marketable components, would those unmeasurable feelings and thoughts be transformed or be trashed? The way we engage with the social systems has been fundamentally reshaped. ","thumbnail_image":{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/Main-Image-1024x576.jpg","title":"Main Image","alt":"A line of rendered avatar models waiting in line with one being curiously leaning her body and looking out.","caption":""},"headshot_image":{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/YourPhoto-768x432-1.jpg","title":"YourPhoto-768x432","alt":"tong headshot","caption":""},"slide_show":[{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/HumanSampleBanner-1-1024x576.jpg","title":"HumanSampleBanner","alt":"A human figure is rendered on the top of an usb drive","caption":"A human figure is rendered on the top of an usb drive"},{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/Fan_v6-1024x576.jpg","title":"Fan_Banner","alt":"Several human figure avatars are rendered into a fan-shape object and standing on the floor","caption":"Several human figure avatars are rendered into a fan-shape object and standing on the floor"},{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/HoldOnBanner-1024x576.jpg","title":"HoldOnBanner","alt":"A line of miniature human figures are binding a book in place of a plastic book binder","caption":"A line of miniature human figures are binding a book in place of a plastic book binder"},{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/FanningBanner-1024x576.jpg","title":"FanningBanner","alt":"A woman is reading a book on a sofa with a human-shape fan fanning her and a cat observing at the corner in a living room environment.","caption":"A woman is reading a book on a sofa with a human-shape fan fanning her and a cat observing at the corner in a living room environment."},{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/HumanSampleBanner-1024x576.jpg","title":"HumanSampleBanner","alt":"A USB drive is placed right next to a laptop, with multiple animated human figures flying over it.","caption":"A USB drive is placed right next to a laptop, with multiple animated human figures flying over it."}],"tags":[{"name":"Art","slug":"art"},{"name":"Speculation","slug":"speculation"}],"video_presentation_url":"https://vimeo.com/337314410","video_documentation_url":"https://vimeo.com/331155335"},{"student_id":135,"student_name":"Vidia Anindhita","student_slug":"vidia-anindhita","advisor_name":"Kathleen M Sullivan","title":"Solus","thesis_statement":"Solus is a series of smart devices that highlights our sense of smell so that people who feel alone can find a state of solitude and joy. How can we transform the experience of this feeling of loneliness into solitude, a state of being alone without being lonely, by exploring our senses and mental states?","abstract":"Solus explores how to regulate our physiological and emotional equilibrium through sensory experiences. The project chooses scent as a method to shift the brain from feeling lonely to embracing solitude and a strong sense of joy.\r\n\r\nThe aim is for three different smart devices to disrupt this perspective of aloneness by using the most pervasive but often forgotten human sense of smell.\r\n\r\nThe three devices are Scent Notification, Scent Clock, and Scent Speaker. Each device was designed to create a multi-sensory experience that impacts mood and memory to transform space in meaningful ways. The scents were designed through the research process to help us feel at peace in our own company and achieve the state of solitude.","context_research":"Aloneness can be perceived differently by our brain: we can feel loneliness or solitude. <br><br>\r\n\r\nLoneliness makes us feel “out in the cold”, marked by a sense of estrangement and, an awareness of excess aloneness. It becomes a mental health issue when we can’t break off of the negative thoughts, sensations, and behaviors. \r\n<br><br>\r\nTo transform the feeling of loneliness to solitude, one needs to know the importance of being able to feel at peace in one own company. <br><br>\r\n\r\nHuman senses play a big role in how we perceive and experience the world. Of all our senses, our sense of smell can be one of the strongest senses. The smell instantly triggers such strong memories and emotions. Smell is also better than images at inducing the feeling of “being brought back in time”.\r\n<br><br>\r\nBy integrating the sense of smell into Solus devices, human perception is taken to a higher level and enhances the way we interact with the world. Solus aims to open a new exploration into how people use underused senses to control perception by using everyday technology.","thumbnail_image":{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/Thumbnail-1-1024x576.jpg","title":"Solus Thumbnail","alt":"Solus Thumbnail","caption":"Solus Thumbnail"},"headshot_image":{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/Vidia-768x432-1.jpg","title":"Vidia-768x432","alt":"vidia headshot","caption":""},"slide_show":[{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/Solus-1024x683.jpg","title":"Solus","alt":"Solus","caption":"Solus"},{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/Scent-Clock-1024x683.jpg","title":"Scent Clock","alt":"Scent Clock","caption":"Scent Clock"},{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/Scent-Notification-1024x683.jpg","title":"Scent Notification","alt":"Scent Notification","caption":"Scent Notification"},{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/Scent-Speaker-1024x683.jpg","title":"Scent Speaker","alt":"Scent Speaker","caption":"Scent Speaker"}],"tags":[{"name":"Design","slug":"design"},{"name":"IOT","slug":"iot"},{"name":"Memory","slug":"memory"},{"name":"Product Design","slug":"product-design"},{"name":"UX","slug":"ux"}],"video_presentation_url":"https://vimeo.com/336827139","video_documentation_url":"https://vimeo.com/331408715"},{"student_id":89,"student_name":"Wang Lu (dk)","student_slug":"wang-lu-(dk)","advisor_name":"Gregory Shakar","title":"The Invader, an immersive opera with multi-channel speaker system","thesis_statement":"The invader, is a non-traditional immersive opera experience about the procedure of manipulation between human and machine.  Audiences will be surrounded by multi-channel speaker system and experience the storytelling purely through the live performed sound and one screen which one of the performer will be remotely projected.  \r\n \r\n","abstract":"Merleau Ponty ’s book, Perception of Phenomenology  inspires me to think about the question on how to create a sound experience which can extend our auditory perception through music and storytelling extensively. <br><br>\r\n\r\nFor seeking the answer to this question, I started to develop a series of live performance project with immersive sound experience equipped with live-controlled multi-channel speaker system since the algorithm composition course and interactive music course I took in 2017.\r\n<br><br>\r\nThe Invader, which is my newest piece on this live-performance series and also, my thesis project. \r\n                                                          <br><br>\r\nThis project is based on the intention of creating an illusionary acoustic experience, which calls for the formation of horizon been built through soundscape and audiences’ unconsciously perceptions. To achieve this effect, I created in real time soundscape through the multi-channel speaker control system with live sound reactive visual. \r\n<br><br>\r\nFour sound layers(ingredients) are included and controlled through the whole performance. They are real-time voice recording, live processed sound signal, synthesized sound and studio recorded music materials.  <br><br>\r\n\r\nOn this project, the sound is used to tell the story.  I will use sound to express the procedure of how human and machine are anxiously invading each other under modern society context. \r\n\r\n","context_research":"Conceptually I'm inspired by the study of the phenomenology of sound, and the concept on considering sound or music element as object and build or observe the invisible bridge between these specific object and the corresponding perception of human. <br><br>\r\n\r\nTo achieve to build the bridge, I researched early 50s-90s avant-garde musicology forms and music materials been used for performance and compositions. And later on how the computer and its algorithm engage in creating different music materials and triggered a new approach to music composition. <br><br>\r\n\r\nFor the technical research, I've been experimenting with Spat, a software suite for spatialization of sound signals in real-time intended for musical creation, postproduction, and live performances made by IRCAM (Institut de Recherche et Coordination Acoustique/Musique). To help me to build my own controlling max patch in better shape.\r\n","thumbnail_image":{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/Screen-Shot-2019-04-19-at-2.58.40-PM-1024x576.png","title":"Screen Shot 2019-04-19 at 2.58.40 PM","alt":"11111","caption":""},"headshot_image":{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/IMG_0967-1-768x432-1.jpg","title":"IMG_0967-1-768x432","alt":"lu headshot","caption":""},"slide_show":[{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/IMG_7264-1024x744.png","title":"IMG_7264","alt":"3","caption":""},{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/IMG_7220-1024x576.png","title":"IMG_7220","alt":"2","caption":""},{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/IMG_7536-1024x687.png","title":"IMG_7536","alt":"4","caption":""},{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/DSC02447-1024x683.jpg","title":"DSC02447","alt":"1","caption":""},{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/Screen-Shot-2019-05-09-at-8.03.24-PM-1024x683.jpg","title":"Screen Shot 2019-05-09 at 8.03.24 PM","alt":"1111","caption":""}],"tags":[{"name":"Art","slug":"art"},{"name":"Experiment","slug":"experiment"},{"name":"Music","slug":"music"},{"name":"Narrative/Storytelling","slug":"narrative-storytelling"},{"name":"Performance","slug":"performance"}],"video_presentation_url":"https://vimeo.com/336826729","video_documentation_url":""},{"student_id":136,"student_name":"William F Hallett","student_slug":"william-f-hallett","advisor_name":"Adaora Udoji","title":"Axolotl: designing social blur","thesis_statement":"Axolotl: Designing Social Blur is a virtual reality installation and software design project that explores what a brutalist aesthetic for immersive social media might look like and sound like. By exploring the weird aesthetic space that floats just prior to where information is rendered totally illegible and chaotic, Axolotl seeks to push social media data towards non-human and utopian environments that have the capacity to reshape how we think about social connection.","abstract":"The principal focus of this thesis is the social. The concept of the social has risen in importance not only through the rise of corporatized social media and its rhetorical image of a worldwide social-graph, but also in scholarly criticism. Critical discussions about the post-human, the non-human, transnational flow, and even matter itself, all take up and question what it might mean for a thing to be social at all. Following a methodology that incorporates scholarly research, new media design, and artistic practice, I’ve tried to think about the social from a bit of a different perspective. <br><br>\r\n\tThe humanities have in many ways split into two meta-methods of critical scholarship: critique following the Marxist theory of historical progress and problematization following Gilles Deleuze’s theories of historical fluidity and chaos. Considering how we might use new media design to create a different image of what it means to be social, I’m interested in computational workflows that problematize social relations through chaos-inspired audiovisual aesthetics but that also retain the coherence and accessibility of a public, or commons, that resists elitism and exclusion. <br><br>\r\n\t To this end, anticipating the mass-adoption of immersive media devices such as AR and VR amongst existing social media platforms, I’ve used VR headsets and media objects scraped from participants’ real newsfeeds in order to overlay a different image of the social on top of the existing networked infrastructure. I’ve designed Axolotl to express the data from this network in a chaotic way, taking aesthetic inspiration from contemporary sculpture through artists such as Isamu Noguchi, Arakawa and Gins, and Olafur Eliasson.<br><br>\r\n\tComputationally, I’ve loosely adapted an approach engineered by Dr. Sha Xin Wei’s Media Choreography Framework (2000-) towards a workflow that drives the aesthetic modulations of 3D shapes and sounds in Unity 3d with a state-engine written in Max/MSP. The two are coordinated over CNMAT's open sound protocol (OSC). ","context_research":"","thumbnail_image":{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/brianna_whiteBox_render-768x460-1.jpg","title":"brianna_whiteBox_render-768x460","alt":"brianna whitebox render","caption":""},"headshot_image":{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/Headshot-2-768x917-1.jpg","title":"Headshot-2-768x917","alt":"william headshot","caption":""},"slide_show":[{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/TechDiagram-1024x576.png","title":"TechDiagram","alt":"tech diagram","caption":""},{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/Interaction_Diagram_02-1024x576.png","title":"Interaction_Diagram_02","alt":"interaction diagram","caption":""},{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/Interaction_Diagram_-1024x576.png","title":"Interaction_Diagram_","alt":"interaction diagram","caption":""},{"src":null,"title":"parisiQuote","alt":"WCAG violation: this image will not be displayed due to lack of alternative text.","caption":""},{"src":null,"title":"24","alt":"WCAG violation: this image will not be displayed due to lack of alternative text.","caption":""}],"tags":[{"name":"3D","slug":"3d"},{"name":"social practice","slug":"social-practice"},{"name":"VR/AR/Immersive","slug":"vr-ar-immersive"}],"video_presentation_url":"https://vimeo.com/336822002","video_documentation_url":"https://vimeo.com/329936360"},{"student_id":140,"student_name":"Xiran Yang","student_slug":"xiran-yang","advisor_name":"Nancy Hechinger","title":"Blind Date","thesis_statement":"\tMy thesis project “Blind Date” is an interactive story with game elements in the format of a phone-based website. It features a 28-year-old single Chinese woman’s struggles with enormous pressure to get married early. It is a reflection and critique of the conventions surrounding marriage in contemporary Chinese society.","abstract":"\t “Blind Date” is a storytelling project that talks about marriage in the format of a web-based interactive story. A user plays the role of a 28-year old Chinese single woman who is being pressured by her friends and family to get married. <br><br>\r\n    There are three chapters in this game. The first chapter features the protagonist’s conversation with her best friend, Lorna, about the wedding of her younger friend, Cici. Along with the conversation, Lorna encourages the protagonist to date someone and warns her about the danger of becoming a leftover woman. In chapter two, the protagonist has a WeChat talk with her mother. Marriage is brought up in this conversation. And the resistance from the protagonist to get married angers her mother and leads to a fight between them. The protagonist compromises in the end and agrees to go on blind dates with several different men. That introduces the third chapter of the game. <br><br>\r\n    In the first two chapters of the game, the user will be clicking through different buttons and graphics to follow the story. In the third chapter, the user will make some decisions before she goes on blind dates and the choices she makes will effectively change the ending of the whole story.<br><br>\r\n    The user will be able to feel the increasing level of pressure the protagonist feels as the story goes on and hopefully he or she can take some insights away after experiencing this story.","context_research":"\tI used to consider “feminism” a sophisticated term that one is able to discuss only using heavy academic quotes. It was not until I played a Chinese game called “A Gay’s Life” that I changed my mind.  “A Gay’s life” is a narrative game about homosexuality. It communicates a seemingly difficult concept well by telling a story. I realized that I can also deliver ideas on feminism by creating an engaging experience. <br><br>\r\n\tAs I am about to turn 24, I started to hear the word “marriage” much more often. My family and friends started to ask me more about whether I have a boyfriend, and what were my plans about marriage. Interestingly, I found that mine was not a unique experience but a common story shared by many Chinese women. The marriage pressure that I and my friends face have therefore made “marriage” my chosen topic. <br><br>\r\n\tTo elaborate on this topic, I did my interviews from three approaches. The first one was academic research. My major reference was Sandy To’s book China’s Leftover Women*, whose studies are mainly based on about 50 interviews with urban educated Chinese women. My second research approach was in-depth interviews with 7 urban educated women around me, who are around my age. I also did an online survey with 85 people (25 males and 60 females). Based on gender and age differences, I asked them what are the most important qualities they look for from in a spouse. <br><br>\r\n\r\n* Note: Leftover Women refer to \"Urban professional women who are over 27 years old who have high educational level, high salary, high intelligence, and attractive appearance, but also overly high expectations for marriage partners, and hence are ‘left behind’ in the marriage market\"","thumbnail_image":{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/人物卡片-19-1-1024x576.png","title":"Blind Date-Thumbnail","alt":"thumbnail for blind date","caption":""},"headshot_image":{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/IMG_8054-768x576-1.jpg","title":"IMG_8054-768x576","alt":"headshot","caption":""},"slide_show":[{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/new-1024x576.png","title":"blind date","alt":"blind date phone screens","caption":""},{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/IMG_8221-1024x576.jpg","title":"user playing my game","alt":"an image of a user using her phone to experience my app","caption":""},{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/friend-19-1024x576.png","title":"mom, protagonist and lorna","alt":"images of mom, protagonist and lorna","caption":""},{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/dates-19-1024x576.png","title":"dates","alt":"dates characters in the story","caption":""}],"tags":[{"name":"Culture","slug":"culture"},{"name":"Design","slug":"design"},{"name":"Mobile","slug":"mobile"},{"name":"Narrative/Storytelling","slug":"narrative-storytelling"},{"name":"Play/Games","slug":"play-games"}],"video_presentation_url":"https://vimeo.com/337314523","video_documentation_url":"https://youtu.be/hs0QwcYG-dk"},{"student_id":151,"student_name":"Yang Yang","student_slug":"yang-yang","advisor_name":"Gabriel Barcia-Colombo","title":"Magical Pencil","thesis_statement":"Magical Pencil is a video game telling a story about a journey of a deserter who has a magical pencil by which whatever is drawn becomes real. In the game, players can create whatever they want by hand drawing to help the character to return to his home. The game can recognize what the player is drawing, and spawn a corresponding item in the game world, with an appearance of the player's doodle, to interact with the player.\r\n","abstract":"We all remember how cool it is when we saw Neo in Matrix saying “Guns, lots of guns.” So what if we get whatever we need in a video game just as simple as that? Then the purpose of the game switches from managing to obtain the game item to figure out what item is one of the solutions.\r\n<br><br>\r\nMoreover, hand drawing recognized by the game is a huge “Wow” moment, which is powered by the magic of Machine Learning. Riding on a motorcycle that was drawing by the player is another level of mind-blowing.\r\n","context_research":"Most interactions in video games are done by pressing some buttons or by clicking some virtual buttons, while quite a few of them by gestures or other sensors. My research focuses on new game inputs since traditional game inputs are hard to satisfy what an ITP-ish game needs. \r\n<br><br>\r\nLine Rider is the first one that caught my attention, in which players can draw a slope freehandedly and the game character sleds down the slop. Next, Scribblenauts is a vocabulary based video game allowing the player to create any in-game objects they want by typing in the names of the items, hence solving game puzzles in creative ways. \r\n<br><br>\r\nThe idea of drawing in games is intriguing because of its simplicity and expressiveness. Creating whatever players want is exciting. What if I combine them, allow the player to create whatever they need by doodling, then also give the game object an appearance identical to their sketch?\r\n<br><br>\r\nFurthermore, I did more in-depth research on drawing related games, found out that at this time point, none of them is allowing players to create game objects by drawing freely. \r\n<br><br>\r\nWhen Google introduced the Quick Draw project, I was fascinated. Now, this technology will play a crucial role in my game, so the next step is researching to figure out if Doodle Classification can be integrated into my project. Luckily, Google open sourced its Quick Draw dataset, so it is possible to train an ML model. Benefited from the Kaggle community, I did it.\r\n","thumbnail_image":{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/Thumbnail-1024x576.png","title":"Thumbnail","alt":"Thumbnail-Game Scene 1","caption":""},"headshot_image":{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/yang.jpg","title":"yang","alt":"yang headshot","caption":""},"slide_show":[{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/Slides-1-1024x768.jpg","title":"Slides-1","alt":"Screenshot - game scene - 1","caption":""},{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/Slides-2-1024x768.jpg","title":"Slides-2","alt":"screenshot - game scene 1 - drawing on sketchbook","caption":""},{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/Slides-3-1024x768.jpg","title":"Slides-3","alt":"screenshot - game scene 1 - riding motorbike","caption":""},{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/Slides-4-1024x768.jpg","title":"Slides-4","alt":"screenshot - game scene 3 - in desert","caption":""},{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/Slides-5-1024x768.jpg","title":"Slides-5","alt":"screenshot - game scene 4 - another world","caption":""}],"tags":[{"name":"Art","slug":"art"},{"name":"Machine Learning","slug":"machine-learning"},{"name":"Narrative/Storytelling","slug":"narrative-storytelling"},{"name":"Play/Games","slug":"play-games"},{"name":"Product Design","slug":"product-design"}],"video_presentation_url":"https://vimeo.com/337309331","video_documentation_url":"https://vimeo.com/331466595"},{"student_id":145,"student_name":"Yeonhee Lee","student_slug":"yeonhee-lee","advisor_name":"Kathleen Stevens Wilson","title":"Design System Starter Tool with AI","thesis_statement":"The Design System Starter Tool with AI helps you sort out how to create a more robust and consistent design system for your digital product. It shares expert perspectives based on the most popular design system methodology and even frees you from tedious jobs such as collecting your existing design patterns using machine learning technology.","abstract":"A design system is a series of design components that can be reused in different combinations for various purposes. More and More digital product companies realize the importance of having a reliable and consistent design system to have a clear brand identity, make their production process more efficient and streamline their communications between their people and teams. However, creating a design system is indeed an overwhelming task especially if you already have a messy set of UI components in your product.\r\nI also had that struggling experience when I worked on a design system building project in my last job. Although there were plenty of great books and web resources about creating a design system, they were all spread out in different places and it took a long time to find and digest them. Another significant pain point during the project was collecting all design assets and UI patterns from the existing products to find out the design issues they have. <br><br>\r\nFrom this experience, I considered creating a tool that can be a starting point for design system beginners by providing the basic steps to follow and the structure of design system based on the most popular methodology, Atomic Design. Also, inspired by the fact that image classification and object detection is one of the most favorable jobs for AI, I integrated it into my idea in order to accelerate the design system building process by having the machine do the tedious work for users.","context_research":"I found several great books that explain how to create a design system. They were all written by experts in the field who have actually participated in building design systems. The list of the books is as follows:<br><br>\r\n1. Creating a Design System by UXPin<br>\r\n2. Design Systems Handbook by Marco Suarez et al<br>\r\n3. Atomic Design by Brad Frost<br><br>\r\n\r\nAfter reading these books, I decided to make my tool based on Atomic Design methodology since I learned that a lot of corporate design systems are based on it and the two other books I looked at suggested design system guides developed from Atomic Design as well. <br><br>\r\n\r\nBesides these books, I read various articles written by professionals to gather advice and tips in terms of designing visual languages and UI patterns in a design system.<br><br>\r\n\r\nI also found some products that have a similar concept to mine. CSS Stat and Stylify Me analyze your websites and show you the style properties used there. Nevertheless, I can say my idea is still different from them as they only do this by parsing CSS codes and therefore, cannot provide you the list of UI patterns.<br><br>\r\n\r\nLastly, for the AI part, I have looked for some possible solutions in the existing machine learning techniques and found that YOLO: You Only Look Once is the most suitable approach for my purpose. It detects certain objects on a given image and creates bounding boxes around the results.","thumbnail_image":{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/thumbnail-4-1024x683.jpg","title":"thumbnail","alt":"Thumbnail image for the Design System Starter Tool with AI","caption":""},"headshot_image":{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/profile-768x432-1.jpg","title":"profile-768x432","alt":"yeonhee headshot","caption":""},"slide_show":[{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/main_01-1024x576.jpg","title":"main_01","alt":"Slide show image 1 for the Design System Starter Tool with AI","caption":""},{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/main_02-1024x576.jpg","title":"main_02","alt":"Slide show image 2 for the Design System Starter Tool with AI","caption":""},{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/main_03-1024x576.jpg","title":"main_03","alt":"Slide show image 3 for the Design System Starter Tool with AI","caption":""},{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/main_04-1-1024x576.jpg","title":"main_04","alt":"Slide show image 4 for the Design System Starter Tool with AI","caption":""},{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/main_05-1024x576.jpg","title":"main_05","alt":"Slide show image 5 for the Design System Starter Tool with AI","caption":""}],"tags":[{"name":"Design","slug":"design"},{"name":"Machine Learning","slug":"machine-learning"},{"name":"UX","slug":"ux"}],"video_presentation_url":"https://vimeo.com/336836844","video_documentation_url":"https://vimeo.com/335426543"},{"student_id":147,"student_name":"Yifan Liu","student_slug":"yifan-liu","advisor_name":"Gregory Shakar","title":"The Ghost","thesis_statement":"\"The Ghost\" is an interactive video installation using holograms to create a space where the boundaries between the digital and physical worlds meet, overlap and bleed together.","abstract":"This project is an interactive video installation based on the idea of bridging over from traditional video arts to the reality and blurring the boundaries between the virtual world and the real world. It is inspired by the phenomenon of social media users frequently liking posts of daily objects that they see through filters, which are illusions that trap them easily. Out of the interest in exploring and playing with the narratives, I aim to give the users / audience some extent of control over how the information spreads on the internet by letting them hit a big “like” button and interact with the projected videos.","context_research":"There are many projection mapping artists who have worked on site-specific projects or projection mapping on specific objects. Some of those projects are interactive, which makes them even more real and engaging. I did research mainly on those interactive video pieces in order to see what people have done in the field of projection mapping so far, what they have done successfully and what they have not, how people respond to them and what is possible to be brought further. I see ideas in those projects which can be reiterated and developed with totally different approach.\r\nPart of the concept also derived from the technique I use called “pepper’s ghost”, which is a technique used to create illusions in reality that can be seen with people’s own eyes. Because the illusions that people see on social media are always affecting them while they are not always aware, they are often “haunted” by those illusions. The interconnection between the concept and the technique has proved the necessity of leveraging such technique to achieve the desired effects.","thumbnail_image":{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/cans2-1024x576.jpg","title":"can 2","alt":"can 2","caption":""},"headshot_image":{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/Headshot-1-768x512-1.jpg","title":"Headshot-1-768x512","alt":"yifan headshot","caption":""},"slide_show":[{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/Image1-2-1024x576.jpg","title":"Image1","alt":"Image1","caption":""},{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/Image2-1024x576.jpg","title":"Image2","alt":"Image2","caption":""},{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/cans3-1024x576.jpg","title":"_cans3","alt":"_cans3","caption":""},{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/cans4-1024x576.jpg","title":"_cans4","alt":"_cans4","caption":""},{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/cans5-1024x576.jpg","title":"_cans5","alt":"cans5","caption":""}],"tags":[{"name":"3D","slug":"3d"},{"name":"Art","slug":"art"},{"name":"Hologram","slug":"hologram"},{"name":"Installation","slug":"installation"}],"video_presentation_url":"https://vimeo.com/336827331","video_documentation_url":"https://vimeo.com/335291167"},{"student_id":148,"student_name":"Yiyao Nie","student_slug":"yiyao-nie","advisor_name":"Nancy Hechinger","title":"Life In A Nutshell","thesis_statement":"Chinese characters (language system) evolved in sync with Chinese people’s character and culture. This piece has two parts, one is a series of sculptures, and one is an interactive installation. The 13 sculptures portray human beings in 12 stages of life as a cycle. The installation invites viewers to become part of the language to experience 12 stages of life and understand the root of the written characters and Chinese philosophy about life.","abstract":"The most ancient characters/pictographs (more than 3600 years old), the Shang oracles, were carved onto tortoise shells and other animal bones. I chose 12 very elemental oracle bones all of which were derived from the basic character for “human”. I aimed to show the symbiotic relationship of language, human beings, and nature in the evolution of Chinese written language and Chinese culture. These 12 characters tell a story, poetically, of the cycle of life. In each one, there is the character for  ‘human’. A viewer will be asked to become part of all the characters. They will strive to mimic the character with their body and hold the posture. After keeping the posture for a few seconds, the story of that character will be revealed on the screen and they will become part of the character. Viewers can truly engage in the story to experience the stage of life the character conveys by interacting with the environment and the other virtual character in the story as an important character for viewers in their life, for example, families, lovers, friends and etc..\r\n<br><br>\r\nIn this project, I hope to convey to non-Chinese and also Chinese speakers something of the richness of Chinese 5000 years of culture and written language. I think different culture actually brings people together. I start up something very specific to my own culture, but it ends up something for human as a big community.\r\n<br><br>\r\nI’m fascinated by Chinese characters. As a graphic designer and programmer, I am also developing a toolkit for people who speak and write Chinese to facilitate working with new font and motion with characters. ","context_research":"Chinese characters have evolved over the long history of China. In this system, Chinese characters are formed as a pictogram and exhibit great potential for the graphical redesign. \r\n<br><br>\r\nThey are not only purely functional–for written communication– but they are also regarded as an art form and as a representation of Chinese culture. It’s very interesting to see that in each dynasty, artists used different tools and shapes to create Chinese characters, from the very first oracle bones carved on tortoise shells and animal bones to calligraphy written on paper and now to fonts typed generated in computer. They portray our life, our character, our origins, philosophical underpinnings, and history.\r\n<br><br>\r\nHowever, the function of Chinese characters have changed in the river of Chinese history; the origins of many characters have been forgotten.<br><br>\r\n \r\nThe Shang oracle bones are version 1.0 of Chinese characters. It portrays how the most ancient Chinese people see our world, our nature, our life and ourselves and transform them into drawings and then into the first written language of Chinese characters.\r\n<br><br>\r\nBy learning the Shang oracle bones, I hope, and I hope viewers, will understand the ancient people’s perspectives about major topics on nature, world, and human: where do we come from, where are we going, and how to live a life.<br><br>\r\n\r\nI researched the meaning of many pictograms(oracle bones) and finally chose 12 of them which were derived from the basic character for “human”  and represented the cycle of life.\r\n<br><br>\r\nHere are some similar projects:<br>\r\nhttps://tinganho.info/Type-Waterfall<br>\r\nhttps://tinganho.info/Motion-Type-Project<br>\r\nhttps://vimeo.com/89622753<br>\r\nhttp://t-h-e-s-p-a-c-e.com/typeface/<br>\r\nhttp://www.xubing.com/cn/work/details/206?year=1991&amp;type=year\r\n<br><br>\r\nFrom these projects, I conclude that Chinese characters really have great graphics potential to deliver meaning, evoke emotion and create aesthetics.\r\n","thumbnail_image":{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/sky-1024x575.png","title":"sky","alt":"2","caption":""},"headshot_image":{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/WechatIMG512-768x432-1.jpg","title":"WechatIMG512-768x432","alt":"yiyao headshot","caption":""},"slide_show":[{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/Screen-Shot-2019-05-10-at-3.25.52-AM-1-1024x577.png","title":"Screen Shot 2019-05-10 at 3.25.52 AM 1","alt":"213","caption":""},{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/Screen-Shot-2019-05-10-at-3.05.21-AM-1024x575.png","title":"Screen Shot 2019-05-10 at 3.05.21 AM","alt":"3","caption":""},{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/Screen-Shot-2019-05-10-at-4.49.56-AM-1024x578.png","title":"Screen Shot 2019-05-10 at 4.49.56 AM","alt":"4","caption":""},{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/Screen-Shot-2019-05-10-at-3.13.16-AM-1024x584.png","title":"Screen Shot 2019-05-10 at 3.13.16 AM","alt":"5","caption":""},{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/Screen-Shot-2019-05-10-at-3.26.34-AM-1024x582.png","title":"Screen Shot 2019-05-10 at 3.26.34 AM","alt":"6","caption":""}],"tags":[{"name":"3D","slug":"3d"},{"name":"Animation","slug":"animation"},{"name":"Art","slug":"art"},{"name":"Culture","slug":"culture"},{"name":"Design","slug":"design"},{"name":"Experiment","slug":"experiment"},{"name":"History","slug":"history"},{"name":"Identity","slug":"identity"},{"name":"Installation","slug":"installation"},{"name":"Machine Learning","slug":"machine-learning"},{"name":"Narrative/Storytelling","slug":"narrative-storytelling"},{"name":"Projection Mapping","slug":"projection-mapping"},{"name":"Sculpture","slug":"sculpture"}],"video_presentation_url":"https://vimeo.com/337314577","video_documentation_url":""},{"student_id":146,"student_name":"Youjin Chung","student_slug":"youjin-chung","advisor_name":"Gregory Shakar","title":"The Tree of Babel","thesis_statement":"This project is a machine learning research project to find a way to analyze graph representations of interactive narrative structure and generate new narrative structure graphs using ML models.","abstract":"his project is a research journey that finding a way to understand, analyze, and generate graph representation of the interactive narrative structure. There is a field of machine learning implements on graphs, but mostly for networks like friendship from Facebook or epidemic studies not with the narrative flow.<br><br>\r\nInteractive media such as video game, interactive film, and ergodic literature have a non-linear narrative structure, which is the critical feature to makes them original genre. The structure of those genres has interesting patterns:  branching, clustering, redirection. The goal of this project is research on how to analyze the pre-existing interactive works using graph theory, and generate new patterns for new pieces.  The project scraped the database of manually analyzed graphs from Choose Your Own Adventure gamebooks. By formatting the narrative graphs to featured matrixes, K-means/Spectral/Agglomerative/Mean Shift clustering can categorize them to distinct patterns. After they cluster database, it is possible to generate similar matrixes of categorized patterns using autoencoder and visualize them for a web app deployment. This project also used text samples to fill nodes narratives of the graphs. By extracting entities of the text and information extraction of Natural Language Processing, the project fills word in the narrative structure. The next step of this project will be how to extract world status out of the full text and vectorize their relationship.","context_research":"Allison Parrish: Data for narrative structure and graph library, vector embedding for python.<br>\r\nGene Kogan: machine learning scheme of graph data for clustering and generation.<br>\r\nSam Kabo Ashwell: the theoretical approach to analyzing the narrative structure of interactive video games. Standard Patterns in Choice-Based Games.<br>\r\nMark O. Riedl: Beyond Adversarial: The Case for Game AI as Storytelling), Interactive Narrative: An Intelligent Systems Approach, PersonalizedInteractive Narratives via SequentialRecommendation of Plot Points.<br>\r\nGensim: Natual Language Processing library for Python. This is used for text summarization and word embedding using fastText.<br>\r\nNetworkX: Python package for the creation, manipulation, and study of the structure, dynamics, and functions of complex networks. I used them for general graph/network theory and implementation examples. This is the major part of the visualization.<br>\r\nScikit-learn: used for K-means clustering and referred for the implementation of other databases, such as images and text data for clustering.<br>\r\nGraph2Vec: Extraction of a featured matrix from the whole graph dataset.<br>\r\nPytorch geometric: Graph generation using autoencoder.\r\nTwine: Writing/Graph tool for nonlinear, interactive storytelling. I learned the basic structure of how writers plan interactive nonlinear narrative and examples. It inspired me to make a visualization of the data and interactivity for users.<br>\r\nTransverse Reading Gallery: The database of this project. They have manually analyzed graphs of old CYOA books, contains symbolized structure, graph, text files of log and contents, .gv .tgf formatted graph files.","thumbnail_image":{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/projectdiagram-1024x576.jpg","title":"Project diagram","alt":"Project diagram","caption":"the approaches of research as branching diagram"},"headshot_image":{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/youjin-768x432-1.jpg","title":"youjin-768x432","alt":"youjin headshot","caption":""},"slide_show":[{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/slide1-1-1024x576.jpg","title":"raw data to featured matrix","alt":"first step","caption":""},{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/slide2-3-1024x576.jpg","title":"clustering","alt":"clustering","caption":""},{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/slide3-4-1024x576.jpg","title":"graph generation and visualization","alt":"graph generation and visualization","caption":""},{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/demo-1024x576.jpg","title":"demo","alt":"project demo image","caption":""}],"tags":[{"name":"Data","slug":"data"},{"name":"Experiment","slug":"experiment"},{"name":"Machine Learning","slug":"machine-learning"},{"name":"Networks","slug":"networks"},{"name":"Science","slug":"science"}],"video_presentation_url":"https://vimeo.com/336827253","video_documentation_url":""},{"student_id":144,"student_name":"Yuhao Ko","student_slug":"yuhao-ko","advisor_name":"Stefani Bardin","title":"LifeShare","thesis_statement":"I am making an interactive environment that allows young people in Taiwan to share stories about their depression or anxiety in order to combat stigmas about mental health.","abstract":"LifeShare is an interactive application that creates a safe Augmented Reality environment where people experiencing depression or anxiety can both get help and also help others in Taiwan. For people who are depressed and anxious, this is a place that people can share their experience anonymously. By telling stories, and listening to other people's stories, individuals can develop a support system. This can alleviate the feeling of loneliness. After all, sometimes talking changes everything.\r\n","context_research":"World Health Organization(WHO) shows that Depression is a common illness worldwide, one of the top three contributor to death, with more than 300 million people being affected. However, TAIPEI (Taiwan News) - A recent study indicates only 20 percent of Taiwanese people with depression seek help, while one third of those seeking help give up treatment after their first doctor's visit. The reasons can be attributed to mental illness denial, shying away from treatment for depression, or don't know where to start when seeking help. To be more detailed, in Taiwanese culture, without proper education, depression is considered “unspeakable” or “weak”, or something to “be ashamed of.” As a result, depression has been stigmatized in Taiwan. Hence, as a creative technologist, I want to create an environment as catharsis to help young generation of people in Taiwan be willing to share their experience and destigmatize depression with recent technology.","thumbnail_image":{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/Thumbnail_img-1024x576.png","title":"Thumbnail_img","alt":"LifeShare","caption":""},"headshot_image":{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/selfPhoto-768x432-1.png","title":"selfPhoto-768x432","alt":"yuhao headshot","caption":""},"slide_show":[{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/Slide_img1-1-1024x683.png","title":"Slide_img1","alt":"render_pic","caption":""},{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/Slide_img3-1024x683.png","title":"Slide_img3","alt":"storyboard","caption":""},{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/Screen-Shot-2019-05-10-at-2.23.53-AM-1024x683.png","title":"Screen Shot 2019-05-10 at 2.23.53 AM","alt":"usr_interface","caption":""},{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/Screen-Shot-2019-05-10-at-2.24.11-AM-1024x683.png","title":"Screen Shot 2019-05-10 at 2.24.11 AM","alt":"ar_scene","caption":""},{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/Screen-Shot-2019-05-10-at-2.24.44-AM-1024x683.png","title":"Screen Shot 2019-05-10 at 2.24.44 AM","alt":"arkit","caption":""}],"tags":[{"name":"3D","slug":"3d"},{"name":"Art","slug":"art"},{"name":"Culture","slug":"culture"},{"name":"Mobile","slug":"mobile"},{"name":"VR/AR/Immersive","slug":"vr-ar-immersive"}],"video_presentation_url":"https://vimeo.com/336822151","video_documentation_url":"https://vimeo.com/335345212"},{"student_id":153,"student_name":"Zahra Khosravi","student_slug":"zahra-khosravi","advisor_name":"Adaora Udoji","title":"Neural Painting","thesis_statement":"I focused on using machine learning techniques in creating art. To be more specific, I used style transfer technique to apply the style of my art to other images. I created an interactive webpage to access the model that I trained on my style in the browser. I was inspired by creative projects that used machine learning as a medium and emphasized a sense of human touch. ","abstract":"I used style transfer to apply the style of my art to other images. This was a two step process. First, I trained a model based on my drawing and then I used my style to recompose images in the style of my artwork. <br><br>\r\nThe style image that is used for the training process has to have certain characteristics. It needs to have very clear and repetitive patterns. The model is trained during a complex process that includes using a GPU on HPC services. I made the model accessible in the browser using Ml5.js library. I use the trained model on different input images. The model applies my style to the input images and outputs (generates) art. I repeated the whole process a number of times while I was changing different parameters in the code or training data set to improve the results. The decisions that I make for creating and picking the style image and input image are based on my personal experience as an illustrator. So far, I worked with famous artworks.The list of current input images is available on the website. I am interested in applying this model to works by my favorite artists. My target audience is an artist who is interested in using machine learning techniques to create art and wants to experiment with patterns and styles.","context_research":"I became familiar with applications of machine learning for creativity and art in Neural Aesthetic (ITP Fall 2018), Nature of Code (ITP Spring 2018) and Artificial Autonomous Artist (ITP Spring 2019) courses. In machine learning techniques we use the past trends from data samples to predict the future. A simple example of using these techniques is when in Analytical Chemistry, we use known parameters of a number of samples to draw a line and use that line to predicts the values of other samples. <br><br>\r\nI was exposed to creative projects that used machine learning techniques and data sets to create art. I was inspired by \"The Fall of House of Asher\", a project by Anna Ridler. She recreated a movie based on her style of paintings as if she painted it. I was fascinated by the idea of seeing myself paint my favorite movies, animations, and illustrations. I think creating images (animations, videos, illustrations, etc ) using a neural network that is trained on drawings and paintings adds a sense of human touch to the process. <br><br>\r\nDuring the process, I started by selecting patterns that were suitable to be used as the style image in the training process among my works. Style image has to have certain characteristics. For example, it needs to have very clear and repetitive patterns. I found instructions on how to train my model on Ml5.js website and run the process locally on my device before transferring the project to a HPC service. I conducted research on how to make the project work on NYU HPC service. I trained several iterations to find the right settings for the project. <br><br>\r\nI also worked on using Text-to-Speech APIs that are developed using machine learning techniques. <br><br>\r\nAs a side project, I researched different Cloud Text-to-Speech API and how to use it to create a text-to-speech feature. I created a prototype for a text to speech feature that takes text article input from a few news  and lifestyle websites and outputs an mp3 files for each article. This feature is for users who are visually impaired or prefer to listen to articles and text presented on a website. ","thumbnail_image":{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/Untitled-3.001-1024x576.jpeg","title":"Girl with a pearl earring recreated using a machine learning model","alt":"Girl with a pearl earring recreated using a machine learning model","caption":"Girl with a pearl earring recreated using a machine learning model"},"headshot_image":{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/default.png","title":"default","alt":"default","caption":""},"slide_show":[{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/girl.002-1024x576.jpeg","title":"Girl with pearl earring recreated using a machine learning model","alt":"Girl with pearl earring recreated using a machine learning model","caption":"Output Image of Machine Learning Style Transfer Model I trained on hand-printed textile"},{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/Untitled.001-1-1024x576.jpeg","title":"The Starry Night in Hand-Printed Textile Style","alt":"The Starry Night in Hand-Printed Textile Style","caption":"The Starry Night recreated using Machine Learning model trained on Persian Textile"},{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/images.004-1024x576.jpeg","title":"Sunflowers recreated using a machine learning model","alt":"Sunflowers recreated using a machine learning model","caption":"Sunflowers recreated using a machine learning model"},{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/images.005-1024x576.jpeg","title":"The Starry Night recreated using a machine learning model","alt":"The Starry Night recreated using a machine learning model","caption":"The Starry Night recreated using a machine learning model"},{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/images.003-1024x576.jpeg","title":"Mona Lisa recreated using a machine learning model","alt":"Mona Lisa recreated using a machine learning model","caption":"Mona Lisa recreated using a machine learning model"}],"tags":[{"name":"Accessibility","slug":"accessibility"},{"name":"Machine Learning","slug":"machine-learning"}],"video_presentation_url":"https://vimeo.com/336822189","video_documentation_url":"https://vimeo.com/331475890"},{"student_id":154,"student_name":"Zohreh Zadbood","student_slug":"zohreh-zadbood","advisor_name":"Kathleen M Sullivan","title":"Who is RIGHT?","thesis_statement":"I have designed an experiment that aims at helping individuals to better think about other people's feeling and thoughts using interactive 360 videos. In fact, I want to help audience thinks about answering the question \"Who is right?\" during her exploration of my project. The user will acquire different perceptions about one specific situation which I designed in my story and  she can find out how hard it is to put herself/himself  in someone else’s shoes? and answering the main question. \r\n","abstract":"The project is an interactive 360/VR art piece. My objective in this project is to design an experiment that aims at helping individuals to think more about other people’s feeling and thoughts. Not only does it help people experience other people’s thoughts, but also also it gets them to think about the reasons which make people's perceptions different. The thesis takes a multidisciplinary approach to contribute to the research on human mind by combining concepts from psychology, communication, and interactive storytelling. From psychology, the top-down and bottom-up approaches are being used for getting the project message across. These two strategies of information processing and knowledge ordering, widely used in various scientific and humanistic research, are utilized in this project. My main question is ”Who is right?”. The user will acquire different perceptions about one specific situation which I designed in my story, which is about people’s romantic relationships. I shot some videos based on my story and the user will put on the headset and will see two scene in two versions. So she will watch part of four videos due to her interactions. \r\n","context_research":"My researches area was a broad one includes several fields.<br><br>\r\n\r\n1. Read about different theories of mind to find out the closest one to my idea / VR empathy <br>\r\n2. Read about the psychological aspects of understanding people’s thoughts and feelings<br>\r\n3. Search about different kinds of media as a tool for presenting my idea <br>\r\n4. Search about the possible interactions <br>\r\n5. Search about the 360 videos and VR capabilities<br>\r\n6. Search about the technical aspects<br>\r\n7. Find cast, crew and location for shooting<br>\r\n<br>\r\nIn my project I got help from different references. Here you can find a list of my references.<br><br>\r\n\r\n1.Interviews<br><br>\r\n- Have an interview with 10 young men and 5 young women of my friends about the story that I sent to them<br>\r\n- Have several appointment with Dr. Asieh Zadbood as a doctor, psychologist and neuroscientist.\r\n<br><br>\r\n2.Books<br><br>\r\n-The psychology of love(Sigmund Freud)<br>\r\n-The prisoners of our thoughts(Alex Pattakos)<br>\r\n-What everybody is saying(Joe Navarro)<br>\r\n-The house that we grew up in( Lisa Jewell)<br>\r\n-Think and grow rich(Napoleon Hill)\r\n<br><br>\r\n3.Articles<br><br>\r\n-How love and lust change people’s perception of relationship partners<br>\r\n-Seeing love, or seeing lust: How people interpret ambiguous romantic situations\r\n(Journal of Experimental Social Psychology)\r\n<br><br>\r\nThe Influence of Media on Young People’s Attitudes towards their Love and Beliefs on Romantic and Realistic Relationships\r\n(International Journal of Academic Research in Psychology)\r\n<br><br>\r\n4.ITP faculties<br><br>\r\n-Heidi Brant<br>\r\n-Nick Hubbard<br>\r\n-Marianne Petit <br>\r\n-Gabe Barcia-Colombo <br>\r\n-Marina Zurkow<br>\r\n-Matthew Niederhauser<br>\r\n-Francesca Mirabella<br>\r\n<br><br>\r\n5.Graduated ITPers:<br><br>\r\n-Richard Lapham<br>\r\n-Dominic Barret<br>\r\n-Nouf Aljowaysir<br>\r\n-Marco Fguarino<br>\r\n-Christina Hall<br>\r\n<br>\r\n6.Experts in Film department :<br><br>\r\n-Spike Lee<br>\r\n-Alex Raspa<br>\r\n-Fritz Gerald<br>\r\n-Damien Panitz<br>\r\n-Tarek Gamal Eldin<br>","thumbnail_image":{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/poster-copy-1024x779.jpg","title":"poster copy","alt":"project poster","caption":""},"headshot_image":{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/zzprofilephoto-0-768x512-1.jpg","title":"zzprofilephoto-0-768x512","alt":"zohreh headshot","caption":""},"slide_show":[{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/Screenshot_20190421-212718_20190421213309115.jpg","title":"Screenshot_20190421-212718_20190421213309115","alt":"--","caption":""},{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/Screenshot_20190421-212737_20190421213418714.jpg","title":"Screenshot_20190421-212737_20190421213418714","alt":"--","caption":""},{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/Screenshot_20190421-212802_20190421213459059.jpg","title":"Screenshot_20190421-212802_20190421213459059","alt":"--","caption":""},{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/PSX_20190421_232735.jpg","title":"PSX_20190421_232735","alt":"--","caption":""},{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/PSX_20190421_232947.jpg","title":"PSX_20190421_232947","alt":"--","caption":""}],"tags":[{"name":"Art","slug":"art"},{"name":"Experiment","slug":"experiment"},{"name":"Narrative/Storytelling","slug":"narrative-storytelling"},{"name":"VR/AR/Immersive","slug":"vr-ar-immersive"}],"video_presentation_url":"https://vimeo.com/336827387","video_documentation_url":"https://www.youtube.com/watch?v=4aYiNOXF6go"}]