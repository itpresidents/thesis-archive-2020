{"student_id":"150","student_name":"Ella Chung","student_slug":"ella-chung","advisor_name":"Gabriel Barcia-Colombo","title":"Breathe We Live","thesis_statement":"Breathe We Live is an interactive meditation experience that awakens the reflection of the human relationship with nature through breathing.","abstract":"Breathe We Live is an interactive installation that presents the invisible connection between human and natural environment through shedding lights on the activity of breathing. The invisible exchange of oxygen is brought into the projection of the natural world and human connection. The breathing sensors track the user in real time of their breathing frequency, and the interaction with the plants will help the user to meditate and slow down their breathing. The goal of this installation is to encourage us to rethink our connection and responsibility towards nature.\r\n<br><br>\r\nThe installation invites people to pay close attention to their body through a session of breathing meditation practice. I created a meditative space, with embedded interactive components, that enables intimate experience between viewers and the natural environment. Only one or two people can enter the space at a time. The installation uses human breath as an input to produce corresponding visuals in real-time. A Kinect camera mounted inside the space will detect the user’s movement to provide a false feedback loop for breathing, when the user is moving and breathing too fast, the visual and music will slow down to give the user feedback to breathe slower. \r\n<br><br>\r\nAccording to my research about mediation, walking through nature is one of the best ways to relieve stress. I wanted to create a meditative space for people to understand their breathing activity and their close relationship to nature. I hope the experience helps the users to reflect their relationship with the current state of nature. \r\n","context_research":"Trees are made of human breath. The tree is recording a history of us. The tree is us. When people work with trees, they will carefully consider every cut and work with each individual tree’s unique shape and growth pattern. Can we tell a tree contains our breath patterns and human history? This makes me think deeper about the relationship between human breath and nature.\r\n<br><br>\r\nOne of the projects that I was inspired by is Vicious Circular Breathing, an art installation by Rafael Lozano-Hemmer. Users breathe the air that was previously breathed by participants who previously visited the same space. The installation consists of a glass room filled with carbon dioxide and oxygen sensors and paper bags hanging from respiration tubes that visualizes the viewers’ breathing patterns. The demonstration of breathing makes the interactive process more dynamic than only showing the results of processed data. \r\n<br><br>\r\nMy installation creates an environment for communal meditation experience between human and nature. The viewers are invited to blow their breath into the sensor while meditating and listening to the sound of nature. The plants within the visual system react according to the participant’s breathing cycle. \r\n<br><br>\r\nDuring user testing sessions I conducted over the design process, participants found the meditation experience to be soothing, but they wanted the space to be darker and more immersive. Some participants wanted physical interaction components along with the visuals. After the user testing, I made the following changes in my design. I projected the visuals closer to the plants and the human to show a clearer connection between the two. I found that the placement of the microphone in my previous design was too far from the users and the users had to breathe harder than they normally do. To fix the problem, I replaced the microphone with wind sensors, which is more sensitive, and placed them right next to the plants. \r\n","technical_details":"The project is made of custom software built with Touchdesigner, a sensor system that detects breathing, a Kinect camera, and a projector. A viewer’s breath data collected by the sensor system is sent to the software built with Touchdesigner to create corresponding visuals in real-time. The viewer’s movement is detected by a Kinect camera and influences the visual system. The visuals are projected onto the floor to create an immersive experience.","further_reading":"","tags":[{"name":"Design","slug":"design"},{"name":"Experiment","slug":"experiment"},{"name":"Meditation","slug":"meditation"},{"name":"Projection Mapping","slug":"projection-mapping"},{"name":"VR/AR/Immersive","slug":"vr-ar-immersive"}],"video_presentation_url":"https://vimeo.com/337309277","video_documentation_url":"https://vimeo.com/335274809","project_url":"http://www.ellachung.com/breathwelive","headshot":{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/My-Photo-768x432-1.jpg","title":"My-Photo-768x432","alt":"ella headshot","caption":""},"thumbnail_image":{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/Thumbnail-Image-2-1024x576.jpg","title":"Thumbnail Image","alt":"Breath We Live Installation Thumbnail Image","caption":""},"slide_show":[{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/Main-Image-1-1-1024x576.jpg","title":"Main Image 1","alt":"Breath We Live Installation Main Image","caption":""},{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/Main-Image-1-copy-1024x576.jpg","title":"Main Image 2","alt":"Breath We Live Installation Main Image","caption":""},{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/Main-Image-1-copy-2-1-1024x576.jpg","title":"Main Image 1 copy 2","alt":"Breath We Live Installation Thumbnail Image","caption":""},{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/Main-Image-1-copy-2-2-1024x576.jpg","title":"Main Image 1 copy 2","alt":"Breath We Live Installation Thumbnail Image","caption":""}]}