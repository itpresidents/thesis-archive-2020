{"student_id":"105","student_name":"Mengzhen Xiao","student_slug":"mengzhen-xiao","advisor_name":"Adaora Udoji","title":"IntoAR: Intuitive AR Notifications Design System","thesis_statement":"Whatâ€™s the next generation of AR interfaces? How can we design immersive AR notifications other than the traditional overlaid textual representations of information? IntoAR is a design system for designing intuitive notifications in augmented reality. It consists of a series of experiments aimed at demonstrating how to create universal and non-text based AR notifications by applying physical affordances.","abstract":"Mobile App notifications, notes, memos - our lives are constantly overloaded with them to the point that we get used to them. To reduce unnecessary notifications and provide effective notice, AR technology is a speculative solution. Through augmented reality, we can both enhance and simplify our everyday experiences, through intentional design of notifications. However, most AR notifications are text-based. Text-based notifications are hard to read and in some cases, it needs to support multiple languages. So, how can we design immersive AR notifications other than the traditional overlaid textual representations of information? How can we create universal and non-text based AR notifications? \r\n\r\nIntoAR is a design system for designing intuitive AR notifications. By constructing and testing a series of AR design prototypes, the system demonstrates how to create universal and non-text based AR notifications by applying physical affordances. The system consists of different categories, such as utility, capacity, temperature, navigation, and gesture. Each category lists several different ways to design AR notifications, and each option provides AR demos of both a cube example and an object application example for users to download and test on their mobile devices.","context_research":"The purpose of this study is to create a design system for designing universal and non-text based AR notifications. <br><br>\r\n\r\nAugmented reality is an emerging technology that is becoming mainstream. AR has evolved over the past years, but it still faces several challenges. Most AR notifications are text-based. Text-based notification is hard to read and in some cases, it needs to support multiple languages. As augmented reality becomes more accessible, there will be a more diverse user archetype spanning different ages, cultures, and comfortability with technology. User diversity becomes a big challenge when designing intuitive AR notifications. \r\n<br><br>\r\nOne possible way to meet the challenge is to apply the understanding of physical affordances. Physical affordances are the object's properties that show the possible actions users can take with it, thereby suggesting how they may interact with that object. Leveraging physical affordances can enable intuitive interaction through embodied knowledge. I have done research on related projects such as Shapeshift by Dixon Lo and Sublimate by MIT. \r\n<br><br>\r\nTo make a reliable design system, I conducted one-on-one user testing with several AR design prototypes and then made a quantified system for measurement and comparison. I also did research on AR design toolkits and system design guidelines such as Google Augmented Reality Design Guidelines, Apple AR human-interface-guidelines, Frog Design Toolkit, Civic Service Design Tools, and Motion Periodic Table.","technical_details":"The main technical tools for this project are 3D scanning, Vuforia Image Target, Vuforia Model Target, and Unity ARkit. For 3D scanning, I used a structure sensor with an iPad, combined with software named itSeez3D. By using Vuforia Model Target Generator, I made the 3D models as the model targets and imported them into Unity. In Unity, I created AR notification animations and exported each prototype as an AR App. To make a webpage for the design system, I used coding languages like HTML, CSS, and Javascript.","further_reading":"","tags":[{"name":"Design","slug":"design"},{"name":"Speculation","slug":"speculation"},{"name":"UX","slug":"ux"},{"name":"VR/AR/Immersive","slug":"vr-ar-immersive"}],"video_presentation_url":"https://vimeo.com/336821782","video_documentation_url":"https://vimeo.com/330364925","project_url":"https://www.mengzhenxiao.com/intuitive-ar-notifications","headshot":{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/my_photo-768x432-1.jpg","title":"my_photo-768x432","alt":"mengzhen headshot","caption":""},"thumbnail_image":{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/Thesis-Thumbnail-image-1024x576.jpg","title":"IntoAR","alt":"IntoAR","caption":""},"slide_show":[{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/thesis-mainimage-01-1024x576.jpg","title":"thesis-mainimage-01","alt":"thesis-mainimage-01","caption":""},{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/thesis-mainimage-02-1024x576.jpg","title":"thesis-mainimage-02","alt":"thesis-mainimage-02","caption":""},{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/thesis-mainimage-03-1024x576.jpg","title":"thesis-mainimage-03","alt":"thesis-mainimage-03","caption":""},{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/thesis-mainimage-05-1024x576.jpg","title":"thesis-mainimage-05","alt":"thesis-mainimage-05","caption":""}]}