{"student_id":"68","student_name":"James Huang","student_slug":"james-huang","advisor_name":"Kathleen M Sullivan","title":"Lost in Translation","thesis_statement":"How much information would loss after series of translations? What would machine interpret with series of translations? How would the interpreted result different from our expectation and cognition?","abstract":"As artificial intelligence developing, more and more people worry about machines will replace humans. Although machine learning seems to do some promising works, it still needs effort to catch up human in complicated works, especially those tasks that have no correct answers or need to be interpreted. The reason why we use machine learning is that we want a machine to come up with the results we expect. Accordingly, we feed training data as its knowledge. However, machine learning is a process of translation. Machine only gives the result based on its knowledge, it doesn't deduct like human does. Since machine interprets in its own way, it is hard to control them to have the same thought like us. Therefore, I designed an interactive experience to show that it is difficult to make a machine come up with the result as we expect. The project has a recursive process for human and machine to interpret each other’s results. Human needs to come up with a sentence to describe an image generated by machine and the machine will do multiple machine learning translations from the description from human to a sketch and then to an image in each round of process.","context_research":"The inspiration of my project is Closed Loop by Jake Elwes. It uses machine learning to do feedback loop on images and texts. Image generates texts and the texts generate another image and so on. With the concept of looping and translation, I tried to do series of translations in multiple languages on Google Translation to see how much information is lost or misinterpreted. Moreover, as to series of message passing, I started to do research on Telephone Game. Since I want to apply this concept on images, I found an online image version Telephone Game called Drawception. Moreover, Google Quick Draw gave me inspiration that sketches can be a medium on image translation.\r\n<br><br>\r\nFor the technical research, there are several machine learning models I have researched. <br>\r\n1. im2txt, a project originated from Google that can generate caption from images.<br>\r\n2. AttnGan, it can generate image from text. <br>\r\n3. Word vector, a group of related models that are used to produce word embeddings, which can help me to find out the relationships between two words. <br>\r\n4. SketchRNN, a generative model that can draw sketches.<br><br>\r\n\r\nThere are more technical projects I have researched that I eventually did not use such as Detectron, a high performance object detection model, and SketchyGAN, a model that can generate images from sketches. ","technical_details":"I make a Python server to do communications with client and machine learning models in Runway. Runway will give the results of im2txt and AttnGAN models. The server will collect the results and send them to the client. The client will send user’s input to the server and show the data received from server.","further_reading":"<p>For further reading, please visit <a href=\"http://www.jhjameshuang.com/lost-in-translation/\">Project Link</a> and <a href=\"https://github.com/pondjames007/LostInTranslation\">Github Page</a></p>\n","tags":[{"name":"Machine Learning","slug":"machine-learning"},{"name":"Play/Games","slug":"play-games"}],"video_presentation_url":"https://vimeo.com/336826469","video_documentation_url":"","project_url":"http://www.jhjameshuang.com/lost-in-translation/","headshot":{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/self-768x432-1.jpg","title":"self-768x432","alt":"james headshot","caption":""},"thumbnail_image":{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/output-10-1024x576.jpg","title":"thumbnail","alt":"thumbnail image","caption":""},"slide_show":[{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/output-4-1024x576.jpg","title":"main 1","alt":"main image 1","caption":""},{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/output-5-1024x576.jpg","title":"main2","alt":"main image 2","caption":""},{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/output-6-1024x576.jpg","title":"main 3","alt":"main image 3","caption":""},{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/output-7-1024x576.jpg","title":"main4","alt":"main image 4","caption":""},{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/main2-1-1024x683.jpg","title":"main5","alt":"main image 5","caption":""}]}