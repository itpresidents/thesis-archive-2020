{"student_id":"115","student_name":"Roxanne Kim","student_slug":"roxanne-kim","advisor_name":"Kathleen M Sullivan","title":"Future IVX (In-Vehicle Experience)","thesis_statement":"\tFuture IVX is a simulated installation of the future In-Vehicle Experience. In this installation, future automobile works as a moving space. Based on user tests and surveys, I create a user-friendly environment and observe how users interact and response. As a result, I examine how we can develop and how people accept when the age of autonomous vehicles comes.","abstract":"\tThe age of self-driving vehicles has come. For decades, the main purpose of the car was to keep me moving. But what can people do if they say the problem is solved? Personally, I am interested in cars, one of which is a fun driving experience. If all cars are fully automated, why buy a car? However, BMW's M series is for the fun driving experience. If we go in the era of autonomous driving, who will guarantee that fun. Therefore, I will research how future human-machine interaction can coexist and how automobile machinery can cooperate with people. What about the appearance of the car in the near future? There are several levels of automation, but in the next few years, the future may mainly consist of purely autonomous vehicles like the Google X auto-driving car without pedals or steering wheel. Does that mean people can do nothing? it's not like that. In terms of human-machine interaction, machines can be being in a car more fun. \t\r\n<br><br>\tLet's take a few examples. First of all, assuming a user is driving, the computer can act as a pacemaker during driving. For example, driving in the city, it improves navigation and helps the user by communicating with pedestrians and obstacles. Another example is, if this person is on the highway, to encourage fun driving experiences such as high-speed driving and gear shifting. Secondly, looking at the function as an assisting friend requires a more emotional interface. It will interact not only in cars but also in life. For example, the system will integrate with your other smart devices. In terms of the hardware side, it provides an ergonomic custom seat or sound system that uses only the frequencies that specific passengers can hear. Considering the software approach, the lighting system will be triggered by the user's emotional mood or sleep mode when he/she tired. Synchronize information without borders to listen to music that you heard right before from home. So I focus on what people can do in that personal moving space and how they respond to the autonomous car environments and interact with it.","context_research":"\tAmong the various types of prototyping, the reason why I chose a simulating installation is an exhibition - The Road Ahead: Reimagining Mobility by Cooper Hewitt. Despite there was a great exhibition, I felt a lack of car experience. Especially, there were two surveys about what people want to a future car? One tends to the approach of the vehicle culture. Although people get the self-driving car, some of them still want to own their car instead of using a taxi or transportation. The other survey was that what people want to do in your car if it’s fully autonomous. The prior feedback was about time usage or consuming. Many people want to spend ‘non-driving time’ to sleep, relax or work. Nevertheless,  it’s hard to find experience simulation. Therefore, I create a simulating installation. \r\n<br><br>\tMostly, I referred to research papers related to Autonomous Car and HMI(Human Machine Interaction). I looked through some academic papers about autonomous cars. From those papers, I got the more idea; the revolution of (autonomous) car, how it changes our life, and how much it shifts our vehicle culture. In terms of user tests, I was helped how I approached users and designed user test by Using embodied design improvisation as a design research tool by David, S. and Wendy, J.","technical_details":"\tI build an installation which contains an ergonomic screen which represented the front window of the car and the comfortable seats which offer both sitting and lying down. In terms of the controller, I create a mobile application which uses both voice control and screen-based interaction.","further_reading":"","tags":[{"name":"Car","slug":"car"},{"name":"Design","slug":"design"},{"name":"Mobile","slug":"mobile"},{"name":"UX","slug":"ux"},{"name":"VR/AR/Immersive","slug":"vr-ar-immersive"}],"video_presentation_url":"https://vimeo.com/336827088","video_documentation_url":"","project_url":"","headshot":{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/roxanne_kim_headshot_03-768x432-1.jpg","title":"roxanne_kim_headshot_03-768x432","alt":"roxanne headshot","caption":""},"thumbnail_image":{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/thumbnail-3-1024x576.png","title":"thumbnail","alt":"logo","caption":""},"slide_show":[{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/slide2-1-1024x576.jpg","title":"slide2","alt":"Installation Sketch","caption":""},{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/slide3-2-1024x576.jpg","title":"slide3","alt":"installation","caption":""},{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/side_show_imge.png","title":"side_show_imge","alt":"Mobile Application Screenshots","caption":""},{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/slide5-1-1024x576.jpg","title":"slide5","alt":"Documentation","caption":""},{"src":"https://itp.nyu.edu/thesis2019/wp-content/uploads/2019/04/side_show_image_002.png","title":"side_show_image_002","alt":"image 6","caption":""}]}