{"post_id":133,"student_id":"4","student_name":"Brandon Kader","student_slug":"brandon-kader","advisor_id":"114","advisor_name":"Adaora Udoji","advisor_slug":"aeu4","project_title":"IMVII","project_question":"I made an immersive experience without a device or VR headset.  I have tried a VR headset and felt disoriented and extremely uncomfortable.  I most definitely do not want to work in that medium.  It is important that the performer not touch things like a conductor does not play a specific instrument in an orchestra, rather directs the performance.  My experience with piano performance is that it is not very physically moving, the piano is stationary and the performer is seated at the keyboard.  There is little showmanship or stage presence.  I have felt the need to perform my music in another way.  \r\n<br />\r\n<br />\r\nI explored how to make an immersive experience - including music and visual effects - using a touch free interface for modern composers to perform room scale installations.  I used a Kinect camera to gather depth sensory data with Processing to map music and generative visuals in a system I built with Max MSP Jitter, a visual programming language that patches and connects the data to music and visual elements.  I used a triplehead2go for 3 projector display to create a room-scale visual experience and performed at NYU Steinhardt’s Recital Room.   ","short_description":"I created a system to seamlessly integrate music, visuals, and depth sensory data to perform as a conductor.  The performer moves in a space to conduct music samples and generative visuals.\r\n","further_reading":"<p>TripleHead2Go Test<br />\nhttps://youtu.be/Hp2PKCdQ2GU</p>\n<p>Visual Sample<br />\nhttps://youtu.be/WF-QcaSIIh4 </p>\n<p>Prototype<br />\nhttps://youtu.be/z348j5Fx4lE</p>\n<p>Rehearsal<br />\nhttps://youtu.be/QBv0QGsCMVg</p>\n<p>Quick &amp; Dirty Thesis Show User Test<br />\nhttps://www.youtube.com/watch?v=ZJHyRLqRVzE</p>\n<p>I am repulsed by the idea of being a dj to perform my music because it does not do the justice to my passion practice of composing and producing my musical expression.  Most of the work I put into my music occurs at a piano, keyboard and computer.  I compose for a range of sounds, melodies, percussions, rhythm and harmonies.  As the author of the music, I feel I must conduct the performance, to direct the sounds via a touch free interface.</p>\n<p>My goal is to build a system that works so I can perform a single piece.  It is unclear whether work has been done in this area.  Certainly there are works that are similar or resemble the idea in one way or another.  I am building upon skills that I have developed at ITP and am inspired to continue working and iterating on these ideas.  The nexus would be the composer being the conductor, the performer.  I am inspired to develop a way for performing my music with stage presence, movement and showmanship.   I feel that enjoying music in headphones is a fraction of what the real music experience can be.  Having an immersive experience in an installation that is the instrument packages the idea of modern music composition and performance with visuals that compliment the sound.  </p>\n<p>The limitations with the technologies are mapping the depth data from Kinect to my musical samples.  It is a prototype system that is inhibited by the workflow.  For example, I must compose my music samples in a Digital Audio Workstation, Logic Pro X, and import them to the music visual system, Max MSP/Jitter.  The depth data comes from the Kinect through a Processing Sketch that has Pixel Thresholds.  I used help from Dan Shiffman and OpenKinect, an open source tool for Processing to retrieve the depth data from Kinect.  The sketch is modified so that if the pixels reach a threshold, a number is sent to my Max system where the music samples are triggered.  </p>\n<p>It would be nice, (yet too large in scope) to design and develop a platform for easily integrating music samples with my music visual system or configure a way to compose with the system.  I write my music using a piano keyboard controller and use it to produce a song.  I would use the Immersive Music Visual Instrument Installation (IMVII) to perform the song.  </p>\n<p>The visuals are an ensemble player to the music composition and performance.  The visuals are a generative composite with a blend of video, particle systems, p5.js sketch, Adobe After Effects / Photoshop, Final Cut Pro X and JITTER.  </p>\n<p>I researched what is required for multiple projections and integrating the system with a touch free sensor.  I spoke with people who have done room scale installations and researched online various methods to accomplish these tasks.</p>\n<p>The experience involves multiple projectors to display visuals on the walls, ceiling and floor of the space.  The audience is for people who enjoy music and exploring how their movement effects the music and visuals. It will enable musicians to perform visuals with their music. It enables visual artists to have a musical accompaniment for their work. It assists dancers who wish to have music and visuals compliment their movements and bodies. The key features include a venue space, where sound and projections submerge the room. A performer steps into the space and performs the music and visuals by their movement through the space.</p>\n<p>In my quest for a space to show my project I was fortunate to schedule an evening to perform at NYU Steinhardt Education Building, Recital Room 303, 35 W. 4th Street for Wednesday, March 14th @ 7pm.  I was referred by Kimmel Center Operations to Luis Mercado who handles the scheduling of those rooms.  On March 2nd, I spoke on the phone with Luis, and he informed me that this space is completely booked after spring break.  He informed me that the room is for professors and students in their department.  So I agreed to book the room for that Wednesday of Spring Break.  We then exchanged email to confirm and go over the procedures for using the room.</p>\n<p>He was able to schedule this time for me and I gratefully obliged.  My prototype is ready and I will be able to perform something and it will give me an opportunity to get some quality documentation of my project in preparation for presentations.  I’ve asked Jenny Lim to help me with camera work.   </p>\n<p>I sent out a promotional card to invite the community.  An email was sent to the student list of ITP and I created a Facebook event invitation.  I found this opportunity to be rather awesome and met it with a radiant performance.  I immediately went into triple overtime on developing the system, mapping sounds, calibrating pixel thresholds and preparing equipment for the rehearsals and performance.    </p>\n<p>I composed music samples for the piece in the key of A Major (Omit E) with Logic Pro X:<br />\nImplemented instruments such as: Orchestra Strings, Synth Pads, Ambient Soundscapes, Oud, Guitar, Distorted Synth Lead, Bass and Rhythmic Beat. </p>\n<p>Preparations included setup of three tripods for three projectors, and another tripod for the documentation camera, Canon 5D Mk III.    </p>\n<p>The process of checking out the equipment was extensive.  Some tripods were not functioning properly, they would slouch and not stay fastened.  There were two projectors that needed recalibration or keystone adjustment.  Another two projectors needed mounting for the Manfrotto Arm Head Mount because that is the only one compatible with the wood mount piece for the bottom of the projectors and corresponding tripods without the proper mount.   Thanks to Marlon and Nitish in the ER for assistance with mounting and adjustments!</p>\n<p>I was able to check out the Roland Speaker Monitors to get louder audio for the performance.  Each speaker required its own power cable and I used 1/4″ to RCA Connector Adapters for a Y 1/8″ connection to the audio output of my laptop.</p>\n<p>For transporting the equipment I was able to fit the speakers, projectors, cables, power cords, extensions cords, and arms in the large Pelican Case.  Michael Kripchak helped with pushing the case to 35 West 4th Street Room 303.<br />\nMarlon then gave me an official NYU Memo document to carry around with me while I am moving the equipment from the ITP floor to the performance space.  To: TSOA Security Re: Removal of Gear.</p>\n<p>The show was a success and it was an inspiring evening.  I was able to perform for the duration of 7-8pm.  Because Spring Break Hours have the Equipment Room close early at 8, I had to make special arrangements with floor staff, Chetan Hasabnis to stay later so I could return the equipment after the performance.  I would have loved to stay there for at least 3 more hours to flush out all the documentation coverage and perform more music and visuals.  Considering all the circumstances and being respectful to everyone’s time and the help I received, I was thankful to all and for everything running smoothly.</p>\n<p>I was able to have others perform the instrument as well - Dominic Barrett, Michael Kripchak and Christina Elizabeth Hall.  I will be getting their feedback and interviewing them about the performance &amp; system.  Meticulous preparation for the show and planning contributed to a successful evening.  I have interviewed three attendees so far for their feedback and response to the performance.  I have another three interviews scheduled for more feedback.  </p>\n<p>I observed in the feedback responses that they would like to see another person in the conductor’s place, such as a dancer, to accentuate the direction of moving in a space for conducting the music and visual performance.  </p>\n<p>The next steps for this project are in a collaboration with Tisch MFA Dancers for a performance show on May 12th.  I am performing another show in Brooklyn on May 10th and hope to collaborate with a dancer for that show as well.   </p>\n","portfolio_icon":{"src":"https://itp.nyu.edu/thesis2018/wp-content/uploads/2018/04/IMVII-THESIS-ARCHIVE-THUMBNAIL-1.jpg","title":"IMVII THESIS ARCHIVE THUMBNAIL","alt":"IMVII","caption":"caption"},"topics":[{"name":"Installation","slug":"installation"},{"name":"Performance","slug":"performance"}],"video_presentation_url":"https://player.vimeo.com/video/270187783","video_documentation_url":"https://www.youtube.com/embed/n3DTe2TOU4Y","project_url":"https://www.brandonkader.com/thesis","description":"","featured_image":[{"src":"https://itp.nyu.edu/thesis2018/wp-content/uploads/2018/04/IMVII-THESIS-ARCHIVE-THUMBNAIL-1.jpg","title":"IMVII THESIS ARCHIVE THUMBNAIL","alt":"IMVII","caption":"caption"}],"slide_show":[{"src":"https://itp.nyu.edu/thesis2018/wp-content/uploads/2018/04/ThesisArchive1.jpg","title":"ThesisArchive1","alt":"IMVII PERFORMANCE SPACE","caption":"IMVII PERFORMANCE SPACE"},{"src":"https://itp.nyu.edu/thesis2018/wp-content/uploads/2018/04/ThesisArchive2.jpg","title":"ThesisArchive2","alt":"IMVII Performance","caption":"Project Performance"},{"src":"https://itp.nyu.edu/thesis2018/wp-content/uploads/2018/04/ThesisArchive3.jpg","title":"ThesisArchive3","alt":"IMVII Performance","caption":"Thesis Project Performance"},{"src":"https://itp.nyu.edu/thesis2018/wp-content/uploads/2018/04/ThesisArchive4.jpg","title":"ThesisArchive4","alt":"VISUALS FOR IMVII","caption":"IMVII Project VISUALS"}]}