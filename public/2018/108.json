{"post_id":97,"student_id":"108","student_name":"Rita Cheng","student_slug":"rita-cheng","advisor_id":"131","advisor_name":"Stefani Bardin","advisor_slug":"sb4840","project_title":"The Personal Panopticon","project_question":"<i>The Personal Panopticon</i> is a multimedia project exploring the Internet of Things (IoT), surveillance culture, and the aesthetics of wellness and self-help. The project is a critical look at internet-enabled care devices (e.g. the Fitbit, smart scales, Apple Health) and the politics of their usage. Using them produces metrics to try and improve your well-being, but also is an implicit agreement to data surveillance and continuous monitoring.\r\n<br />\r\n<br />\r\nThe project consists of an IoT hub called Karma. Karma will take care of and manage your life, as a vision of the dystopia in which surveillance and monitoring is taken to extremes. Karma will collect information from other devices and will nag you to meet your goals and stay connected. When you are in range, she will talk to you and care for you in person. When you are away, she will call you and remind you of your obligations. You cannot opt out of Karma—she is connected to your phone, email, and social media, so connecting to any network necessitates connecting to Karma.\r\n<br />\r\n<br />\r\nThe project also includes marketing such as the <a href=\"http://www.karma.care\">landing website found here</a> and the Indiegogo campaign. A trade show setup was designed for the quick and dirty show. In this way, I examine how technology companies sell IoT devices and look at the aesthetics of surveillance, gadgets, and wellness.","short_description":"How are IoT devices like the Fitbit aiding in our collective exploitation and surveillance? What is the future of these caretaking devices? Most importantly: how do I get a piece of this action?","further_reading":"<p><b>Background &amp; Personal Statement</b></p>\n<p>This project started with positive intentions. I thought that by looking at self-care, I'd make time to take care of myself. But my life experience in the tech industry and my work at ITP leads me to a critical attitude about technology in general, and once I started my research, it pointed to several sinister aspects of self-care. As presented by the tech industry, self-care is capitalistic, bettering yourself so you can be a better worker. The tech industry does not blink an eye at the idea of overworking yourself to create a meditation app.</p>\n<p>A more remote inspiration for this project was my mother, who passed away from cancer in September of last year. This led to two thoughts: one, that I should create a virtual mother, which led directly to the project's creation. Two, it led me to think about caretaking and the future of care: who will take care of us when we grow feeble or old?</p>\n<p>Caregiving will become increasingly important over the next few decades, with the world's older population (aged 65 or older) projected to double to 17% of the population by 2050 (NIH). This means both that there will be more older people that require care, as well as fewer young people to perform this caregiving role. Consequentially, caregiving is planned to be increasingly roboticized: in 2015, the Japanese government projected that 4 in 5 elderly Japanese will have some care provided for by robots in 2020. But such a shift in caregiving has multiple ethical conundrums embedded in it. For instance, is it humane to leave people's physical and emotional lives in the care of robots? Should we leave people in the care of large corporations like Google or Facebook? What is the surveillance inherent to robot-led caregiving, and what rights to privacy are we giving up with it?</p>\n<p><b>Project Summary</b></p>\n<p><i>The Personal Panopticon</i> aims to explore these ethical issues in a satirical but probing way. I would be creating a AI smart assistant, Karma, in the vein of an upgraded Alexa or the PARO caretaking robot. This caretaker would be inherently and intentionally simplistic: even with machine learning and other advanced technology, there is no replicating the triaging and problem solving of other human beings. Furthermore, I would like to display the data collection implicit in such a creation: voice recordings, schedules, preferences, and health information. What services currently collect these data? Do these services collect other data as well? What consideration should be given to these services that we do not currently give?</p>\n<p>The name Karma stems, clearly, from the concept of karma, a Hindu and Buddhist concept in which the sum of your actions affect the state of your current and future lives. I had wanted to choose a name that had a sense of surveillance or judgement that could not be turned off. I also liked that karma, as we understood it in the West, was represented in my experience and leveling up concepts: if you do “good,” Karma will treat you “good.”</p>\n<p>What I ultimately liked the best about this name choice, though, is a subtle theme that I’ve been researching but had not been able to include in my concept. The name Karma for this product is cultural appropriation in the same way that meditation apps appropriate that concept. It’s a complex idea that is tied to eastern faith systems that, in the West, is simplified and completely divorced from religion. Interestingly, it’s also, in the West, a name that seems feminine, despite being a male name in countries like Tibet where karma is part of the religion. Karma, my AI, will also be female, as are most smart assistants (Siri, Alexa, etc.) The name continues in this tradition of making things feminine that have no reason to be feminine.</p>\n<p>The intended audience for this project is anyone who does not consider privacy in IoT devices, but particularly those in the tech industry that create these devices without thought to the holistic effect they may have on their users. The hope is that the audience will be more cognizant of the potential harms before signing up for, or creating, more of these devices. What happens when we replace humans with robot caretakers? This flattens complex systems like health and well-being into a system of nuance-free numbers, an additional theme of this piece.</p>\n<p><b>Research</b></p>\n<p>In this project and in my research, I explored the following questions:</p>\n<ul>\n<li>Why do we flatten “health” into quantitative data that does not ultimately measure our health?</li>\n<li>How does capitalism affect the design and aesthetic choices of Silicon Valley products?</li>\n<li>Why would we want to optimize ourselves?</li>\n<li>What do companies get when they encourage their workers to practice self-care and wellness?</li>\n<li>What processes is the wellness industry replacing?</li>\n<li>What moral judgements are embedded into the wellness industry?</li>\n<li>How much money is being made in the wellness industry?</li>\n<li>How do tech companies incorporate video game and corporate aesthetics in their wellness projects?</li>\n<li>Why do we appropriate from other cultures to seek our own enlightenment?</li>\n</ul>\n<p>More broadly, I have been researching the sociological and philosophical aspects of care and self-care, particularly the writings of Laura Berlant and Eva Ilouz. I've also looked at the philosophies espoused by the technology industry, including the Quantified Self movement, the Dark Enlightenment and its quest for immortality-- what role does that play in the push for exercise and care? What role does \"work life balance\" and workplace benefits play in them? How do the capitalist aesthetics of video games-- explicitly, such as in gamification, and implicitly, in a push for 'optimization,' affect people's desires for self-care? Broader looks at surveillance culture and machine learning attitudes are also a part of my research process, as well as the aesthetics of gender and wellness in this industry. For instance, every smart assistant voice is feminine, as this is supposedly more \"friendly,\" and most meditation apps are \"gamified\" to resemble the incentive mechanics of a video game. How do these aesthetics affect our perceptions of these devices and apps?</p>\n<p><a href=\"http://www.karma.care\">A bibliography can be found here.</a></p>\n","portfolio_icon":{"src":"https://itp.nyu.edu/thesis2018/wp-content/uploads/2018/04/render.png","title":"Karma. The Smarter Assistant.","alt":"A Render of Karma","caption":"Karma. The Smarter Assistant."},"topics":[{"name":"Data","slug":"data"},{"name":"Health","slug":"health"}],"video_presentation_url":"https://player.vimeo.com/video/269234063","video_documentation_url":"","project_url":"http://www.karma.care","description":"","featured_image":[{"src":"https://itp.nyu.edu/thesis2018/wp-content/uploads/2018/04/render.png","title":"Karma. The Smarter Assistant.","alt":"A Render of Karma","caption":"Karma. The Smarter Assistant."}],"slide_show":[{"src":"https://itp.nyu.edu/thesis2018/wp-content/uploads/2018/04/image-3-1024x576.png","title":"The uses of Karma","alt":"The uses of Karma","caption":"The uses of Karma"},{"src":"https://itp.nyu.edu/thesis2018/wp-content/uploads/2018/04/pc-1024x576.png","title":"Webapp + Texts from Karma","alt":"Webapp + Texts from Karma","caption":"Webapp + Texts from Karma"},{"src":"https://itp.nyu.edu/thesis2018/wp-content/uploads/2018/04/render2-1024x576.png","title":"Karma on your desk.","alt":"Karma on your desk.","caption":"Karma on your desk."},{"src":"https://itp.nyu.edu/thesis2018/wp-content/uploads/2018/04/bannerwide.png","title":"Ad Campaign for Karma","alt":"Ad Campaign for Karma","caption":"Ad Campaign for Karma"}]}