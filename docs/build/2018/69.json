{"post_id":396,"student_id":"69","student_name":"Nitish Wakalkar","student_slug":"nitish-wakalkar","advisor_id":"124","advisor_name":"Kathleen Wilson","advisor_slug":"ksw222","project_title":"The Quirk Bot Experiment","project_question":"The goal of my thesis project was to comment on society’s current rush to automate everyday tasks, for better or for worse, by creating a fictionalized work-space scenario where office products are made to perform mundane human tasks and assume human personality traits.\r\n<br />\r\n<br />\r\nMy primary research consisted of trying to understand the office organization and modular systems, as well as process of automation, machine learning and fabrication. Based on my findings, I made a catalog of the different kinds of motions work-space objects might perform if automated, created a few preliminary simulations and ultimately, built a desktop installation comprised of two prototypes, a ‘lamp bot’ and a ‘stationery bot.'\r\n<br />\r\n<br />\r\nThe preliminary simulation I developed included: lamp bot, which is a study lamp that automatically positions itself over a rectangular object held in hand, such as a book or paper. Stationery bot, which is a pen holder that moves around the desk and collects small oblong objects (like pens or pencils). Knolling bot, which is an aligner cube that moves around the desk trying to align edges of rectangular objects to the edges of the table. Monitor bot, which is a computer screen that automatically positions itself to the user's viewing angle.\r\n<br />\r\n<br />\r\nMy experiments were motivated by several design questions. Will making desktop objects smarter be helpful? Funny? Or just annoying? Will it help reveal and solve any problems that were previously unnoticed or help create new product ideas? Will it become a common feature of new products? Can it help us be more productive? Should smart objects be able to work for us in our absence? Can virtual assistants pair-up with other smart objects to form a new kind of smart work-space?\r\n<br />\r\n<br />\r\nCurrently we use smart devices like virtual assistants at home and work, but they have physical and spatial restrictions. Products with automation capabilities could give these smart assistants partial spatial access, which may help various users suit their different needs.","short_description":"How much is too much with respect to robotic task automation? Can automation in the work space help us be more productive?\r\n<br />\r\n<br />\r\n<i>Quirk bots</i> is an experimental project that speculates on the value of making work- space objects smarter and whether or not they have the potential to enhance the day-to- day work experience.","further_reading":"<p>Machines and AI are increasingly taking on the problematic tasks that we perform on a daily basis. We humans spend a good amount of time fidgeting and adjusting objects in our work-space. like adjusting our table lamps to get the perfect lighting for reading or keeping things organized and aligned to the edge of table. We don't usually think much about these micro-tasks, but sometimes they can be time-consuming and bothersome. We perform them anyway because we think they might solve the small issues we are facing at the moment.</p>\n<p><i>Quirk Bot</i> is a speculative design project exploring the kinds of hypothetical smart office products that might be created to perform automated micro-motions based on observations of the ongoing micro-tasks people often perform while going about their daily office tasks. My goal is not to make a product that solves current problems around the work space, but rather to find ways to enhance the work experience and make it more efficient by removing the need to deal with frequently recurring micro-tasks. </p>\n<p>My primary audience so far has been me, but my plan is to get feedback from other people in the future who, like me, tend to like their work environments to be neat and are interested in trying out smart devices like virtual assistants and robots. I am curious to learn more about the kinds of smart objects others would like to have and whether or not they would find the prototypes I’ve created useful. Once all of my Quirk Bot prototypes are complete, I plan to observe people interacting with them in order to learn more about what’s working and what’s not, as well as get a better understanding of the kinds of users that might benefit from the ideas inspired by my prototypes.</p>\n<p>Among other things, my primary research involved contacting a professional organizer, who gave me some invaluable insights about how their clients behave in their work-spaces. I learned, for example, how difficult it is for them to change certain habits that cause them to be less productive, such as fidgeting with objects on their desks. I recorded myself in my work area for a week with a GoPro to analyze my own micro-interactions with objects. This made me realize it is very difficult to eliminate mundane tasks with automation because they do not really seem to be an issue, in fact these tasks and micro-interactions are a part of my personality.</p>\n<p>I also did a review of products on the market with similar features to ‘Quirk Bot’ in terms of automating everyday tasks. These included Roomba, Nissan’s self-parking chairs, Seven Dreamer’s Clothes folding closet and Travelmate Robotics handle-less travel bag. It was difficult, however, to find a product that deals specifically with the workspace. I find it interesting that although automation has yet to come to our physical offices and desks, our virtual offices and desktops have plenty of organizational tools for digital workspaces such as Fences or Rainmeter, which many people find quite useful.</p>\n<p>In terms of technical implementation, I investigated the ways in which I could use machine learning to detect objects and humans to help be better understand how my smart objects could be instructed to perform their actions. I also studied certain mobility related mechanisms like kinematic linkages, pulleys, joints with different degrees of freedom, etc., in order to fabricate the most effective way to perform the mentioned tasks.</p>\n<p>I began prototyping <i>Quirk Bot</i> by creating a modular system that could work for any number of smart office objects. This involved attaching a camera above my desk facing downwards, then programming a machine-learning AI to locate a smart object on my desk and send it instructions for performing its designated micro-tasks. The first smart object prototype I made was the study lamp bot, which automatically positions itself over rectangular objects someone is holding on the desktop. Rather than building a robotic arm from scratch, I borrowed one that was available at ITP, attached a flashlight on it and programmed it to follow a rectangular object using a camera. The next one I built was the stationery bot, which moves around a desk collecting pens and pencils. The materials I used for these prototypes included wooden sheets, metal rods, springs and electronic components like LED lights, servo motors, DC motors, batteries, digital camera, depth sensors, Arduino, Raspberry Pi, and cables.</p>\n<p><img src=\"https://itp.nyu.edu/thesis2018/wp-content/uploads/2018/04/combined.gif\" /></p>\n<p>I began user testing before I actually built my automated objects. This involved moving a study lamp by hand above a person sitting at a desk and reading a book or sketching to simulate how a smart lamp might adjust as to the person’s micro-movements with the book. I was curious to see how helpful, or perhaps annoying, the movement of the lamp would be. Next, I recorded my movement patterns with the lamp as I reacted to the person’s micro-movements, then programmed the robotic arm to perform these actions based on simple preplanned user tasks. For the stationery bot, I first used a empty box with a slit on one of the edges, attached a thin rope to it and pulled it over the table to see what sort of motions would the robot would have to perform to get around the obstacles on the desk. Then made a prototype and programmed it to move in a straight direction, rotate on sensing the edge or an obstacle and keep moving straight again, just how a roomba would.</p>\n<p>Upon user testing these prototypes, the feedback was mostly positive, and directed me towards possible real use case scenarios where such products would benefit certain users. For example, the lamp bot could help people with near sight issues help read small text, or use it as a pointer to find tagged objects like wallets and keys. Some users thought it they would also like such devices as novelty or toys for their home or workspace.</p>\n<p>My next step would be to try to minimize and miniaturize in order to suit a marketable solution. To carry on the experiment I would be attaching a Pico projector and a camera to a robotic gimbal, this would enable me not only to track the user’s actions but also project custom light or image in the space, based on user’s requirements. I would also like to explore if advanced sensors and components could help me embed machine learning capabilities along with AI assistant pairing compatibility to the product, so as to give the user multiple control points. </p>\n<p>For my thesis I chose to experiment with the notion of what the new smart product might do. A typical design process is purely driven by practicality of solving a singular problem in a problem area by upon creation of a single product. The process of experimentation lets the designer create different solutions for multiple problems in a problem area so as to validate and simplify further, thus tackling various problems upon creation of a single product.  </p>\n<p><img src=\"https://itp.nyu.edu/thesis2018/wp-content/uploads/2018/04/design-reprocess-01.png\" /></p>\n<p>These experiments and their user feedback has inspired me to create a product which may be a viable solution for AI assistant’s limited spatial accessibilities, and I would definitely like to explore more as to how the future of AI might shape the invention of products.</p>\n","portfolio_icon":{"src":"https://itp.nyu.edu/thesis2018/wp-content/uploads/2018/04/quirk-bots-thumbnail.png","title":"quirk bots-thumbnail","alt":"smart objects","caption":""},"topics":[{"name":"Tangiable","slug":"tangiable"},{"name":"UX\\UI","slug":"uxui"}],"video_presentation_url":"https://player.vimeo.com/video/269233811","video_documentation_url":"https://player.vimeo.com/video/265900909","project_url":"https://www.nitishitp.com/quirk-bots/","description":"","featured_image":[{"src":"https://itp.nyu.edu/thesis2018/wp-content/uploads/2018/04/quirk-bots-thumbnail.png","title":"quirk bots-thumbnail","alt":"smart objects","caption":""}],"slide_show":[{"src":"https://itp.nyu.edu/thesis2018/wp-content/uploads/2018/04/quirk-bots-render-1.jpg","title":"quirk bots render","alt":"All bots","caption":""}]}